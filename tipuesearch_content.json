{"pages":[{"title":"Rust - Closure","text":"tl;dr Rust's closures are syntax sugar for trait default closure environment on stack (borrow) static dispatch return from function closure environment on heap (use Box ) use move to create own stack frame dynamic dispatch use reference //////////////////////////////////////// // Syntax fn plus_one_v1 ( x : i32 ) -> i32 { x + 1 } // function let plus_one_v2 = | x : i32 | -> i32 { x + 1 }; // closure let plus_one_v3 = | x : i32 | x + 1 ; // closure let plus_one_v4 = | x | x + 1 ; // closure //////////////////////////////////////// // dynamic dispatch (reference) fn f ( closure : & Fn ( i32 ) -> i32 ) -> i32 { closure ( 1 ) } let answer = f ( &| x | x + 2 ); //////////////////////////////////////// // return closure from function fn factory () -> Box < Fn ( i32 ) -> i32 > { let num = 5 ; Box :: new ( move | x | x + num ) } let f = factory (); //////////////////////////////////////// 等待的時間總是無聊， 只好打開電腦研究點東西。 今天在 Slack 上聊天時， 聊到了在 Python 可以利用 function 回傳 function 來做一些特別的事， 對於一個 Python 使用者來說這件事很常遇到 (又看看 decorator)， 這時突然就連結到 Rust， Rust 裡面也可以定義 local function， 那是否可以像 Python 一樣回傳出去使用？ 於是，來翻翻 Rust 的 closure 吧 ~ Rust 不只支援 named function， 還支援匿名函式， 當匿名函式裡有跟當時環境相關的變數時， 就稱為 closure， 以下就描述如何在 Rust 裡運用它。 Syntax Rust 的 closure 是用兩個 | 把變數夾住， 後面接處理的 code， 可以用 {} 把多個處理包起來 (Rust 的 {} 是 expression) let plus_one = | x | x + 1 ; assert_eq ! ( 2 , plus_one ( 1 )); //////////////////////////////////////// let plus_two = | x | { let mut result : i32 = x ; result += 1 ; result += 1 ; result }; assert_eq ! ( 4 , plus_two ( 2 )); //////////////////////////////////////// let plus_one = | x : i32 | -> i32 { x + 1 }; assert_eq ! ( 2 , plus_one ( 1 )); //////////////////////////////////////// // compare fn plus_one_v1 ( x : i32 ) -> i32 { x + 1 } let plus_one_v2 = | x : i32 | -> i32 { x + 1 }; let plus_one_v3 = | x : i32 | x + 1 ; let plus_one_v4 = | x | x + 1 ; 這邊可以看到 Rust 的 closure 和一般 function 不同， 不需要寫明傳入和回傳的 type (但可以寫明)， 這設計是為了方便使用 (一般 function 要寫明是為了 documentation、type inference)。 Closure 和外部變數 先看一段範例 code： let num = 5 ; let plus_num = | x | x + num ; assert_eq ! ( 10 , plus_num ( 5 )); 這邊的 closure 有用到一個不是參數的變數 num ， 他是靠外面的 num 來取得資料， 更明確來說這個 closure 裡的 num 借 (borrow) 了外面 num 的 binding。 如果在那之後又更動了 num 這個變數， 則會在 compile time 時出錯： let mut num = 5 ; let plus_num = | x : i32 | x + num ; // error num = num + 1 ; // error: cannot assign to `num` because it is borrowed // num = num + 1; // &#94;~~~~~~~~~~~~ // note: borrow of `num` occurs here // let plus_num = |x: i32| x + num; // &#94;~~~~~~~~~~~~~~~ 但是可以用 {} 把借用的區域包起來， 這樣超出這段範圍後就會停止借用： let mut num = 5 ; { let plus_num = | x : i32 | x + num ; } // plus_num goes out of scope, borrow of num ends num = num + 1 ; 另外 Rust 的 closure 對於 non-copyable 的變數還會拿走 ownership、move 資源： let nums = vec ! [ 1 , 2 , 3 ]; let takes_nums = || nums ; println ! ( \"{:?}\" , nums ); // error: use of moved value: `nums` [E0382] // println!(\"{:?}\", nums); // &#94;~~~ // note: `nums` moved into closure environment here because it has type `collections::vec::Vec<i32>`, which is non-copyable // let takes_nums = || nums; // &#94;~~~~~~ \"move\" closures 對於不會自動觸發 ownership 轉移的情況， 我們可以使用 move 來強制轉移 (注意的是這邊雖然叫 move，但是表示的是 closure 可以拿到 ownership， 不一定是 resourse 的 move，可能是 copy 一份)： let mut num = 5 ; { let mut add_num = | x : i32 | num += x ; // modify the original num add_num ( 5 ); } assert_eq ! ( 10 , num ); let mut num = 5 ; { let mut add_num = move | x : i32 | num += x ; // modify a copy version of num add_num ( 5 ); } assert_eq ! ( 5 , num ); 在沒有使用 move 的情況下， closure 會綁在建立這 closure 的 stack frame 上， move closure 則是 self-contained 的， 這裡也可以發現要回傳一個 non-move closure 是不行的 (因為綁在 function stack frame 上，回傳後會被清掉)。 Closure implementation Rust closure 的實作和其他語言有點不同， Rust 的 closure 是 trait 的 syntax sugar Rust Book - Traits Rust Book - Trait Objects 在 Rust 裡，用 () 來 call function 這件事是 overloadable 的， 我們可以用 trait 來 overload 這個 operator (有三種 trait 可以 overload)： pub trait Fn < Args > : FnMut < Args > { extern \"rust-call\" fn call ( & self , args : Args ) -> Self :: Output ; } pub trait FnMut < Args > : FnOnce < Args > { extern \"rust-call\" fn call_mut ( & mut self , args : Args ) -> Self :: Output ; } pub trait FnOnce < Args > { type Output ; extern \"rust-call\" fn call_once ( self , args : Args ) -> Self :: Output ; } 三種不同的情況，讓我們可以有良好的掌控性： trait self Fn &self FnMut &mut self FnOnce self || {} 則是這三種情況的 syntax suger， Rust 會為 closure 的外部變數生出 struct， impl 需要的 trait，然後使用它。 closures as arguments 到這邊我們得知 Rust 的 closure 其實就是 trait， 所以如何傳入和回傳 closure 就跟 trait 一樣 (這也表示我們可以選擇 static 或 dynamic dispatch)。 fn call_with_one < F > ( some_closure : F ) -> i32 where F : Fn ( i32 ) -> i32 { some_closure ( 1 ) } let answer = call_with_one ( | x | x + 2 ); assert_eq ! ( 3 , answer ); 這邊可以看到傳入的 type 為 Fn(i32) -> i32 ， Fn 就是個 trait，這邊寫明說會傳入 i32、回傳 i32， 這也就是我們 closure 需要的 type。 這邊一個重點是 Rust 的 closure 可以做 static dispatch， 在許多語言裡，closure 是 heap allocation 並且是 dynamic dispatch， 但是 Rust 可以做 stack allocation 和 static dispatch， 這很常被使用，尤其是在 iterator 那邊常常會傳入 closure 做篩選。 雖然 Rust 支援 static dispatch 的 closure， 但是想要使用 dynamic dispatch 還是可以的： fn call_with_one ( some_closure : & Fn ( i32 ) -> i32 ) -> i32 { some_closure ( 1 ) } let answer = call_with_one ( &| x | x + 2 ); assert_eq ! ( 3 , answer ); returning closures 第一次失敗的嘗試： fn factory () -> ( Fn ( i32 ) -> Vec < i32 > ) { let vec = vec ! [ 1 , 2 , 3 ]; | n | vec . push ( n ) } let f = factory (); let answer = f ( 4 ); assert_eq ! ( vec ! [ 1 , 2 , 3 , 4 ], answer ); // error: the trait `core::marker::Sized` is not implemented for the type // `core::ops::Fn(i32) -> collections::vec::Vec<i32>` [E0277] // f = factory(); // &#94; // note: `core::ops::Fn(i32) -> collections::vec::Vec<i32>` does not have a // constant size known at compile-time // f = factory(); // &#94; // error: the trait `core::marker::Sized` is not implemented for the type // `core::ops::Fn(i32) -> collections::vec::Vec<i32>` [E0277] // factory() -> (Fn(i32) -> Vec<i32>) { // &#94;~~~~~~~~~~~~~~~~~~~~ // note: `core::ops::Fn(i32) -> collections::vec::Vec<i32>` does not have a constant size known at compile-time // factory() -> (Fn(i32) -> Vec<i32>) { // &#94;~~~~~~~~~~~~~~~~~~~~ 為了要從 function 回傳東西，Rust 需要知道 return type 的大小， 但是 Fn 是一個 trait，它可以包含各種東西、是各種大小， 各種不同的 type 可以實作 Fn ， 一個可以知道回傳大小的簡單方式就是用 reference (reference 的大小是已知的) 第二次失敗的嘗試： fn factory () -> & ( Fn ( i32 ) -> Vec < i32 > ) { let vec = vec ! [ 1 , 2 , 3 ]; | n | vec . push ( n ) } let f = factory (); let answer = f ( 4 ); assert_eq ! ( vec ! [ 1 , 2 , 3 , 4 ], answer ); // error: missing lifetime specifier [E0106] // fn factory() -> &(Fn(i32) -> i32) { // &#94;~~~~~~~~~~~~~~~~ 這次缺了 lifetime，我們用了 reference， 所以需要給個 lifetime， 這邊沒有參數，狀況很單純，使用 'static 第三次失敗的嘗試： fn factory () -> & 'static ( Fn ( i32 ) -> i32 ) { let num = 5 ; | x | x + num } let f = factory (); let answer = f ( 1 ); assert_eq ! ( 6 , answer ); // error: mismatched types: // expected `&'static core::ops::Fn(i32) -> i32`, // found `[closure <anon>:7:9: 7:20]` // (expected &-ptr, // found closure) [E0308] // |x| x + num // &#94;~~~~~~~~~~ compiler 說他拿到的 type 是 [closure <anon>:7:9: 7:20] ， 不是我們寫的 &'static Fn(i32) -> i32 ， 這是因為每個 closure 都是依照當時的 environment struct 、 Fn 實作， 這些 type 都是 anonymous 的，所以 Rust 把它視為 closure <anon> 。 至於為何沒有實作 &'static Fn 則是因為 environment 是借來的， 而在這 case 中 environment 是 stack 上的變數， 所以 borrow 的 lifetime 等同於 stack frame 的 lifetime， 如果把 closure 回傳了，function stack frame 就會被清除， closure 裡取到的就是不正確的值。 第四次失敗的嘗試： fn factory () -> Box < Fn ( i32 ) -> i32 > { let num = 5 ; Box :: new ( | x | x + num ) } let f = factory (); let answer = f ( 1 ); assert_eq ! ( 6 , answer ); // error: `num` does not live long enough // Box::new(|x| x + num) // &#94;~~~~~~~~~~ 這次把 closure 丟到 heap 上了 (用 Box)，但是發現 num 還是取到 stack 上的值， 於是又再稍做修改。 成功： fn factory () -> Box < Fn ( i32 ) -> i32 > { let num = 5 ; Box :: new ( move | x | x + num ) } let f = factory (); let answer = f ( 1 ); assert_eq ! ( 6 , answer ); 使用 move 來為 closure 建立新的 stack frame來儲存一份使用到的外部變數， 利用 Box 來把 closure 放到 heap 上，如此一來 size 變成已知， 離開原本建立的 stack frame 後也可以使用。 Reference Rust Book - Closures","loc":"/posts/2015/07/rust-closure/","tags":"Rust"},{"title":"Rust Example - Project Euler #1 - Try Some Features in Simple Problem","text":"心血來潮跑去用 Rust 寫一下 Project Euler #1 的題目， 題目其實很簡單，算出 1000 以下 3 或 5 的倍數的總和， 就是個簡單的數學題，這樣的題目如果也只用非常簡單的作法來解就太無聊了， 所以就拿簡單的題目試試看可以展現出 Rust 的哪些 features (? #![feature(iter_arith)] // for .sum() // unstable library feature 'iter_arith' : bounds recently changed fn p1_sol1 () -> u64 { // formula solution // 3, 6, 9, ... // 5, 10, 15, ... // 15, 30, 45, ... // 3 * 1, 3 * 2, 3 * 3, ..., 3 * a => sum: 3 * a * (1 + a) / 2 // 5 * 1, 5 * 2, 5 * 3, ..., 5 * b => sum: 5 * b * (1 + b) / 2 // 15 * 1, 15 * 2, 15 * 3, ..., 15 * c => sum: 15 * c * (1 + c) / 2 fn sum_range ( start : u64 , end : u64 ) -> u64 { end * ( start + end ) / 2 } fn sum_multiples_of_two_below ( base_num : & [ u64 ], end : u64 ) -> u64 { let v1 = base_num [ 0 ]; let v2 = base_num [ 1 ]; let a = ( end - 1 ) / v1 ; let b = ( end - 1 ) / v2 ; let c = ( end - 1 ) / ( v1 * v2 ); let sum_a = v1 * sum_range ( 1 , a ); let sum_b = v2 * sum_range ( 1 , b ); let sum_c = ( v1 * v2 ) * sum_range ( 1 , c ); sum_a - sum_c + sum_b } sum_multiples_of_two_below ( & [ 3 , 5 ], 1000 ) // -C opt-level=3 : // // p1_sol1::h7b3c1cda8687c063eaa: // cmpq %fs:112, %rsp // ja .LBB0_2 // movabsq $8, %r10 // movabsq $0, %r11 // callq __morestack // retq // .LBB0_2: // pushq %rbp // movq %rsp, %rbp // movl $233168, %eax // popq %rbp // retq // // -C opt-level=3 -C no-stack-check : // // p1_sol1::h7b3c1cda8687c063eaa: // pushq %rbp // movq %rsp, %rbp // movl $233168, %eax // popq %rbp // retq } fn p1_sol2 () -> u64 { // simple filter solution ( 1. . 1000 ) . filter ( |& n | ( n % 3 == 0 ) || ( n % 5 == 0 )) . sum () } fn p1_sol3 () -> u64 { // general filter solution fn sum_multiples_of_base_below ( base_num : & [ u64 ], start : u64 , end : u64 ) -> u64 { ( start .. end ) . filter ( |& n | base_num . iter (). any ( |& base | n % base == 0 )) . sum () } sum_multiples_of_base_below ( & [ 3 , 5 ], 1 , 1000 ) } fn p1_sol4 () -> u64 { // macro version for filter macro_rules ! sum_multiples_of_base_below { ( OωO $($base : expr ), + OωO , $start : expr , $end : expr ) => { ( $start .. $end ) . filter ( |& n | $( n % $base == 0 ) ||+ ) . sum () } } sum_multiples_of_base_below ! ( OωO 3 , 5 OωO , 1 , 1000 ) } fn p1_sol5 () -> u64 { // closure let mut s = 0 ; let mut v = 0 ; { // only borrow in this scope let mut f = || { v = v + 1 ; s = s + (( v % 3 ) * ( v % 5 ) < 1 ) as u64 * v ; }; for _ in 1. . 1000 { f (); } } s } fn p1_sol6 () -> u64 { // static variable fn f () -> u64 { static mut s : u64 = 0 ; static mut v : u64 = 0 ; // static mut is unsafe unsafe { v = v + 1 ; s = s + (( v % 3 ) * ( v % 5 ) < 1 ) as u64 * v ; s } } let mut result = 0 ; for _ in 1. . 1000 { result = f (); } result } fn p1_sol7 () -> u64 { // iterator struct Euler { s : u64 , v : u64 , } impl Iterator for Euler { type Item = u64 ; fn next ( & mut self ) -> Option < u64 > { let s = self . s ; let v = self . v ; let s = s + (( v % 3 ) * ( v % 5 ) < 1 ) as u64 * v ; let v = v + 1 ; self . s = s ; self . v = v ; Some ( self . s ) } } let euler = Euler { s : 0 , v : 0 }; euler . skip ( 1000 - 1 ) . next (). unwrap_or ( 0 ) } fn p1_sol8 () -> u64 { // overload index // index has side-effect, it's bad :P use std :: ops :: { Index , IndexMut }; struct Euler { s : u64 , v : u64 , } impl Index < u64 > for Euler { type Output = u64 ; fn index ( & self , _index : u64 ) -> & u64 { & self . s } } impl IndexMut < u64 > for Euler { fn index_mut ( & mut self , _index : u64 ) -> & mut u64 { let v = self . v ; let s = self . s ; let v = v + 1 ; let s = s + (( v % 3 ) * ( v % 5 ) < 1 ) as u64 * v ; self . v = v ; self . s = s ; & mut self . s } } let mut euler = Euler { s : 0 , v : 0 }; for _ in 1. . 1000 { & mut euler [ 0 ]; } euler [ 0 ] } fn main () { // sum of all the multiples of 3 or 5 below 1000 // ans : 233168 println ! ( \"p1_sol1 : {}\" , p1_sol1 ()); println ! ( \"p1_sol2 : {}\" , p1_sol2 ()); println ! ( \"p1_sol3 : {}\" , p1_sol3 ()); println ! ( \"p1_sol4 : {}\" , p1_sol4 ()); println ! ( \"p1_sol5 : {}\" , p1_sol5 ()); println ! ( \"p1_sol6 : {}\" , p1_sol6 ()); println ! ( \"p1_sol7 : {}\" , p1_sol7 ()); println ! ( \"p1_sol8 : {}\" , p1_sol8 ()); } Solution 1 一般的公式解，但是還沒全部完成， 目前只能吃兩個 base number，需要更 general。 這邊剛好可以看到幾個地方， 一個是 Rust 會用 & 符號來表示 pass by reference， array 的 reference 就會變成 &[type] 。 再來是 Rust 的 function 裡面可以定義 function， 個人有在寫 Python， 而 Python 對於這種 function 裡面定義 function 是蠻方便且常見的 (看看 decorator)， 看到 Rust 可以有 local function 就有種熟悉感， 雖然 Python 跟 Rust 這兩個語言在本質上有很大的差異 XD Solution 2 Rust 可以用 .. 這個特殊的 operator 來產生 Python 中 range 的效果， 使用方法就直接寫 start..end 就可以了。 另外 Rust 有支援豐富的 iterator 操作， 可以使用 .filter 來對 iterator 做篩選， 而 .filter 中可以直接寫 lambda function 傳入， lambda function 的 syntax 是用 | ... | 把參數夾住， 可以指定參數的 type 以及是否要用 reference， 如果要寫多行的 lambda function 的話， 可以用 { ... } 來撰寫 (在 Rust 中 {} 是個 expression)。 Struct std::ops::Range Solution 3 Solution 2 的改版， 利用傳入的 array 來做出 .filter 需要的 lambda function， 如此一來可以適用於任何長度的 array。 Solution 4 Solution 3 的改版， 刻意拿 macro 出來玩 (?)。 這邊要先注意一件事， Rust 的 macro 跟 C 和 C++ 的不同， 並不是單純的字串取代， 而是跟 AST 息息相關的一部份。 這個範例把 OωO 當作前面 base numbers 的開頭和結尾， 中間的數字都會被 $($base:expr),* 吃進去， $base:expr 表示說我要爬的是 expression， 而爬到的資料我稱它為 \"base\"， 最外面的 $(...),+ 則表示裡面的 pattern 會重複一次以上 (中間用 , 區隔)， 後面分別是 $start:expr 和 $end:expr 兩個 expression， 到這邊已經把東西 parse 完了， 接下來是要生出想要的程式碼， $start 和 $end 直接拿去用在 range 上， 而 $(n % $base == 0)||* 則把寫的 base numbers 都展開成判斷式 (用 || 接起來)， 最後就達到類似 Solution 3 的效果啦~ Wikipedia - Hygienic macro Todo 把 Solution 1 改的更 general 觀察 Rust 編譯完後出來的結果 觀察 Rust 底下的記憶體操作 不同優化下生出的 assembly ...","loc":"/posts/2015/07/rust-example-project-euler-1/","tags":"Rust"},{"title":"BSD 與 AT&T; 官司訴訟的影響","text":"這學期修課爬的一些歷史 w 原共筆在這裡 : https://fossapc.hackpad.com/B0-1oYaaSKkruW 以下為直接嵌入 Hackpad 的資料 (之後應該會自己備份一份) View \bB0共筆頁面 on Hackpad.","loc":"/posts/2015/06/bsd-at-and-t/","tags":"Misc"},{"title":"Memory Management","text":"這篇主要放在 https://github.com/wdv4758h/notes/blob/master/memory-management.rst 那邊才保證是最新的 :P 在現今流通的電腦架構中，要執行一個程式就會需要用到記憶體， 而我們在撰寫程式時，依照不同的語言，會給程式設計師不同的記憶體操作程度。 例如 C 會給你操控 pointer 來對記憶體做各式各樣的處理， 但是像是 Python 這種相對高階的語言則會把記憶體相關的處理打包起來， 讓程式設計師可以專注在計算的撰寫上而不是底層記憶體的掌控。 這當然有好有壞，端看需求來做 tradeoff， 一邊是可以對資源做細部的控制，來用少量的資源達到要做的事， 一邊則是更注重在快速的把可以用的程式寫出來。 在實際開始之前，我們需要先知道一些概念。 在現代常見的電腦中，每隻程式所能看到的記憶體是受限的， 大家會被區隔開來，每隻程式都會以為只有自己在執行，看不到其他人， 這麼做可以保護程式，讓程式間不互相干擾。 想像一下，假如在沒有區隔開的情況下，我寫了一個 C 程式， 不小心沒寫好，裡面的 pointer 可能指向別的程式的資料， 然後還不小心改到，這是多麼可怕的事。 這樣的區隔機制稱為 \"Virtual Memory\"， 其中的 Virtual 指的意思是分給程式的記憶體空間不是真的實體記憶體， 而是做了一層控管，在存取時中間會把 Virtual Address 轉換成實際的 Physical Address， 而各程式看到的都是同樣的一大塊空間，但其實底下對應到的是不同實體記憶體。 (要做到這樣的機制需要 MMU (memory management unit) 的硬體支援) 在 Virtual Memory 之上，每隻程式看到的記憶體又會依照不同的使用而分區塊， 其中在程式執行時，變數常存在的地方為 Stack 和 Heap， 接下來就來看看裡面在幹嘛。 Stack & Heap 在講記憶體管理的一開始，我們先來看看資料在記憶體中是如何被放置的。 Linux process : 其中 Stack 是 local variables 和 function parameters 的地方， 每呼叫一次 function 就會 push 一個 stack frame 進去， 每次 function 回傳時就會被清掉。 [Error] 這邊可以注意到，如果我們不斷地 push 到 stack 裡， 最後超過可容許的大小，就會產生 stack overflow 因為放在 stack 上的資料會在回傳時被清掉， 當遇到回傳後仍需使用的情況， 就要把資料放在 Heap。 在 C 中要使用 Heap 就需要用 malloc 並設定需要的大小， 用完後需要使用 free 來清除。 這些步驟在一般使用 Stack 的情況中都不需要， 但是 Heap 的特別處就在於不會受限於特定的 scope 裡， 就算 function 回傳還是可以正常使用，也常用動態決定資料大小的情況。 example : // C #include <stdio.h> #include <stdlib.h> // malloc, free, atoi int main ( int argc , char * argv []) { int * dynamic_array ; if ( argc < 2 ) { printf ( \"Please give a number \\n \" ); } else { int size = atoi ( argv [ 1 ]); dynamic_array = ( int * ) malloc ( sizeof ( int ) * size ); for ( int i = 0 ; i < size ; i ++ ) { printf ( \"%d \\n \" , dynamic_array [ i ]); } free ( dynamic_array ); } return 0 ; } more example (新 malloc 的記憶體真的是新的嗎？) : // C #include <stdio.h> #include <stdlib.h> // malloc, free, atoi int main ( int argc , char * argv []) { int * dynamic_array ; if ( argc > 1 ) { int size = atoi ( argv [ 1 ]); dynamic_array = ( int * ) malloc ( sizeof ( int ) * size ); printf ( \"first time \\n \" ); for ( int i = 0 ; i < size ; i ++ ) { printf ( \"%d \\n \" , dynamic_array [ i ]); } for ( int i = 0 ; i < size ; i ++ ) { // modify dynamic_array [ i ] = i * i ; } free ( dynamic_array ); // get some new memory dynamic_array = ( int * ) malloc ( sizeof ( int ) * size ); printf ( \"second time \\n \" ); for ( int i = 0 ; i < size ; i ++ ) { printf ( \"%d \\n \" , dynamic_array [ i ]); } free ( dynamic_array ); } else { printf ( \"Please give a number \\n \" ); } return 0 ; } Common Memory Problem 管理 double free (清多次) memory leak (沒清到) 使用 use after free (清了還用) dangling pointer (清了還用) heap overflow (寫超過) stack buffer overflow (寫超過) buffer over-read (讀超過) stack overflow (用太多) double free source code : // C #include <stdio.h> #include <stdlib.h> // malloc, free int main () { int * x = malloc ( sizeof ( int )); printf ( \"origin : %d \\n \" , * x ); * x = 10 ; printf ( \"assign : %d \\n \" , * x ); free ( x ); free ( x ); return 0 ; } compile : $ gcc -Wall -std = c11 -g double-free.c -o double-free 執行 origin : 0 assign : 10 *** Error in `./double-free': double free or corruption (fasttop): 0x00000000013e3010 *** ======= Backtrace: ========= /usr/lib/libc.so.6(+0x71bad)[0x7ffb1c21cbad] /usr/lib/libc.so.6(+0x770fe)[0x7ffb1c2220fe] /usr/lib/libc.so.6(+0x778db)[0x7ffb1c2228db] ./double-free[0x4005fc] /usr/lib/libc.so.6(__libc_start_main+0xf0)[0x7ffb1c1cb790] ./double-free[0x4004c9] ======= Memory map: ======== 00400000-00401000 r-xp 00000000 00:1e 1685697 /tmp/memory/double-free 00600000-00601000 rw-p 00000000 00:1e 1685697 /tmp/memory/double-free 013e3000-01404000 rw-p 00000000 00:00 0 [heap] 7ffb1bf95000-7ffb1bfab000 r-xp 00000000 08:01 137661 /usr/lib/libgcc_s.so.1 7ffb1bfab000-7ffb1c1aa000 ---p 00016000 08:01 137661 /usr/lib/libgcc_s.so.1 7ffb1c1aa000-7ffb1c1ab000 rw-p 00015000 08:01 137661 /usr/lib/libgcc_s.so.1 7ffb1c1ab000-7ffb1c344000 r-xp 00000000 08:01 134345 /usr/lib/libc-2.21.so 7ffb1c344000-7ffb1c543000 ---p 00199000 08:01 134345 /usr/lib/libc-2.21.so 7ffb1c543000-7ffb1c547000 r--p 00198000 08:01 134345 /usr/lib/libc-2.21.so 7ffb1c547000-7ffb1c549000 rw-p 0019c000 08:01 134345 /usr/lib/libc-2.21.so 7ffb1c549000-7ffb1c54d000 rw-p 00000000 00:00 0 7ffb1c54d000-7ffb1c56f000 r-xp 00000000 08:01 134444 /usr/lib/ld-2.21.so 7ffb1c72a000-7ffb1c72d000 rw-p 00000000 00:00 0 7ffb1c76c000-7ffb1c76e000 rw-p 00000000 00:00 0 7ffb1c76e000-7ffb1c76f000 r--p 00021000 08:01 134444 /usr/lib/ld-2.21.so 7ffb1c76f000-7ffb1c770000 rw-p 00022000 08:01 134444 /usr/lib/ld-2.21.so 7ffb1c770000-7ffb1c771000 rw-p 00000000 00:00 0 7ffe79fa4000-7ffe79fc5000 rw-p 00000000 00:00 0 [stack] 7ffe79fdf000-7ffe79fe1000 r--p 00000000 00:00 0 [vvar] 7ffe79fe1000-7ffe79fe3000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall] Aborted (core dumped) memory leak source code : // C #include <stdio.h> #include <stdlib.h> // malloc #include <unistd.h> // getpid int main () { long long * x ; printf ( \"pid : %d \\n \" , getpid ()); printf ( \"per size %lu \\n \" , sizeof ( long long )); while ( 1 ) { // malloc, no free x = malloc ( sizeof ( long long ) * 1000 ); getchar (); } return 0 ; } compile : $ gcc -Wall -std = c11 -g memory-leak.c -o memory-leak 觀看 Memory 使用： $ pmap -x $pid 30593: ./a.out Address Kbytes RSS Dirty Mode Mapping 0000000000400000 4 4 0 r-x-- a.out 0000000000600000 4 4 4 rw--- a.out 0000000002572000 136 8 8 rw--- [ anon ] 00007fe14389b000 1636 1044 0 r-x-- libc-2.21.so 00007fe143a34000 2044 0 0 ----- libc-2.21.so 00007fe143c33000 16 16 16 r---- libc-2.21.so 00007fe143c37000 8 8 8 rw--- libc-2.21.so 00007fe143c39000 16 8 8 rw--- [ anon ] 00007fe143c3d000 136 136 0 r-x-- ld-2.21.so 00007fe143e1b000 12 12 12 rw--- [ anon ] 00007fe143e5c000 8 4 4 rw--- [ anon ] 00007fe143e5e000 4 4 4 r---- ld-2.21.so 00007fe143e5f000 4 4 4 rw--- ld-2.21.so 00007fe143e60000 4 4 4 rw--- [ anon ] 00007fff33951000 132 8 8 rw--- [ stack ] 00007fff3397a000 8 0 0 r---- [ anon ] 00007fff3397c000 8 4 0 r-x-- [ anon ] ffffffffff600000 4 0 0 r-x-- [ anon ] ---------------- ------- ------- ------- total kB 4184 1268 80 $ cat /proc/ $pid /smaps | grep -A 15 heap 02572000-02594000 rw-p 00000000 00:00 0 [ heap ] Size: 136 kB Rss: 8 kB Pss: 8 kB Shared_Clean: 0 kB Shared_Dirty: 0 kB Private_Clean: 0 kB Private_Dirty: 8 kB Referenced: 8 kB Anonymous: 8 kB AnonHugePages: 0 kB Swap: 0 kB KernelPageSize: 4 kB MMUPageSize: 4 kB Locked: 0 kB VmFlags: rd wr mr mw me ac use after free source code : // C #include <stdio.h> #include <stdlib.h> // malloc int main () { int * x ; x = malloc ( sizeof ( int )); * x = 9 ; printf ( \"use before free : %d \\n \" , * x ); free ( x ); printf ( \"use after free : %d \\n \" , * x ); int * y = malloc ( sizeof ( int )); * y = 10 ; printf ( \"use after free : %d \\n \" , * x ); return 0 ; } compile : $ gcc -Wall -std = c11 -g use-after-free.c -o use-after-free $ ./use-after-free use before free : 9 use after free : 0 use after free : 10 heap overflow source code : // C #include <stdio.h> #include <stdlib.h> // malloc, free #include <string.h> // strlen int main () { const char s1 [] = \"This is a test.\" ; const char s2 [] = \"This is a test. This is a test.\" ; char * x = malloc ( sizeof ( char ) * strlen ( s1 )); strcpy ( x , s2 ); free ( x ); return 0 ; } compile : $ gcc -Wall -std = c11 -g heap-overflow.c -o heap-overflow 執行： $ ./heap-overflow *** Error in ` ./heap-overflow ' : free () : invalid next size ( fast ) : 0x000000000250e010 *** ======= Backtrace: ========= /usr/lib/libc.so.6 ( +0x71bad )[ 0x7f38d091cbad ] /usr/lib/libc.so.6 ( +0x770fe )[ 0x7f38d09220fe ] /usr/lib/libc.so.6 ( +0x778db )[ 0x7f38d09228db ] ./heap-overflow [ 0x400669 ] /usr/lib/libc.so.6 ( __libc_start_main+0xf0 )[ 0x7f38d08cb790 ] ./heap-overflow [ 0x400509 ] ======= Memory map: ======== 00400000-00401000 r-xp 00000000 00:1e 1894065 /tmp/memory/heap-overflow 00600000-00601000 rw-p 00000000 00:1e 1894065 /tmp/memory/heap-overflow 0250e000-0252f000 rw-p 00000000 00:00 0 [ heap ] 7f38d0695000-7f38d06ab000 r-xp 00000000 08:01 137661 /usr/lib/libgcc_s.so.1 7f38d06ab000-7f38d08aa000 ---p 00016000 08:01 137661 /usr/lib/libgcc_s.so.1 7f38d08aa000-7f38d08ab000 rw-p 00015000 08:01 137661 /usr/lib/libgcc_s.so.1 7f38d08ab000-7f38d0a44000 r-xp 00000000 08:01 134345 /usr/lib/libc-2.21.so 7f38d0a44000-7f38d0c43000 ---p 00199000 08:01 134345 /usr/lib/libc-2.21.so 7f38d0c43000-7f38d0c47000 r--p 00198000 08:01 134345 /usr/lib/libc-2.21.so 7f38d0c47000-7f38d0c49000 rw-p 0019c000 08:01 134345 /usr/lib/libc-2.21.so 7f38d0c49000-7f38d0c4d000 rw-p 00000000 00:00 0 7f38d0c4d000-7f38d0c6f000 r-xp 00000000 08:01 134444 /usr/lib/ld-2.21.so 7f38d0e2a000-7f38d0e2d000 rw-p 00000000 00:00 0 7f38d0e6d000-7f38d0e6e000 rw-p 00000000 00:00 0 7f38d0e6e000-7f38d0e6f000 r--p 00021000 08:01 134444 /usr/lib/ld-2.21.so 7f38d0e6f000-7f38d0e70000 rw-p 00022000 08:01 134444 /usr/lib/ld-2.21.so 7f38d0e70000-7f38d0e71000 rw-p 00000000 00:00 0 7fffdc083000-7fffdc0a4000 rw-p 00000000 00:00 0 [ stack ] 7fffdc13b000-7fffdc13d000 r--p 00000000 00:00 0 [ vvar ] 7fffdc13d000-7fffdc13f000 r-xp 00000000 00:00 0 [ vdso ] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [ vsyscall ] Aborted ( core dumped ) stack buffer overflow source code: // C #include <stdio.h> int main () { int x = 0 ; char c [ 1 ]; printf ( \"x : %d \\n \" , x ); scanf ( \"%s\" , c ); printf ( \"x : %d \\n \" , x ); return 0 ; } compile : $ gcc -Wall -std = c11 -g stack-buffer-overflow.c -o stack-buffer-overflow 執行： $ ./stack-buffer-overflow x : 0 test x : 7631717 buffer over-read source code : // C #include <stdio.h> int main () { int x = 'z' ; char c [ 1 ]; c [ 0 ] = 'a' ; printf ( \"c[0] : %c \\n \" , c [ 0 ]); printf ( \"c[1] : %c \\n \" , c [ 1 ]); // read x return 0 ; } compile : $ gcc -Wall -std = c11 -g buffer-over-read.c -o buffer-over-read 執行： $ ./buffer-over-read c [ 0 ] : a c [ 1 ] : z stack overflow // C #include <stdio.h> void stack_overflow () { static int count = 0 ; count ++ ; printf ( \"count : %d \\n \" , count ); stack_overflow (); } int main () { stack_overflow (); return 0 ; } $ gcc -Wall -O0 -std = c11 -g stack-overflow.c -o stack-overflow # avoid optimization Debugger Valgrind Valgrind double free 執行： $ valgrind ./double-free Valgrind output ==22811== Memcheck, a memory error detector ==22811== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al. ==22811== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info ==22811== Command: ./double-free ==22811== ==22811== Conditional jump or move depends on uninitialised value(s) ==22811== at 0x4E7D3DC: vfprintf (in /usr/lib/libc-2.21.so) ==22811== by 0x4E84E38: printf (in /usr/lib/libc-2.21.so) ==22811== by 0x4005C2: main (double-free.c:8) ==22811== ==22811== Use of uninitialised value of size 8 ==22811== at 0x4E7A33B: _itoa_word (in /usr/lib/libc-2.21.so) ==22811== by 0x4E7D6BD: vfprintf (in /usr/lib/libc-2.21.so) ==22811== by 0x4E84E38: printf (in /usr/lib/libc-2.21.so) ==22811== by 0x4005C2: main (double-free.c:8) ==22811== ==22811== Conditional jump or move depends on uninitialised value(s) ==22811== at 0x4E7A345: _itoa_word (in /usr/lib/libc-2.21.so) ==22811== by 0x4E7D6BD: vfprintf (in /usr/lib/libc-2.21.so) ==22811== by 0x4E84E38: printf (in /usr/lib/libc-2.21.so) ==22811== by 0x4005C2: main (double-free.c:8) ==22811== ==22811== Conditional jump or move depends on uninitialised value(s) ==22811== at 0x4E7D730: vfprintf (in /usr/lib/libc-2.21.so) ==22811== by 0x4E84E38: printf (in /usr/lib/libc-2.21.so) ==22811== by 0x4005C2: main (double-free.c:8) ==22811== ==22811== Conditional jump or move depends on uninitialised value(s) ==22811== at 0x4E7D4AB: vfprintf (in /usr/lib/libc-2.21.so) ==22811== by 0x4E84E38: printf (in /usr/lib/libc-2.21.so) ==22811== by 0x4005C2: main (double-free.c:8) ==22811== ==22811== Conditional jump or move depends on uninitialised value(s) ==22811== at 0x4E7D837: vfprintf (in /usr/lib/libc-2.21.so) ==22811== by 0x4E84E38: printf (in /usr/lib/libc-2.21.so) ==22811== by 0x4005C2: main (double-free.c:8) ==22811== ==22811== Conditional jump or move depends on uninitialised value(s) ==22811== at 0x4E7D4FB: vfprintf (in /usr/lib/libc-2.21.so) ==22811== by 0x4E84E38: printf (in /usr/lib/libc-2.21.so) ==22811== by 0x4005C2: main (double-free.c:8) ==22811== ==22811== Conditional jump or move depends on uninitialised value(s) ==22811== at 0x4E7D53B: vfprintf (in /usr/lib/libc-2.21.so) ==22811== by 0x4E84E38: printf (in /usr/lib/libc-2.21.so) ==22811== by 0x4005C2: main (double-free.c:8) ==22811== ==22811== Invalid free() / delete / delete[] / realloc() ==22811== at 0x4C2B200: free (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so) ==22811== by 0x4005FB: main (double-free.c:12) ==22811== Address 0x51d8040 is 0 bytes inside a block of size 4 free'd ==22811== at 0x4C2B200: free (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so) ==22811== by 0x4005EF: main (double-free.c:11) ==22811== ==22811== ==22811== HEAP SUMMARY: ==22811== in use at exit: 0 bytes in 0 blocks ==22811== total heap usage: 1 allocs, 2 frees, 4 bytes allocated ==22811== ==22811== All heap blocks were freed -- no leaks are possible ==22811== ==22811== For counts of detected and suppressed errors, rerun with: -v ==22811== Use --track-origins=yes to see where uninitialised values come from ==22811== ERROR SUMMARY: 9 errors from 9 contexts (suppressed: 0 from 0) memory leak 執行： $ valgrind --leak-check = full --show-leak-kinds = all ./memory-leak Valgrind output ==27173== Memcheck, a memory error detector ==27173== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al. ==27173== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info ==27173== Command: ./memory-leak ==27173== ==27173== ==27173== HEAP SUMMARY: ==27173== in use at exit: 32,000 bytes in 4 blocks ==27173== total heap usage: 4 allocs, 0 frees, 32,000 bytes allocated ==27173== ==27173== 8,000 bytes in 1 blocks are still reachable in loss record 1 of 2 ==27173== at 0x4C29F90: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so) ==27173== by 0x400621: main (memory-leak.c:15) ==27173== ==27173== 24,000 bytes in 3 blocks are definitely lost in loss record 2 of 2 ==27173== at 0x4C29F90: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so) ==27173== by 0x400621: main (memory-leak.c:15) ==27173== ==27173== LEAK SUMMARY: ==27173== definitely lost: 24,000 bytes in 3 blocks ==27173== indirectly lost: 0 bytes in 0 blocks ==27173== possibly lost: 0 bytes in 0 blocks ==27173== still reachable: 8,000 bytes in 1 blocks ==27173== suppressed: 0 bytes in 0 blocks ==27173== ==27173== For counts of detected and suppressed errors, rerun with: -v ==27173== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0) use after free 執行： $ valgrind ./use-after-free Valgrind output ==32017== Memcheck, a memory error detector ==32017== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al. ==32017== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info ==32017== Command: ./use-after-free ==32017== ==32017== Invalid read of size 4 ==32017== at 0x4005DD: main (use-after-free.c:16) ==32017== Address 0x51d8040 is 0 bytes inside a block of size 4 free'd ==32017== at 0x4C2B200: free (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so) ==32017== by 0x4005D8: main (use-after-free.c:14) ==32017== ==32017== Invalid read of size 4 ==32017== at 0x40060C: main (use-after-free.c:21) ==32017== Address 0x51d8040 is 0 bytes inside a block of size 4 free'd ==32017== at 0x4C2B200: free (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so) ==32017== by 0x4005D8: main (use-after-free.c:14) ==32017== ==32017== ==32017== HEAP SUMMARY: ==32017== in use at exit: 4 bytes in 1 blocks ==32017== total heap usage: 2 allocs, 1 frees, 8 bytes allocated ==32017== ==32017== LEAK SUMMARY: ==32017== definitely lost: 4 bytes in 1 blocks ==32017== indirectly lost: 0 bytes in 0 blocks ==32017== possibly lost: 0 bytes in 0 blocks ==32017== still reachable: 0 bytes in 0 blocks ==32017== suppressed: 0 bytes in 0 blocks ==32017== Rerun with --leak-check=full to see details of leaked memory ==32017== ==32017== For counts of detected and suppressed errors, rerun with: -v ==32017== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0) heap overflow 執行： $ valgrind ./stack-overflow Valgrind output ==31005== Memcheck, a memory error detector ==31005== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al. ==31005== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info ==31005== Command: ./heap-overflow ==31005== ==31005== Invalid write of size 1 ==31005== at 0x4C2D610: strcpy (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so) ==31005== by 0x40065C: main (heap-overflow.c:12) ==31005== Address 0x51d804f is 0 bytes after a block of size 15 alloc'd ==31005== at 0x4C29F90: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so) ==31005== by 0x400645: main (heap-overflow.c:10) ==31005== ==31005== Invalid write of size 1 ==31005== at 0x4C2D623: strcpy (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so) ==31005== by 0x40065C: main (heap-overflow.c:12) ==31005== Address 0x51d805f is 16 bytes after a block of size 15 alloc'd ==31005== at 0x4C29F90: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so) ==31005== by 0x400645: main (heap-overflow.c:10) ==31005== ==31005== ==31005== HEAP SUMMARY: ==31005== in use at exit: 0 bytes in 0 blocks ==31005== total heap usage: 1 allocs, 1 frees, 15 bytes allocated ==31005== ==31005== All heap blocks were freed -- no leaks are possible ==31005== ==31005== For counts of detected and suppressed errors, rerun with: -v ==31005== ERROR SUMMARY: 17 errors from 2 contexts (suppressed: 0 from 0) stack buffer overflow Valgrind 的 Memcheck 目前沒有針對 global / stack array 的 bounds checking， 但是有另外一個實驗的工具叫 \"SGcheck\" 可以偵測這類問題 Why doesn't Memcheck find the array overruns in this program? 執行： $ valgrind --tool = exp-sgcheck ./stack-buffer-overflow Valgrind output ==6617== exp-sgcheck, a stack and global array overrun detector ==6617== NOTE: This is an Experimental-Class Valgrind Tool ==6617== Copyright (C) 2003-2013, and GNU GPL'd, by OpenWorks Ltd et al. ==6617== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info ==6617== Command: ./stack-buffer-overflow ==6617== ==6617== Invalid write of size 1 ==6617== at 0x4E854A5: _IO_vfscanf (in /usr/lib/libc-2.21.so) ==6617== by 0x4E9571E: __isoc99_scanf (in /usr/lib/libc-2.21.so) ==6617== by 0x4005AE: main (stack-buffer-overflow.c:9) ==6617== Address 0xfff0000cc expected vs actual: ==6617== Expected: stack array \"c\" of size 1 in frame 2 back from here ==6617== Actual: unknown ==6617== Actual: is 0 after Expected ==6617== ==6617== ==6617== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0) buffer over-read 暫時沒看到 Valgrind 上的解法 ... GCC 的話可以在 compile 時，加上 -fsanitize=address 參數來 check compile : $ gcc -Wall -std = c11 -fsanitize = address -g buffer-over-read.c -o buffer-over-read 執行 : $ ./buffer-over-read output (terminal 上有上色) ================================================================= ==10965==ERROR: AddressSanitizer: stack-buffer-overflow on address 0x7ffde2d80511 at pc 0x00000040095e bp 0x7ffde2d804d0 sp 0x7ffde2d804c0 READ of size 1 at 0x7ffde2d80511 thread T0 #0 0x40095d in main /tmp/memory/buffer-over-read.c:13 #1 0x7f43ee71a78f in __libc_start_main (/usr/lib/libc.so.6+0x2078f) #2 0x4007b8 in _start (/tmp/memory/buffer-over-read+0x4007b8) Address 0x7ffde2d80511 is located in stack of thread T0 at offset 33 in frame #0 0x400895 in main /tmp/memory/buffer-over-read.c:5 This frame has 1 object(s): [32, 33) 'c' <== Memory access at offset 33 overflows this variable HINT: this may be a false positive if your program uses some custom stack unwind mechanism or swapcontext (longjmp and C++ exceptions *are* supported) SUMMARY: AddressSanitizer: stack-buffer-overflow /tmp/memory/buffer-over-read.c:13 main Shadow bytes around the buggy address: 0x10003c5a8050: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x10003c5a8060: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x10003c5a8070: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x10003c5a8080: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x10003c5a8090: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 f1 f1 =>0x10003c5a80a0: f1 f1[01]f4 f4 f4 f3 f3 f3 f3 00 00 00 00 00 00 0x10003c5a80b0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x10003c5a80c0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x10003c5a80d0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x10003c5a80e0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x10003c5a80f0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 Shadow byte legend (one shadow byte represents 8 application bytes): Addressable: 00 Partially addressable: 01 02 03 04 05 06 07 Heap left redzone: fa Heap right redzone: fb Freed heap region: fd Stack left redzone: f1 Stack mid redzone: f2 Stack right redzone: f3 Stack partial redzone: f4 Stack after return: f5 Stack use after scope: f8 Global redzone: f9 Global init order: f6 Poisoned by user: f7 Container overflow: fc Array cookie: ac Intra object redzone: bb ASan internal: fe ==10965==ABORTING stack overflow 執行： $ valgrind ./stack-overflow Valgrind output ==12380== Memcheck, a memory error detector ==12380== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al. ==12380== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info ==12380== Command: ./stack-overflow ==12380== ==12380== Stack overflow in thread 1: can't grow stack to 0xffe801ff8 ==12380== ==12380== Process terminating with default action of signal 11 (SIGSEGV) ==12380== Access not within mapped region at address 0xFFE801FF8 ==12380== at 0x4EA8E8A: _IO_file_write@@GLIBC_2.2.5 (in /usr/lib/libc-2.21.so) ==12380== If you believe this happened as a result of a stack ==12380== overflow in your program's main thread (unlikely but ==12380== possible), you can try to increase the size of the ==12380== main thread stack using the --main-stacksize= flag. ==12380== The main thread stack size used in this run was 8388608. ==12380== Stack overflow in thread 1: can't grow stack to 0xffe801ff0 ==12380== ==12380== Process terminating with default action of signal 11 (SIGSEGV) ==12380== Access not within mapped region at address 0xFFE801FF0 ==12380== at 0x4A246D0: _vgnU_freeres (in /usr/lib/valgrind/vgpreload_core-amd64-linux.so) ==12380== If you believe this happened as a result of a stack ==12380== overflow in your program's main thread (unlikely but ==12380== possible), you can try to increase the size of the ==12380== main thread stack using the --main-stacksize= flag. ==12380== The main thread stack size used in this run was 8388608. ==12380== ==12380== HEAP SUMMARY: ==12380== in use at exit: 0 bytes in 0 blocks ==12380== total heap usage: 0 allocs, 0 frees, 0 bytes allocated ==12380== ==12380== All heap blocks were freed -- no leaks are possible ==12380== ==12380== For counts of detected and suppressed errors, rerun with: -v ==12380== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0) RAII (Resource Acquisition Is Initialization) RAII 為在數個 OO 語言中使用的 programming idiom， 為 C++ 於 1984 到 1989 年間發展出來，主要由 Bjarne Stroustrup 和 Andrew Koenig 來完成， 後來也用於 D、Ada、Vala、Rust 等語言。 主要概念為把資源和物件的 lifetime 綁在一起， 當物件由 constructor 建立時，就做 resource allocation， 當物件由 destructor 拆掉時，就做 resource deallocation， 如此一來只要物件正常的拆掉，就不會有 resource leak 發生。 Ownership Pointer Ownership Model 會把 pointer 分成好幾個種類來區分出哪些資源需要被回收， 而這件事情會在編譯時期做處理，利用靜態分析來得知這些訊息， 但是這個靜態分析需要程式設計師在程式中提供一些訊息， 藉此才能提供強大的安全保證。 C++ Smart Pointer 在 <memory> 裡有以下幾種 pointer： unique_ptr 獨占的 ownership 不可複製 可以用 std::move() 轉移所有權 shared_ptr 共享的 ownership 使用 reference counting 當 counter 變成 0 時就做 deallocation weak_ptr 類似 shared_ptr，但是沒有權利做 deallocation 不會增加 reference counter 的計算 不能用來做資料的存取，主要用來監控 shared_ptr 的狀況 有了 ownership 後只要擁有者都不見了就代表可以清掉， 其中 C++ 有好幾種 pointer 來指定 ownership， unique_ptr 可以指定說只有自己是擁有者， 自己不用時就可以清掉，不用管其他人， shared_ptr 則是指定說會有多個人分享、使用， 當大家都不用時才清掉， weak_ptr 則是和 shared_ptr 類似， 但是沒有清除的權利，也不會被算進資源的使用者裡，當 shared_ptr 要清掉時，不用理 weak_ptr Garbage Collection 和前面提到自己管理記憶體的狀況相反的是自動管理記憶體， 這邊所要提的 Gabrage Collection 就是自動管理的一個方式。 Garbage Collection 不自己寫說要在什麼時候把記憶體回收， 而是等程式發現沒人要用的時候再自動回收， 缺點就是要多花點時間和記憶體，以及不確定回收的時間點， 優點就是不自己經手那些管理，可以減少出現 double free、dangling pointer 之類的 bug。 Garbage Collection 這樣的技術早在 1959 年就由 John McCarthy 發明， 用來解決 Lisp 上的一些問題。 至今使用 Garbage Collection 的程式語言很多， 知名的 Java、Python、Ruby、Lua、Go 皆在這當中。 Garbage Collection 主要分成兩大種類： reference counting tracing garbage collectors Reference Counting reference counting 就是在每個 object 後附上一個計數器， 有人用到就加一，不用了就減一， 當變成 0 時就代表沒有人在用了， 也就是說可以清掉，此時再自動做記憶體的回收。 優點是好實作，缺點是每個 object 都需要一個計數器， 會多消耗一些記憶體， 另外如果有人互相使用的話就會形成 cycle， 此時計數器就永遠不會變成 0， 因此會需要額外的 cycle 偵測的演算法來處理。 Tracing Garbage Collectors tracing garbage collectors 的概念則是一段時間後去爬那些給出去的記憶體， 看看有誰沒在用，沒在用的就清掉。 tracing garbage collectors 有很多種實作方式， 不同實作方式會有不同的優缺點以及適合的狀況。 Basic Algorithm mark-and-sweep 最簡單的概念就是 mark-and-sweep， 爬過使用清單上的 object 做標記， 最後沒做到標記的 object 就是沒在用的， 此時就可以清掉。 Strategies 由於 tracing garbage collectors 這邊依照實作的方式不同， 結果會有極大的差異， 所以當中又可以列出幾個實作的策略方向。 Generational Incremental Cases Python CPython : GC with reference counting PyPy : GC with incremental generational tracing (incminimark) Allocator Implementations dlmalloc general purpose allocator ptmalloc2 改自 dlmalloc glibc 內建使用的 memory allocator jemalloc 從 FreeBSD 7.0 和 NetBSD 5.0 開始，兩個 OS 上的 malloc 使用 Jason Evans 寫的 jemalloc 取代舊有的 phkmalloc 用於 Firefox tcmalloc thread-caching malloc Google 開發的 malloc nedmalloc hoard libumem 用於 Solaris ptmalloc2 是在 2006 年從 dlmalloc fork 出去，並且加上 multithreading 支援的版本， 後來取代 dlmalloc 成為 linux 上內建的 memory allocator。 ptmalloc // C struct malloc_chunk { INTERNAL_SIZE_T prev_size ; /* Size of previous chunk (if free). */ INTERNAL_SIZE_T size ; /* Size in bytes, including overhead. */ struct malloc_chunk * fd ; /* double links -- used only if free. */ struct malloc_chunk * bk ; /* Only used for large blocks: pointer to next larger size. */ struct malloc_chunk * fd_nextsize ; /* double links -- used only if free. */ struct malloc_chunk * bk_nextsize ; }; Debugging Data Format Reference [2009] Anatomy of a Program in Memory [2013] Using the Pointer Ownership Model to Secure Memory Management in C and C++ Ownership [2012] 避免 memory leak：C++11 Smart Pointer（上） [2012] 避免 memory leak：C++11 Smart Pointer（下） Allocators [2015] Understanding glibc malloc [GitHub] emeryberger/Malloc-Implementations [2009] one malloc to rule them all [2011] Scalable memory allocation using jemalloc algorithm behind jemalloc [2013] How tcmalloc Works [2013] Memory Allocators 101 Memory Allocator Benchmarks Dynamic Memory Management for Embedded Real-Time Systems Nah Lock: A Lock-Free Memory Allocator [2015] Malloc Microbenchmark [2014] Allocators in Rust Hoard [2010] A look at how malloc works on the Mac OSDev wiki - Memory Allocation [2000] Hoard: A Scalable Memory Allocator for Multithreaded Applications Emery Berger [2011] An Experimental Study on Memory Allocators in Multicore and Multithreaded Applications dlmalloc - A Memory Allocator Projects: Linux scalability: malloc() performance report DWARF How debuggers work: Part 1 - Basics How debuggers work: Part 2 - Breakpoints How debuggers work: Part 3 - Debugging information An interesting tree serialization algorithm from DWARF The contents of DWARF sections Wikipedia Wikipedia - C dynamic memory allocation Wikipedia - Memory management unit Wikipedia - Virtual memory Wikipedia - Memory management Wikipedia - Bounds checking Wikipedia - Memory debugger Wikipedia - Tracing garbage collection Wikipedia - Hoard memory allocator Wikipedia - Smart pointer Wikipedia - DWARF","loc":"/posts/2015/06/memory-management/","tags":"Misc"},{"title":"ARM - Raspberry Pi","text":"最近因為一些事需要嘗試看看 Raspberry Pi 跑 Computer Vision 相關程式的狀況， 手邊拿到的 Raspberry Pi 是第一代的 Model B， 硬體狀況如下： CPU 是單核的 ARM1176JZFS (架構為 ARMv6l) (Broadcom BCM2835 700MHz)， RAM 則是 512 MB (CPU、GPU 共用)， GPU 為 Broadcom VideoCore IV (250 MHz)。 根據 Wikipedia 上的紀錄，這顆 CPU 的效能大約到 0.041 GFLOPS， 差不多是 1997 ~ 1999 年 300 MHz Pentium II 的效能。 而 GPU 則可以達到 24 GFLOPS，大約為 2001 年的 Xbox。 今年 (2015) Raspberry Pi 有推出了第二代， Raspberry Pi 2 的 CPU 有升級，GPU 則維持不變， CPU 變為四核的 ARM Cortex-A7 (架構就變為 ARMv7l) (Broadcom BCM2836 900MHz)， 相比 2012 年推出的第一代，CPU 效能應該有不少的提升。 Installation 這邊因為本身是 Arch Linux 慣用者， 所以選用了 Arch Linux ARM， 在安裝上官網直接提供 針對 Raspberry Pi 的整個流程 這邊的官方 Installation 會直接把準備好的系統檔案放進去 SD Card， 照著說明做完後， 預設啟動會使用 DHCP 來連網路， 可以在 /etc/systemd/network/eth0.network 做修改， 預設： [Match] Name=eth0 [Network] DHCP=yes 修改成 static IP (假如想要的話)：(IP 純脆亂設當範例) [Match] Name=eth0 [Network] DNS=8.8.8.8 [Address] Address=202.169.175.123 [Route] Gateway=202.169.175.256 剛裝完的系統很多開發用的工具都沒有， 所以需要的話都要另外裝 XD Cross Compile [Todo] 由於 Raspberry Pi 上面的運算能力沒有很強， 如果想要編譯大量東西時會需要不少時間， 所以開始尋求在一般伺服器 (Intel x86-64 CPU) 上編譯出適合 Raspberry Pi ARM 的執行檔 Raspberry Pi 上面如果有裝 GCC 可以用的話， 可以用以下 command 來看一些優化之不支援： $ gcc -march = native -Q --help = target 這邊也可以從吐出來的訊息中看到可以在 GCC 裡使用 -march=armv6zk 來針對這顆 CPU 做優化。 Control Simple Guide to the RPi GPIO Header and Pins Layout (Raspberry Pi GPIO Layout – Revision 2)： GPIO WiringPi 官網 如是說： \"WiringPi is a GPIO access library written in C for the BCM2835 used in the Raspberry Pi.\" 安裝只要用 git 把 repo clone 下來後執行 script 就可以了： $ git clone git://git.drogon.net/wiringPi $ cd wiringPi $ ./build 裝完後會出現之後要 compile 相關程式時， 所需要的 linker 參數提示： NOTE: To compile programs with wiringPi, you need to add: -lwiringPi to your compile line(s) To use the Gertboard, MaxDetect, etc. code (the devLib), you need to also add: -lwiringPiDev to your compile line(s). 除此之外，也多了一個 command 叫 gpio ； $ gpio -v gpio version: 2.26 Copyright ( c ) 2012-2015 Gordon Henderson This is free software with ABSOLUTELY NO WARRANTY. For details type : gpio -warranty Raspberry Pi Details: Type: Model B, Revision: 2, Memory: 512MB, Maker: Sony 讀資訊： $ gpio readall +-----+-----+---------+------+---+-Model B2-+---+------+---------+-----+-----+ | BCM | wPi | Name | Mode | V | Physical | V | Mode | Name | wPi | BCM | +-----+-----+---------+------+---+----++----+---+------+---------+-----+-----+ | | | 3.3v | | | 1 || 2 | | | 5v | | | | 2 | 8 | SDA.1 | IN | 1 | 3 || 4 | | | 5V | | | | 3 | 9 | SCL.1 | IN | 1 | 5 || 6 | | | 0v | | | | 4 | 7 | GPIO. 7 | IN | 1 | 7 || 8 | 1 | ALT0 | TxD | 15 | 14 | | | | 0v | | | 9 || 10 | 1 | ALT0 | RxD | 16 | 15 | | 17 | 0 | GPIO. 0 | IN | 0 | 11 || 12 | 1 | IN | GPIO. 1 | 1 | 18 | | 27 | 2 | GPIO. 2 | IN | 0 | 13 || 14 | | | 0v | | | | 22 | 3 | GPIO. 3 | IN | 0 | 15 || 16 | 0 | IN | GPIO. 4 | 4 | 23 | | | | 3.3v | | | 17 || 18 | 0 | IN | GPIO. 5 | 5 | 24 | | 10 | 12 | MOSI | IN | 0 | 19 || 20 | | | 0v | | | | 9 | 13 | MISO | IN | 0 | 21 || 22 | 0 | IN | GPIO. 6 | 6 | 25 | | 11 | 14 | SCLK | IN | 0 | 23 || 24 | 1 | IN | CE0 | 10 | 8 | | | | 0v | | | 25 || 26 | 1 | IN | CE1 | 11 | 7 | +-----+-----+---------+------+---+----++----+---+------+---------+-----+-----+ | 28 | 17 | GPIO.17 | IN | 0 | 51 || 52 | 0 | IN | GPIO.18 | 18 | 29 | | 30 | 19 | GPIO.19 | IN | 0 | 53 || 54 | 0 | IN | GPIO.20 | 20 | 31 | +-----+-----+---------+------+---+----++----+---+------+---------+-----+-----+ | BCM | wPi | Name | Mode | V | Physical | V | Mode | Name | wPi | BCM | +-----+-----+---------+------+---+-Model B2-+---+------+---------+-----+-----+ Physical 是原本 Layout 上的編號，wPi 是 WiringPi 內部用的編號， 在使用 gpio 指令時預設是吃 wPi 的編號 (pin) GPIO 的模式： Mode Display in IN out OUT pwm ALT5 clock up down 模式切換 : $ gpio mode <pin> <mode> The GPIO utility Camera Module Camera Module - Raspberry Pi Raspberry Pi 的 Camera Module 可用在 Raspberry Pi 和 Raspberry Pi 2， 支援到 1080p30、720p60、VGA90 Python 上控制 Raspberry Pi camera module 的 library 常見的為 picamera Performance Testing 目前只先拿了 OpenCV 的 Image Stitching 範例來跑看看， 實際的東西放在這邊 [GitHub] wdv4758h/image_stitching ， 測資為 images 資料夾裡的 A001.jpg ~ A003.jpg， \"OpenCV 2.4 sample\" 在我的筆電上跑 (Intel i5-3210M) 大約需要 1.5 秒， 在 Raspberry Pi 上面則大約需要 81 秒。 之後應該要看能不能利用 GPU 來跑快一點 ~\"~ Reference Raspberry Pi | Arch Linux ARM 讓你的 Raspberry Pi 透過 GPIO 閃爍 LED 燈 用純 C 控制 GPIO，不依靠 library","loc":"/posts/2015/06/arm-rpi/","tags":"Misc"},{"title":"Rust 的一些紀錄","text":"最近又心血來潮翻了一點 Rust， 目前版本還在 1.0 beta (現在已經正式 release 啦~)， 但是有許多東西已經差不多定型了， 開始紀錄一下狀況 XD 待研究列表 traits format! 實作 macro Ownership Box Lifetime static variable dylib, rlib, and staticlib coroutine [GitHub] awesome-rust Reddit - Rust [Ｏ] Big Number 支援？ 有！ Rust - Module num::bigint pidigits benchmark | Computer Language Benchmarks Game The Fastest BigInt In The West [Ｏ] First-class function 支援？ 有！ Higher-order functions Non-local variables Partial application Arguments Results Nested functions Anonymous functions Closures Yes Yes Yes Yes Yes No Wikipedia - Firsr-class function [Ｏ] map / reduce / filter 之類的東西？ 有！在 iterator Rust - Trait std::iter::Iterator let a = [ 1 , 2 ]; // get a new iterator with map let it = a . iter (). map ( |& x | 2 * x ); // get a new iterator with filter let it = a . iter (). filter ( |& x | * x > 1 ); // use fold (reduce) to get summation let a = [ 1 , 2 , 3 , 4 , 5 ]; let value = a . iter (). fold ( 0 , | acc , & item | acc + item ); [Ｏ] Option type (maybe type) ? 有！ (目前理解) Maybe monad 裡面可能是該有的值或是 Nothing， 這樣包起來可以提醒你 handle 好意外狀況。 在 Rust 裡這樣的 type 叫作 Option ， Option 可以用來表示 function 可能會 fail， 實際存的資料長這樣 : pub enum Option < T > { None , Some ( T ), } 其中可以看到除了預期的型態之外，多加了一個 None 為可能的回傳， 當處理出問題就回傳 None ， 適用於簡單的狀況。 但是如果狀況比較複雜， 想要知道為什麼會 fail 的時候， 可以使用 Result ， 實際存的資料長這樣 : enum Result < T , E > { Ok ( T ), Err ( E ) } 可以看到正常狀況下會回傳 Ok(T) ，失敗的話會回傳 Err(E) ， 跟前面的 Option 相比多了 error 狀況可以檢查。 Option Monads in Rust Error Handling in Rust On Error Handling in Rust Rust - Error Handling Using The Option Type Effectively The Option Type Wikipedia - Option type [Ｏ] OOP (object-oriented programming)？ (研讀中 XD) Abstraction without overhead: traits in Rust [2013] The Rise of the Gang of Four with Rust Go and Rust — objects without class Rust Book - Traits Rust Book - Traits Objects rust-guidelines - traits/objects Wikipedia - Trait (computer programming) [Ｏ] Type Inference [Ｏ] 高度的 Memory Control？ Guaranteeing Memory Safety in Rust [－] REPL？ 官方目前沒有提供， 但是有專案正在進行中 [GitHub] rusti [？] 預設提供的 Sort Algorithm 是啥？ let mut v = [ - 5 , 4 , 1 , - 3 , 2 ]; v . sort (); 目前看 src/libcollections/slice.rs 裡面的 sort_by 是去 call merge_sort Worst Case O(n log n) Average Case O(n log n) Best Case O(n log n) Space O(2 n) Stable Yes Rust - Primitive Type slice - sort_by [Ｏ] Regular Expression 支援？ 官方有實作，也有文件，不過放在另外一個 package [GitHub] rust-lang/regex Rust - Crate regex [Ｏ] FFI (Foreign Function Interface)？ Rust Once, Run Everywhere Rust Book - Foreign Function Interface Rust - Module std::ffi Rust - Crate libc [GitHub] rust-lang/libc [GitHub] rust-ffi-examples - FFI examples written in Rust [Ｏ] Import third party library？ [Ｏ] Native Threading Support？ (Native Threads) 目前是 1:1 的 thread，每個 user thread 都會對應到一個 kernel thread Rust - Module std::thread Rust Book - Concurrency Fearless Concurrency with Rust [Ｘ] Garbage Collection？ [Ｏ] Format String？ 使用 macro format! format ! ( \"the value is {}\" , 123 ) Rust - Module std::fmt [Ｏ] Ownership？ Rust ownership, the hard way [GitHub] Rust RFCs - 0599 - Default Object Bound [2013] Using the Pointer Ownership Model to Secure Memory Management in C and C++ 不錯的 Memory Management 相關背景知識解說 CERT C Coding Standard Third Party Django-like project？ 還在發展中，漸漸有一些 web framework 出現。 Introducing Teepee: the next step for rust-http 上面那篇的作者有寫過 Django，後來跳出來用 Rust 想做另一套自己想要的 web framework， 但是 Rust 在當時還沒有強大的 HTTP library 可以用， 所以寫了 rust-http，後來對 Rust 更熟悉以及有了 rust-http 的經驗後， 決定重設計一個 library 並增加更多支援，這 library 被取名為 Teepee 。 現在出現的 framework 有 : Iron nickel.rs Are there any Rust projects that have similar goals to Django (i.e. full-featured web framework)? If not, want to start one? Game Engine？ http://www.piston.rs/ Template Engine？","loc":"/posts/2015/05/some-rust/","tags":"Rust"},{"title":"Krita - Open Source digital painting","text":"Krita 是一個繪圖軟體， 不管是介面操作還是功能， 都算是目前在 Open Source 繪圖軟體中最有實力和市面上商業軟體較競的， 國外也有社群在使用， 也有國外的大學在課程中開始使用 Krita ~ 希望可以把 Open Source 大幅傳入繪圖軟體市場 XDDD Kickstarter - Krita: open source digital painting","loc":"/posts/2015/05/krita/","tags":"Misc"},{"title":"OpenMP 入門","text":"Introduction OpenMP 全名叫 Open Multi-Processing， 是由 OpenMP Architecture Review Board 這個非營利組織所訂定的跨平台 API 規範， 目標是要幫現有的程式快速的加上多核心支援， 語言支援有 C、C++、Fortran， 內容包含 compiler directives、library routines、environment variables。 Compiler Support GCC 從 4.2 開始支援 OpenMP Clang 在 3.6 時還沒有完整的支援 OpenMP Version GCC icc Clang 2.5 4.2 10.1 3.0 4.4 11.0 3.1 4.7 4.0 4.9 Current Compiler Version GCC : 5.1, 2015-04-22 Clang : 3.6, 2015-02-27 Intel C++ Compiler : 15.0.2, 2015-01-22 $ gcc - fopenmp hello . c - o hello OpenMP Compilers LLVM - OpenMP Clang - Status of supported OpenMP constructs GCC -fopenmp GCC - OpenMP Example // sleep sort #include <cstdio> #include <vector> #include <unistd.h> // sleep void sleep_sort ( std :: vector < unsigned long long > & data ) { const auto length = data . size (); #pragma omp parallel num_threads(length) { #pragma omp for for ( unsigned long i = 0 ; i < length ; i ++ ) { sleep ( data [ i ]); printf ( \"%llu \\n \" , data [ i ]); } } } int main ( int argc , char * argv []) { std :: vector < unsigned long long > data ( argc - 1 ); #pragma omp parallel for for ( int i = 0 ; i < argc - 1 ; i ++ ) { sscanf ( argv [ i + 1 ], \"%llu\" , & data [ i ]); } sleep_sort ( data ); return 0 ; } OpenMP 會利用 directive 來增加 multithread 支援， 起手勢為 #pragma omp 在 GCC 中， -fopenmp 會在 link 時加上 libgomp 這個 runtime library， libgomp 會由 CPU 核心數來決定要開的 thread 數 在 C/C++ 標準中，如果遇到不支援的 #pragma 就直接忽略， 所以這樣增加 OpenMP 的支援不會造成舊 compiler 編譯時出現問題。 經由 omp.h 可以存取一個 runtime library， 但是這通常不需要， 如果要的話可以從 #define _OPENMP 得知對於不支援的 compiler 會如何處理。 Syntax parallel 使用 parallel pragma 來開始一個 parallel block， 程式會 runtime 決定要開多少 thread， 平行化的範圍是 parallel pragma 後的 statement 或 block， 結束後 thread 就會收回。 #pragma omp parallel { // Code inside this region runs in parallel. printf ( \"Hello! \\n \" ); } 實作上，GCC 會產生一個 magic function，把相關的 code 都放進去， 如此一來 block 裡個變數都是 function 的 local variable (在不同 thread 也是 local)。 ICC 則是使用類似 fork 的機制，而非使用 magic function。 兩種實作都會正常運作。 不同 context 間的變數的分享是自動處理的， 有時候是用 reference，有時候是用 register 變數 (離開 parallel block 或是執行 flush 時會清掉) OpenMP 的平行化只要搭配 if clause 就可以使用 condition 來開關 #pragma omp parallel for if(parallelism_enabled) for ( int c = 0 ; c < n ; ++ c ) handle ( c ); Loop directive: for #pragma omp for for ( int n = 10 ; n < 20 ; ++ n ) { printf ( \"%d \\n \" , n ); } 這段 code 和以下 code 等價 : int this_thread = omp_get_thread_num (), num_threads = omp_get_num_threads (); int start = ( this_thread ) * ( 20 - 10 ) / num_threads + 10 ; int end = ( this_thread + 1 ) * ( 20 - 10 ) / num_threads + 10 ; for ( int n = start ; n < end ; ++ n ) printf ( \"%d \\n \" , n ); 其中， omp_get_thread_num 取得的是現在這個 thread 的編號， omp_get_num_threads 取得的是總共有多少 thread。 在只有單條 thread 的情況下，this_thread 就會是 0， num_threads 就會是 1， start 和 end 的話則是把 for 裡的範圍分配給各個 thread， 每個 thread 會拿到 loop 裡的不同 section，如此一來每個 section 會各自平行執行。 Scheduling 預設的 schedule 是 static，在進入 loop 時，各 loop 會各自決定要計算的部份。 #pragma omp for schedule(static) for ( int c = 0 ; c < n ; ++ c ) handle ( c ); 在 dynamic 的 schedule 中，不會事先決定好每個 thread 要跑哪個部份， 每個 thread 會去詢問 OpenMP runtime library 來取得 iteration number 然後運算， 算完後再要下一個。常和 ordered 一起使用，或是不同的 iteration 會需要不同時間來執行時。 #pragma omp for schedule(dynamic) for ( int c = 0 ; c < n ; ++ c ) handle ( c ); 另外可以指定一次分配多少個 iteration 來減少詢問 OpenMP runtime library 的次數 : #pragma omp for schedule(dynamic, 3) for ( int c = 0 ; c < n ; ++ c ) handle ( c ); ordered 指定 code 中的某部份需要照順序執行 #pragma omp for ordered schedule(dynamic) for ( int n = 0 ; n < 100 ; ++ n ) { files [ n ]. compress (); #pragma omp ordered send ( files [ n ]); } Sections 指定多個 block 可以平行執行 #pragma omp sections { { Work1 (); } #pragma omp section { Work2 (); Work3 (); } #pragma omp section { Work4 (); } } #pragma omp parallel // starts a new team { //Work0(); // this function would be run by all threads. #pragma omp sections // divides the team into sections { // everything herein is run only once. { Work1 (); } #pragma omp section { Work2 (); Work3 (); } #pragma omp section { Work4 (); } } //Work5(); // this function would be run by all threads. } tasks (OpenMP 3.0) struct node { node * left , * right ; }; extern void process ( node * ); void postorder_traverse ( node * p ) { if ( p -> left ) #pragma omp task // p is firstprivate by default postorder_traverse ( p -> left ); if ( p -> right ) #pragma omp task // p is firstprivate by default postorder_traverse ( p -> right ); #pragma omp taskwait process ( p ); } 有了起手勢 #pragma omp 後，可以接以下東西 : parallel 建 thread for 把 for 切給各個 thread num_threads(N) 指定要開 N 個 thread ordered 指定 code 中的某部份需要照順序執行 sections / section 指定多個 block 可以平行執行 atomic 只能用於簡單的運算 (例如加法) critical reduction flush private firstprivate shared lastprivate default barrier 一條分界線，後面的 code 會等所有 thread 把前面都執行完後才開始 nowait 這個 statement 或 block 可以不用等，先執行完的 thread 可以繼續 (例如搭配 for 來使用) single master collapse(N) (搭配 for 使用) 處理 N 層的 Nested Loops OpenMP 2.5 中，for 裡的 iteration variable 必需是 signed integer。 OpenMP 3.0 中，還可以是 unsigned integer、pointer、constant-time random access iterator， iterator 的 case 會使用 std::distance() 來判斷 loop 的次數。 Problem Nested Loops #pragma omp parallel for for ( int y = 0 ; y < 25 ; ++ y ) { #pragma omp parallel for for ( int x = 0 ; x < 80 ; ++ x ) { tick ( x , y ); } } 裡面那層的 OpenMP code 實際上不會平行化。 OpenMP 3.0 中加入了 collapse 可以解決這個狀況 : #pragma omp parallel for collapse(2) for ( int y = 0 ; y < 25 ; ++ y ) { for ( int x = 0 ; x < 80 ; ++ x ) { tick ( x , y ); } } 效能方面，因為 libgomp 夠聰明，所以這種多層的平行化不會一直建立和回收 thread， 建立次數 ( clone system call) 會和 concurrent threads 的最大數量一樣， parallel 不單純是 pthread_create 和 pthread_join 的結合。 Reference Guide into OpenMP: Easy multithreading programming for C++ Wikipedia - OpenMP","loc":"/posts/2015/05/openmp-intro/","tags":"Misc"},{"title":"Django migrations","text":"前幾天學弟跑來問我說 Django 裡的 migrations 要怎麼用？ 本來想說留個筆記，下次碰到問題時可以參考，後來決定紀錄對話 (X 學弟 M：「dv ~，Django 的 migrations 要怎麼用啊？」 我：「你就想像是 database 的 version control 啊。用 python manage.py makemigrations myapp 會把更動 commit 上去。」 (幾分鐘後) 學弟 M：「可是我更改後它沒有偵測到耶」 我：「蛤 ~ ?」 我：「我之前用過可以正常偵測到啊，你的東西應該是用 inspectdb 去爬之前用的 database 生出來的吧 (我知道他要接現有的資料庫)，生出來後有先 makemigrations 嗎？」 學弟 M：「有啊，還是沒偵測到。」 (我跑過去東看西看) 學弟 M：「dv，還是我開我機器的帳號給你進來看好了？」 我：「喔喔，好窩」 (我進去東試試西試試) 我：「真的沒偵測到耶，好奇怪喔 ~ 囧」 (開始 Google 各種資訊) 我：「還是它自己的問題？要升升 1.8 看嗎？反正你才剛開始寫。(隨便亂猜)」 (我開始看 Django 1.8 的 release 有沒有相關的 change) 學弟 M：「好啊，我不是用 1.8 喔」 我：「我剛剛看你是 1.7.2 啊」 學弟 M：「喔喔，我去升看看」 (幾分鐘後) 學弟 M：「我升好了~」 我：「有東西壞掉了耶 XD」 我：「看起來是底下的 db connector」 學弟 M：「真的耶，壞掉惹 Q_Q」 (Google 中) 我：「原本你用的 mysql-connector-python 現在還沒支援 Django 1.8」 我：「可以先換 PyMySQL，裝一下 ~」 學弟 M：「好，我用 pip 裝一下」 學弟 M：「裝好啦」 (我去改 settings.py 換成 django.db.backends.mysql) 我：「好啦 ~ 正常了，可以開始找剛剛的問題了 ...」 (經過一些檔案開開關關和嘗試) 我：「找到問題啦，你的 models 那裡設了 manage = False 這樣他不會去偵測更動」 我：「inspectdb 出來的就設成 False 了，應該是因為你在用 inspectdb 時，代表你很有可能有另外的程式在負責管理 database，所以 Django 預設就不去做更動。」 學弟 M：「哦哦哦，真的耶，解決啦，感謝 dv ~」 我：「喔，你那邊還會有些訊息說需要 default 值的 field 沒有給 default 值，你去改改後應該就都會 work 了」 以上是在剛剛由回憶中撈取，根據修過的心理學，記憶是建構出來的，如有錯誤，我也沒辦法 XD","loc":"/posts/2015/04/django-migrations-ask-log/","tags":"Python"},{"title":"GC again - Vim","text":"前幾天覺得裝在筆電上的 neovim 也好久沒去更新了，來看看近期有什麼新進展， 後來就看到這個 GC 相關的 issue，留做紀錄 XD (Neo)Vim hangs with freeing a lot of objects #1687 [RFC] Speed up garbage collection (Issue 1687). #1761 Vim hangs with freeing a lot of objects. Patch for performance-up of GC. Without this patch, it take 100 seconds to finish GC. And if set 100000 instead of 50000, vim often hangs. With this patch, it take just 0.133967 seconds. 又是一個改 GC 後，某處獲得性能提升的例子 (X","loc":"/posts/2015/04/gc-again-vim/","tags":"Misc"},{"title":"[WIP] History of BSD","text":"這學期修了一門叫做「自由開源軟體與專案協作」的課 (看到自由開源軟體這麼對胃口的課就修下去了 (?))， 作業一被 Jserv 要求看一些 CS 歷史相關的影片，其中一部是 《A Narrative History of BSD》 ，由 BSD 知名的開發者 Kirk McKusick 來簡述歷史的一段影片， 片中講到早期 Bill Joy 還沒加入 Sun 的時間，以及後續的發展歷程。 在看影片的過程中我有紀錄下來 Kirk McKusick 描述的話， 後來我在整理的時候開始想用文字做更完整的紀錄， 於是先去找了相關文章，後來發現了一些比較完整一點的中文紀錄。 於是就開始基於那些文章做修改，加上影片的內容以及其他相關的資訊， 慢慢整理成一篇更完整的紀錄。 (目前還沒全部完成，等比較有空會繼續做，完成後應該會移過來吧) 紀錄連結 ~~~","loc":"/posts/2015/04/history-of-bsd/","tags":"Misc"},{"title":"[WIP] Artificial Neural Network - Again","text":"[WIP] 持續更改中 Artificial Neural Network Artificial Neural Network，中文有時翻做「類神經網路」， 顧名思義就是想模擬生物大腦的神經系統來解決生物能迅速做到但電腦還不能做到的事情。 其實當初就覺得有點興趣，想投入時間進去學一下， 所以在大二下的時候就有去修了系上一門叫「類神經網路」的課， 但是中間覺得老師上課實在太無聊 ...，後來就決定退掉， 那時候每次上課都只有個位數的學生到場 Orz ... 這學期 (大三下) 去修了研究所的「電腦視覺」， 剛好也碰到一些跟類神經有關的地方， 再加上近期也一直在各個地方看到相關訊息， 於是還是來好好補強一下 :P (還債) History 早在 1943 年的時候，Warren McCulloch 和 Walter Pitts 就基於數學和演算法提出了類神經的計算模型， 被稱為 \"threshold logic\"。從這模型之後，類神經的研究就分成兩邊，一邊致力於模擬生物的大腦， 另一邊則專注在應用於人工智慧領域。 在 1940 年代晚期，心理學家 Donald Hebb 基於突觸的可塑性提出了學習的假說， 被稱為 Hebbian learning。其理論為持續重複的刺激會讓突觸傳遞效能增加 (像是平常不斷做某個動作，那這個動作的反應時間就會降低)， 常被總結為 \"Cells that fire together, wire together\"。 Hebbian learning 被視為典型的非監督式學習，其後來的變種成為 long term potentiation (LTP) 的早期模型。 後來在 1948 年和 Turing's B-type machines (Unorganized machine) 開始運用在運算模型。 1954 年，Farley 和 Wesley A. Clark 在 MIT 用實際的機器來模擬 Hebbian network。 其他類神經計算的機器由 Rochester, Holland, Habit, Duda 在 1956 年製造。 1958 年，Frank Rosenblatt 提出了 perceptron (感知器)， perceptron 是一個用於 pattern recognition 的演算法， 作法是利用簡單的加減法來做兩層的學習。 除了數學式子，Rosenblatt 也說明了基本的 perceptron 不支援一些處理， 例如 exclusive-or，exclusive-or 的問題到了 1975 年 Paul Werbos 提出 backpropagation 的作法才解決。 類神經的發展在 Marvin Minsky 和 Seymour Papert 發表 machine learning 的研究後停滯， 因為裡頭提到了兩個相當重要的問題， 其中一個就是單層的 perceptron 不能解 exclusive-or 的問題， 另一個是電腦還沒複雜到足以有效率地應付類神經所需要的長時間運算。 研究就此緩慢了下來，直到電腦變得更有效率， 以及 1975 年 Paul Werbos 提出 backpropagation 的作法解決了 exclusive-or 的問題。 1980 年代中期，parallel distributed processing 在 connectionism 的發展下流行起來 (parallel distributed processing 有時簡稱為 PDP，跟 DEC 出的 PDP 衝名啦 XD)， David E. Rumelhart 和 James McClelland 在 1986 年提供了利用 connectionism 來模擬神經運作的完整說明。 類神經在人工智慧領域一向被視為大腦神經運作的簡化模型， 但其實這模型和實際大腦運作的架構的相關性一直遭到質疑， 因為類神經沒有很明確地是模擬大腦哪個部份的功能。 後來類神經在 machine learning 的領域上逐漸被 SVM (support vector machines) 和其他較簡單的方式 (例如 linear classifiers) 取代。 直到 2000 年代末期 deep learning 的到來才讓類神經又逐漸受到更多的注目。 2009 年到 2012 年間， 來自 Swiss AI Lab IDSIA 的 Jürgen Schmidhuber 的研究團隊開發了 recurrent neural networks 和 deep feedforward neural networks 贏得了諸多 pattern recognition 和 machine learning 的比賽。 舉例來說，在 2009 年的 ICDAR (International Conference on Document Analysis and Recognition)， Alex Graves 等人的 bi-directional 和 multi-dimensional long short term memory (LSTM) 就在沒有三種語言的背景知識下贏了三場手寫辨識比賽。 Dan Ciresan 和 IDSIA 的同事做了利用 GPU 的快速實作， 也因此贏得了諸多比賽 (例如 IJCNN 2011 Traffic Sign Recognition Competition、 ISBI 2012 Segmentation of Neuronal Structures in Electron Microscopy Stacks challenge)。 他們的類神經網路是第一個在辨識上可以跟人類競爭的， 甚至在一些項目中可以達到超過人類的辨識率 (例如 traffic sign recognition (IJCNN 2012)、MNIST handwritten digits problem of Yann LeCun at NYU)。 Reference Wikipedia - Deep learning Wikipedia - Artificial neural network Wikipedia - Unorganized machine Wikipedia - Long-term potentiation Wikipedia - Backpropagation Wikipedia - Long short term memory Wikipedia - Connectionism Wikipedia - MNIST database","loc":"/posts/2015/04/artificial-neural-network-agaion/","tags":"Misc"},{"title":"2001: A Space Odyssey (2001 太空漫遊)","text":"《2001: A Space Odyssey》是一部 1968 年上映的經典科幻片， 故事改編自 Arthur Clark 寫的一些短篇， 由 Arthur Clark (作家) 和 Stanley Kubrick (導演) 共同創作， 電影拍攝的同時 Arthur Clark 也在創作小說， 最後小說和電影在同一時期面世。 電影於 1964 年開始拍攝，當時國際仍處於冷戰時期 (1947 ~ 1991)，而且正值太空競賽期間 (1957 ~ 1975)。 1961 年 4 月蘇聯才剛送上第一位太空人 (當時蘇聯的太空技術領先美國)， 種種因素迫使美國投入阿波羅計劃，以登上月球為目標， 美國的甘迺迪總統也在 1961 年 5 月宣佈將會在 1970 年之前將太空人送上月球並成功返回。 而後在 1969 年 7 月，Buzz Aldrin 和 Neil Armstrong 成為史上第一個登入月球的人類。 《2001: A Space Odyssey》剛好在太空技術正開始發展的時間點， 人們開始對太空有許多的想像、寄望， 藉由這部電影可以看到當時對未來的各種想像， 也因此成為現今科幻片的經典代表。 但是對於未來的想像難免過於樂觀， 電影想像的未來 \"2001 年\" 早就已經過了， 現在已經來到了 2015 年， 但是片中還是有很多技術尚未實現。 語音辨識 ，這部電影有很多地方是建立在電腦已經能正確辨識人類說的話之上。 早在 1932 年，Bell Labs 就有這方面的研究。 1952 年，Bell Labs 建立了一個辨識系統，不過能力非常非常差。 後來因為經費因素而影響到了後續研究。 1960 年代晚期，開始出現使用 Hidden Markov Model (HMM) 來做語音辨識， 因此開始可以結合不同領域的知識來形成一個統一的機率模型 (像是聲學、語言、語法等等)。 1971 年，DARPA 對語音辨識投資了 5 年的研究，BBN、IBM、CMU、Stanford Research Institute 都參與了這項計劃， 但是後續 DARPA 就不再投資這個部份了 (相比其他能源或醫療或登月相關計劃，認為這領域沒有那麼重要)。 1980 年代開始出現 n-gram 語言模型。 Sphinx (CMU Sphinx speech recognition engines) 由李開復 (台灣) 開發， 利用 HMM 和 n-gram 而形成，特色在於第一個做到 speaker-independent。 Sphinx 2 則是針對 performance 改過的版本，由黄学东 (美國) 開發， 在 1992 年 DARPA 的評估時被認為是當時效能最好的。 2000 年，Lernout & Hauspie 取得了 Dragon Systems 這套系統， 成為當時業界的領導者，後來 Lernout & Hauspie 的 speech technonogy 被 ScanSoft 買下， 在 2005 成為 Nuance，之後與 Apple 合作，將此技術使用於 Siri 上。 2009 年開始有 deep learning 用運在語音辨識上，被稱為「自 1979 年後語音辨識準確度最戲劇性的變化」， 錯誤率下降了 30%。 人工智慧 ，片中的 AI ( HAL 9000 ) 已經能夠和人類下棋， 也能用一般的人類語言來對話，並且可以幫忙操控太空船的諸多部份， 甚至有自己的思考，會提出問題。 AI 這領域從 1956 年位在 Dartmouth College 的一場 conference 後開始被廣泛討論， 而當初參與這研討會的成員也變成了 AI 研究的領導者。 之後發展冷冷熱熱，投資來來去去。 1997 年 5 月，IBM 的 Deep Blue 成為世界上首個在西洋棋上擊敗人類世界冠軍的 AI。 2011 年 2 月，IBM 的 Watson 則在 Jeopardy! 這個智力競賽中擊敗兩位紀錄保持人。 但到現在依舊還是無法完整模擬人類的大腦，AI 領域上還是有很多地方需要被克服。 視訊電話 ，其實早期就有在發展 (甚至在 1876 年就有出現概念了)，曾經有做在電信網路上過， 到了後來網際網路發展成熟後就轉往用 TCP/IP 當底層來實作， 所以現今已經藉由網路讓 PC、手機等各個地方都可以使用視訊電話的服務。 (而網際網路的話在 1960 年代開始發展 ARPANET，到 1982 年 TCP/IP 成為 ARPANET 上的標準 protocol) Reference 【科學史上的今天】4/2——《2001太空漫遊》首映 Wikipedia - History of the Internet Wikipedia - History of videotelephony Wikipedia - Speech recognition Wikipedia - History of artificial intelligence Wikipedia - AI winter Wikipedia - History of tablet computers","loc":"/posts/2015/04/2001-a-space-odyssey/","tags":"Misc"},{"title":"Linux Video Hardware Acceleration","text":"tl;dr; VDPAU 和 VA-API 是 Unix-like 上 Video Decode 的硬體加速 API VA-API (Video Acceleration API) 是 Intel 在 2007 年提出的一套 royalty-free API， 實作在 libVA 以 MIT license 釋出。 目的是讓其他程式可以使用 Video 硬體加速。 VDPAU (Video Decode and Presentation API for Unix) 是 NVIDIA 在 2009 年提出的另一套 royalty-free API， 實作放在 libvdpau 以 MIT license 釋出 (一開始是做給 NVIDIA 自己的 GPU 用的)。 mesa 在 0.8 版加入了 VDPAU 的支援，以後只要是利用 Gallium3D 的顯卡驅動就可以獲得 VDPAU 的支援。 XvBA (X-Video Bitstream Acceleration) 則是 AMD 後來提的令一套 API ... VDPAU 也可以當作 VA-API 的 backend (libva-vdpau-driver)， VA-API 也可以當作 VDPAU 的 backend (libvdpau-va-gl)， 他們有一部份是重疊的。 Company Name First Release Year License Intel VA-API 2007 MIT NVIDIA VDPAU 2009 MIT AMD XvBA vdpau Intel : libvdpau-va-gl AMD : mesa-vdpau NVIDIA : mesa-vdpau # Intel $ sudo pacman -S libvdpau-va-gl 可以裝 vdpauinfo 這個 package 來知道目前這台機器上的 GPU 支援的 features # 裝 vdpauinfo 來看相關資訊 $ sudo pacman -S vdpauinfo # 跑 vdpauinfo 來取得訊息 # 但是在我筆電上 (Intel i5-3210M, HD Graphics 4000) 會出現找不到 shared object 的錯誤 # 感覺算是 bug $ vdpauinfo display: :0 screen: 0 Failed to open VDPAU backend libvdpau_i965.so: cannot open shared object file: No such file or directory Error creating VDPAU device: 1 # 用 VDPAU_DRIVER 這個環境變數來指定 driver 後就正常了 $ env VDPAU_DRIVER = va_gl vdpauinfo display: :0 screen: 0 [ VS ] Software VDPAU backend library initialized libva info: VA-API version 0.37.0 libva info: va_getDriverName () returns 0 libva info: Trying to open /usr/lib/dri/i965_drv_video.so libva info: Found init function __vaDriverInit_0_37 libva info: va_openDriver () returns 0 API version: 1 Information string: OpenGL/VAAPI/libswscale backend for VDPAU Video surface: name width height types ------------------------------------------- 420 1920 1080 NV12 YV12 UYVY YUYV Y8U8V8A8 V8U8Y8A8 422 1920 1080 NV12 YV12 UYVY YUYV Y8U8V8A8 V8U8Y8A8 444 1920 1080 NV12 YV12 UYVY YUYV Y8U8V8A8 V8U8Y8A8 Decoder capabilities: name level macbs width height ---------------------------------------------------- MPEG1 --- not supported --- MPEG2_SIMPLE --- not supported --- MPEG2_MAIN --- not supported --- H264_BASELINE 51 16384 2048 2048 H264_MAIN 51 16384 2048 2048 H264_HIGH 51 16384 2048 2048 VC1_SIMPLE --- not supported --- VC1_MAIN --- not supported --- VC1_ADVANCED --- not supported --- MPEG4_PART2_SP --- not supported --- MPEG4_PART2_ASP --- not supported --- DIVX4_QMOBILE --- not supported --- DIVX4_MOBILE --- not supported --- DIVX4_HOME_THEATER --- not supported --- DIVX4_HD_1080P --- not supported --- DIVX5_QMOBILE --- not supported --- DIVX5_MOBILE --- not supported --- DIVX5_HOME_THEATER --- not supported --- DIVX5_HD_1080P --- not supported --- H264_CONSTRAINED_BASELINE --- not supported --- H264_EXTENDED --- not supported --- H264_PROGRESSIVE_HIGH --- not supported --- H264_CONSTRAINED_HIGH --- not supported --- H264_HIGH_444_PREDICTIVE --- not supported --- Output surface: name width height nat types ---------------------------------------------------- B8G8R8A8 53 53 y R8G8B8A8 0 0 y R10G10B10A2 0 0 y B10G10R10A2 0 0 y A8 0 0 y Bitmap surface: name width height ------------------------------ B8G8R8A8 8192 8192 R8G8B8A8 8192 8192 R10G10B10A2 8192 8192 B10G10R10A2 8192 8192 A8 8192 8192 Video mixer: feature name sup ------------------------------------ DEINTERLACE_TEMPORAL - DEINTERLACE_TEMPORAL_SPATIAL - INVERSE_TELECINE - NOISE_REDUCTION - SHARPNESS - LUMA_KEY - HIGH QUALITY SCALING - L1 - HIGH QUALITY SCALING - L2 - HIGH QUALITY SCALING - L3 - HIGH QUALITY SCALING - L4 - HIGH QUALITY SCALING - L5 - HIGH QUALITY SCALING - L6 - HIGH QUALITY SCALING - L7 - HIGH QUALITY SCALING - L8 - HIGH QUALITY SCALING - L9 - parameter name sup min max ----------------------------------------------------- VIDEO_SURFACE_WIDTH - VIDEO_SURFACE_HEIGHT - CHROMA_TYPE - LAYERS - attribute name sup min max ----------------------------------------------------- BACKGROUND_COLOR - CSC_MATRIX - NOISE_REDUCTION_LEVEL - SHARPNESS_LEVEL - LUMA_KEY_MIN_LUMA - LUMA_KEY_MAX_LUMA - libva $ sudo pacman -S libva $ vainfo # 看硬體解碼支援哪些格式 libva info: VA-API version 0.37.0 libva info: va_getDriverName () returns 0 libva info: Trying to open /usr/lib/dri/i965_drv_video.so libva info: Found init function __vaDriverInit_0_37 libva info: va_openDriver () returns 0 vainfo: VA-API version: 0.37 ( libva 1.5.0 ) vainfo: Driver version: Intel i965 driver for Intel ( R ) Ivybridge Mobile - 1.5.0 vainfo: Supported profile and entrypoints VAProfileMPEG2Simple : VAEntrypointVLD VAProfileMPEG2Simple : VAEntrypointEncSlice VAProfileMPEG2Main : VAEntrypointVLD VAProfileMPEG2Main : VAEntrypointEncSlice VAProfileH264ConstrainedBaseline: VAEntrypointVLD VAProfileH264ConstrainedBaseline: VAEntrypointEncSlice VAProfileH264Main : VAEntrypointVLD VAProfileH264Main : VAEntrypointEncSlice VAProfileH264High : VAEntrypointVLD VAProfileH264High : VAEntrypointEncSlice VAProfileH264StereoHigh : VAEntrypointVLD VAProfileVC1Simple : VAEntrypointVLD VAProfileVC1Main : VAEntrypointVLD VAProfileVC1Advanced : VAEntrypointVLD VAProfileNone : VAEntrypointVideoProc VAProfileJPEGBaseline : VAEntrypointVLD Chromium 原來現在從 package 裡裝到的 chromium 都是沒有開 VAAPI 支援的， 目前好像只有 在 ChromeOS 上會開啟 如果在 chromium 裡面開影片的話會看到 console 上有段資訊 (寫著 \" HW video decode acceleration not available. \") : [5100:5100:0322/052925:ERROR:gpu_video_decode_accelerator.cc(272)] Not implemented reached in void content::GpuVideoDecodeAccelerator::Initialize(media::VideoCodecProfile, IPC::Message*)HW video decode acceleration not available. 官方也寫了 unsupport ... 另外可以在 chromium 裡的 chrome://gpu 看到一些 features 的支援狀況 (但是 video 的 hardware decode acceleration 實際上還是沒開啟 ...) Reference Arch Wiki - VDPAU Arch Wiki - VA-API Wikipedia - VDPAU Wikipedia - Video Acceleration API Wikipedia - X-Video Bitstream Acceleration freedesktop.org - vaapi freedesktop.org - VDPAU Linux Graphics - VAAPI","loc":"/posts/2015/03/linux-video-acceleration/","tags":"Linux"},{"title":"GitHub at NCTU - Here comes GitHub","text":"前陣子看到 訊息 說 GitHub 的人要來臺灣， Ruinland 就在 3/4 寄信去問是否接受社團去接洽去安排活動 (其他好像都是學校或老師去接洽的)， 後來 Mu-An (目前 GitHub 裡唯一的臺灣人) 回信表示社團接洽也樂意前來， 結果 Ruinland 就在大半夜跑到我宿舍跟我說這件事， 於是我就回信談相關細節。 後來才知道原來他們之前有寄信到交大資工的 mailing list 詢問， 可是就 ... 沒下文， 後來還是嘗試幫 GitHub 和系上牽線， 不過最後系上那邊一直橋不隴， 所以就 ... 索性放棄， 不然跟 GitHub 那邊提的活動時間就不能定下來 (系上回信慢，感覺也不是很積極)， 最後活動定在 3/20 (五)， 約了和社團的大家一起去吃個飯再回學校給 Talk。 在信件往來的同時，馬上請了 joyqul 幫忙畫宣傳圖， 於是我們有了精美的宣傳圖啦 ~ OwO// 活動的講師實際上是 John Britton，他說他長期在各個國家間旅遊，沒有固定的住處， 工作也都是遠端的，Airbnb 是他大多時候會住的地方 XD。 Talk 的內容是偏向 Git 的 internal，著重在 .git 裡發生的事情， 之後整理一下發在另外一篇。","loc":"/posts/2015/03/github-at-nctu/","tags":"Misc"},{"title":"Wayland - First Look","text":"去年 (2014) 年底有看了點 Wayland 相關的訊息，蒐集了些東西放在 GitHub 上， 不過一直沒時間繼續研究，希望之後有空能繼續研究 :P GitHub - wdv4758h/wayland-resources","loc":"/posts/2015/03/wayland-first-look/","tags":"Misc"},{"title":"CPython's bug in feature that nobody uses","text":"之前 (2015 二月初) 發現 CPython 3.4 開始支援在 command line 直接用 tarfile 這 module 來處理檔案， 也就是說可以能來當作 Unix-like 平台上常見的 tar 指令的替代品， 其中支援由指定的副檔名來選擇壓縮的演算法 (無、gzip、bz2、lzma)， 但是經過嘗試後發現不管怎麼選都只是單純的 tar file， 後來去翻了一下 CPython source code 發現有地方寫錯了， 只好去開個 issue 送 patch 修正以及補上 test cases， 才知道原來 CPython 的 code review 還是使用 Rietveld ， 這也是我第一次幫 CPython 加 unit test :P [準備要報 PyCon APAC 2015 的 lighting talk，之後會補上 slide]","loc":"/posts/2015/03/cpython-bug-in-feature-that-nobody-uses/","tags":"Python"},{"title":"[留存] Why GNU grep is fast","text":"Why GNU grep is fast (2010) 用 Boyer-Moore (而且做點 loop unroll) 避免在搜尋前複製 input bytes 在 match 之前不找 newlines 看 \"Fast String Searching\" (by Andrew Hume and Daniel Sunday, in the November 1991 issue of Software Practice & Experience) 裡的 Boyer-Moore implementation tricks Try to set things up (page-aligned buffers, page-sized read chunks, optionally use mmap) so the kernel can ALSO avoid copying the byte Wikipedia - Boyer–Moore string search algorithm","loc":"/posts/2015/03/why-gnu-grep-is-fast/","tags":"Misc"},{"title":"HTML5 - Web Storage","text":"以下是放置很久的紀錄，最近整理清出來 (ry Web Storage 是一種可讓網頁將資料儲存於 local 端的技術，純粹運作於 client side，其作用如同 cookie，但空間更大。 它原本是 HTML5 規格的一部份，後來單獨劃為一個規格。 Web Storage 主要分成兩種 : local storage (類似 persistent cookies) session storage (類似 session cookies) Web Storage V.S. Cookies 不同處 Storage size Web storage 可存的 size 遠大於 cookies Client-side interface Cookies 在 server 和 client 端都可以 access，但 Web Storage 只在 client 端 Web Storage 的資料不會在每次 HTTP request 的時候都傳送過去，web server 也不能直接寫入 Web Storage (但這些都可以由 client-side scripts 達到) Local and session storage local storage 和 session storage 的差別在於 scope 和 lifetime local storage 是用 來源 (Same-origin policy) 分的 (size 也是用這個方式分開來算的)，在 browser 關掉之後仍會持續存在 session storage 是 per-page-per-window，lifetime 限制在那個 window，關掉後就沒了 Session storage is intended to allow separate instances of the same web application to run in different windows without interfering with each other, a use case that's not well supported by cookies 性質 local storage session storage lifetime browser 關掉仍會存在 windows/分頁 關掉後就沒了 scop 可跨分頁 (用 origin 分) 不可跨分頁 Interface and data model Web storage 提供比 cookies 更好的 programmatic interface，使用了 associative array data model (keys 和 values 都是 strings) Web Storage Usage 支援 Web Storage 的 browsers 會有 sessionStorage 和 localStorage 這兩個 global variables，可以使用 Javascript 來操作 sessionStorage // Store value on browser for duration of the session sessionStorage . setItem ( 'key' , 'value' ); // Retrieve value (gets deleted when browser is closed and re-opened) alert ( sessionStorage . getItem ( 'key' )); localStorage // Store value on the browser beyond the duration of the session localStorage . setItem ( 'key' , 'value' ); // Retrieve value (persists even after closing and re-opening the browser) alert ( localStorage . getItem ( 'key' )); Accessing data for the currently browsed domain 以下是取得目前 domain 的所有在 local storage 裡的 data 的範例 code var output = \"LOCALSTORAGE DATA:\\n------------------------------------\\n\" ; if ( window . localStorage ) { if ( localStorage . length ) { for ( var i = 0 ; i < localStorage . length ; i ++ ) { output += localStorage . key ( i ) + ': ' + localStorage . getItem ( localStorage . key ( i )) + '\\n' ; } } else { output += 'There is no data stored for this domain.' ; } } else { output += 'Your browser does not support local storage.' } console . log ( output ); Data types 只有 strings 可以透過 Storage API 儲存進去，在多數的 browser 裡，如果要嘗試存入非 string 的 data type，會自動轉為 string // Store an object instead of a string localStorage . setItem ( 'key' , { name : 'value' }); alert ( typeof localStorage . getItem ( 'key' )); // string // Store an integer instead of a string localStorage . setItem ( 'key' , 1 ); alert ( typeof localStorage . getItem ( 'key' )); // string // Store an object using JSON localStorage . setItem ( 'key' , JSON . stringify ({ name : 'value' })); alert ( JSON . parse ( localStorage . getItem ( 'key' )). name ); // value DOM Storage Web Storage 也常被稱為 DOM storage (這裡指的不是 Document Object Model) According to the W3C, \"The term DOM is used to refer to the API set made available to scripts in Web applications, and does not necessarily imply the existence of an actual Document object...\" Web Storage Management Local Storage Firefox 會把所有 web storage objects 存入一個叫作 webappsstore.sqlite 的 sqlite 檔案 (可以用 sqlite3 的 command 去看)， 例如 : ~/.mozilla/firefox/XXX/webappsstore.sqlite ， column 裡會有 reversed hostname 和 protocol $ sqlite3 webappsstore.sqlite sqlite> . tables webappsstore2 sqlite> . schema CREATE TABLE webappsstore2 (scope TEXT, key TEXT, value TEXT, secure INTEGER, owner TEXT); CREATE UNIQUE INDEX scope_key_index ON webappsstore2(scope, key); sqlite> select * from webappsstore2 ; moc.elpmaxe.www.:http:80|stringkey|value|0| moc.elpmaxe.www.:http:80|jsonkey|{\"key\",\"value\"}|0| sqlite> . exit Chrome 把這個 sqlite 的 file 依照 hostname 和 protocol 分開來 Chromium 的路徑 : ~/.config/chromium/Default/Local Storage/ Session Storage 因為 session storage 在重開之後就會被清掉，所以不需要存進 database Firefox 還是會把它寫入 disk 來提供目前 session 的 restore (主要用於 recover from crashes)， 這個檔案是一個 JSON file 在 ~/.mozilla/firefox/XXX/sessionstore.js ， 裡面有個 key 叫 storage ，它的 value 是 URLs 和 sessionStorage data 的對應 Reference Web Storage - Wikipedia HTML5 Web Storage Web Storage 使用經驗 The Past, Present & Future of Local Storage for web applications HTML5 功能 - 儲存 - HTML5 Rocks DOM Storage guide How is HTML5 WebStorage data physically stored? Where does Firefox store javascript/HTML localStorage? Web Storage - W3C","loc":"/posts/2015/03/html5-web-storage/","tags":"HTML5"},{"title":"Python Benchmark for Interpreter","text":"Introduction 什麼是 benchmark ? benchmark 就是用幾個固定項目來測量不同程式的效率， 取得測量出來的數值後互相做比較， 藉此來做優劣分析，但是這作法其實是蠻粗糙的。 benchmark 這種作法一直都有人在用 (也常會被拿來說嘴)， 雖然一個程式的效率不能就這麼用 benchmark 跑出來的數字來輕易評斷， 但還是能獲得些許的資訊，或者找到進步的空間。 以下會說明幾個拿來評量 Python interpreter 的 benchmark。 實作介紹 CPython Python 官方實作， 中規中矩， garbage collection 採用 reference counting。 PyPy JIT 版本實作， garbage collection 為 incremental generational tracing， 內部 data structure 有做過改良。 Nuitka 不是一個 Python interpreter 實作， 而是把 Python code compile 成單一的執行檔， 不過這樣一來也就損失了很多 Python 的特性。 Hello World Background 沒什麼特別的，就是一個簡單的 Hello World， 目的是要測 interpreter 的 startup time， 在此項目中 startup time 愈小愈好。 Result Test: CPython 2.7.9 0.01 ~ 0.03 s CPython 3.4.2 0.02 ~ 0.04 s PyPy 2.5 (Python 2.7.8) 0.10 ~ 0.12 s PyPy3 2.4 (Python 3.2.5) 0.06 ~ 0.07 s Nuitka compile 0.5.9 (Python 2.7) 0.01 ~ 0.02 s Nuitka compile 0.5.9 (Python 3.4) 0.06 ~ 0.08 s PyStone Background PyStone 是 CPython 裡面一個非常 high-level 的 benchmark (CPython lib/test/pystone.py ， 拿不同的實作跑下去會拿到各自的 PyStone，代表著整體的效能分數， 愈多的 PyStone 愈好。 Result 在這個項目中，PyPy JIT 的優勢大幅顯現，隨著 loop 量的上升，差距也跟著拉大。 Test: (50000 passes) CPython 2.7.9 59814 pystones/second CPython 3.4.2 46957 pystones/second PyPy 2.5 (Python 2.7.8) 570821 pystones/second PyPy3 2.4 (Python 3.2.5) 475670 pystones/second Nuitka compile 0.5.9 (Python 2.7) 188474 pystones/second Nuitka compile 0.5.9 (Python 3.4) 94807 pystones/second Test: (1000000 passes) CPython 2.7.9 56851.8 pystones/second CPython 3.4.2 46869.8 pystones/second PyPy 2.5 (Python 2.7.8) 1.88367e+06 pystones/second PyPy3 2.4 (Python 3.2.5) 1.54948e+06 pystones/second Nuitka compile 0.5.9 (Python 2.7) 186711 pystones/second Nuitka compile 0.5.9 (Python 3.4) 103947 pystones/second PyBench 2.0 Background PyBench 是 CPython 裡的 low-level benchmarks (CPython Tools/pybench )， PyStone 用來衡量整體效能， PyBench 用來衡量特定細項的效能。 Richards Background 和 PyStone 類似， 是 PyPy 裡的 high-level benchmark (原版本是由 Dr. Martin Richards 在 Cambridge University 用 BCPL 寫的) (PyPy rpython/translator/goal/richards.py )， 一樣給出單一的值來衡量 (Average time per iteration)， 愈低的 \"Average time per iteration\" 愈好。 Result CPython 2.7.9 382.70 ms CPython 3.4.2 437.50 ms PyPy 2.5 (Python 2.7.8) 49.66 ms PyPy3 2.4 (Python 3.2.5) 58.72 ms Nuitka compile 0.5.9 (Python 2.7) 178.72 ms Nuitka compile 0.5.9 (Python 3.4) 261.62 ms 總結 Nuitka 把 Python 轉成 C++ 然後 compile， 雖然可以得到效能提升，但是缺失去很多 Python 的特質， 雖然小 script 在處理過後可以得到小小的執行檔， 但如果是一個大專案的話， compile 出來的結果可能就會很大 (先別提是否能好好處理)， 這樣相對之下選用原本 interpreter 的方式可能還會好一些， 而且如此一來，在更改 Python 專案時也需要不斷重新 compile， 失去了一些方便性， 如果別人要把 compile 過的 Python code import 進去來用又是另外一個問題， 但不可否認，對於一個小 script 且又有 performance 和 memory 考量下， 目前可能是個選擇。 若是單純講究 performance 的話， PyPy 的可能性會大很多， 保留原本 Python 的特質， 還有 JIT 加持， 又有更好的 garbage collection 支援， 一些 data structure 也有做過改良， 雖然 PyPy 的成熟度已經愈來愈高了， 但是還是會有地方需要改進， 若發現有比原本 CPython 慢的地方可以回報， PyPy developer 會找到問題點然後解決 (有時是 project code 需要小改進，讓 JIT 可以幫上忙)， 而且 PyPy 還有很多更 advanced 的 interpreter features 正在實驗， 評估效能和整體架構下，可看性最高。 不過這邊的 benchmark 都只是一個粗略衡量， 還是要像 speed.pypy.org 一樣拿一些實際在用的 project 來跑， 可看性會比較高。 Reference CPython benchmark suite IronPython Performance Report Wikipedia - IronPython Wikipedia - Jython Wikipedia - Dynamic Language Runtime Wikipedia - Common Language Infrastructure Wikipedia - Cython","loc":"/posts/2015/02/python-benchmark-for-interpreter/","tags":"Python"},{"title":"PyPy - Tutorial for Brainfuck Interpreter","text":"Introduction Python 是一個 Dynamic Language， 官方提供了一個叫作 CPython 的 Interpreter 實作， Interpreter 讓這類 Dynamic Language 不用事先 compile 過才可以執行， 只要寫好 script 後丟進去就可以跑， 以下有 Compiler 和 Interpreter 簡陋的流程圖 : Compiler : Interpreter : CPython 的實作只維持在很標準的方式， 相較之下並沒有花費大量的努力往更好的效能去調整， 一來應該是商業公司投資的資源量不夠， 再來應該是人力也不夠。 雖然在 2009 年一度從 Google 發起一個叫作 Unladen Swallow 的 project， 目標是在 CPython 上利用 LLVM 做 just-in-time compiler， 不過最後在 2009 年底就漸漸中斷，目前只留下一個沒在開發的 branch。 目前幾個針對效能的實作中，Cython 和 PyPy 是最成熟可行的選項， Cython 是一個 Python 的 superset， 利用 Cython 提供的靜態型別宣告以及其他功能來修改程式， 最後經過 compile 後可以讓程式變得相當快速， 而 PyPy 則是一個 Drop-In Replacement 的實作， PyPy 的效能來自於 JIT、更有效率 Garbage Collection、更有效率的 Data Structure。 近期倒是有由 Dropbox 發起的新實作叫 Pysyon ， 目標是 based on LLVM 做一個有效率的 JIT 實作， 由於是個新專案，目前 release 只有到 0.2 版， 有 Dropbox 企業的金錢、人力資助下， 只要這專案持續下去，相信出來的效能是會蠻有看頭的， 不過專案目前還在早期開發中，就靜觀其變囉。 Tutorial PyPy 的官方 Blog 上， 在 2011 年發了兩篇由 Andrew Brown 撰寫用 PyPy 來實作 Brainfuck Interpreter 的 Tutorial， 時至今日，已經來到了 2015 年，中間也經過了許多 release， 接下來將會以 PyPy 2.5 為試驗目標， 更新一些舊 Tutorial 上需要改變的地方，並且和其他實作做初步比較。 (本練習的 code 會放在 GitHub wdv4758h/brainfuck_bench ) Tutorial: Writing an Interpreter with PyPy, Part 1 Tutorial Part 2: Adding a JIT PyPy 這個專案其實有兩個角色 Python 的 Interpreter 實作 撰寫 Dynamic Languages 的 Interpreter 的 framework \"Interpreter 的 framework\" 是 PyPy 這 project 最特別的地方， 接下來這篇的重點將會放在 \"撰寫 Interpreter\" 要做一個 Language 的 Interpreter 會需要以下事情 source code parser a bytecode interpretation loop lots of standard library code 對於稍微複雜一點點的語言，實作這些這會需要不少的時間， 更別提中間還得考慮 Memory 管理、Data Type 的實作， 會有許多的東西需要煩惱。 如果可以用一個高階一點的語言來實作，那前面提到的事情就可以大幅化簡， 可以利用到一些高階語言的特色， 像是不用自己考慮記 Memory 管理、有好用的 Data Type 等， 但是講到這，想必有人就會想到這個實作的速度應該會 \"很慢\"， 在高階語言上在建一層來實作自己的語言， 速度會比原本可能就不快的高階語言還來的更慢， 所以 PyPy 就是來解決這部份的問題啦。 利用 PyPy 來寫 Interpreter 的話，要用的是一個叫作 RPython 的語言， 看名字就知道跟 Python 有關，RPython 全名叫 Restricted Python， 是一個 Python 的 subset，既然是 subset 也就代表寫出來的還是一個 Python 程式， 但是 RPython 的特點是它的 type 是 inferable 的， 所以雖然一樣不寫出 type，但是可以做到 statically typed， 而 PyPy 的 RPython toolchain 會把 RPython 的 code 轉成 C code 再丟給 GCC 或 Clang 這類 C compiler 來 compile 成 native code， 藉此你可以獲得 native code 的 interpreter，所以會跑的比原本疊在 interpreter 上的 interpreter 來的快， 在這當中 PyPy 還可以幫你處理 Garbage Collecion 和 JIT。 關於 RPython 的內容，有興趣的話可以看 2007 年 \" RPython: a Step Towards Reconciling Dynamically and Statically Typed OO Languages \" 這篇 paper 裡的內容 (Bibtex key : AACM-DLS07)， 或是這邊有 slide 版本 。 關於 PyPy 裡面用到的 JIT 技術可以看這篇 (2012) PyPy JIT under the hood 當作入門。 Brainfuck Interpreter - Begin Brainfuck spec : > 指標加一 < 指標減一 + 指標指向的 byte 的值加一 - 指標指向的 byte 的值減一 . 輸出指標指向的 byte (ASCII) , 輸入到指標指向的 byte (ASCII) [ 如果指標指向的 byte 為零，向後跳到對應的 ] 指令的下一指令 ] 如果指標指向的 byte 不為零，向前跳到對應的 [ 指令的下一指令 Brainfuck to C (assuming \"ptr\" is of type \"unsigned char*\") : brainfuck command C equivalent (Program Start) char array [ infinitely large size ] = { 0 }; char * ptr = array ; > ++ ptr ; < -- ptr ; + ++* ptr ; - --* ptr ; . putchar ( * ptr ); , * ptr = getchar (); [ while ( * ptr ) { ] } 另外任何不在 Brainfuck spec 裡的東西都會被忽略 以下我們開始做 Brainfuck Interpreter 首先先做 parser 還有 main loop : (以下 code 大部份來自官方 Tutorial 的 example 1) #!/usr/bin/env python # -*- coding: utf-8 -*- import sys class Tape ( object ): \"\"\" 因為 Brainfuck 的 code 就像是在 Tape 上操作一樣， 所以有這個 class 來處理所有 action \"\"\" def __init__ ( self ): self . thetape = [ 0 ] self . position = 0 def get ( self ): return self . thetape [ self . position ] def set ( self , val ): self . thetape [ self . position ] = val def inc ( self ): self . thetape [ self . position ] += 1 def dec ( self ): self . thetape [ self . position ] -= 1 def advance ( self ): self . position += 1 if len ( self . thetape ) <= self . position : self . thetape . append ( 0 ) def devance ( self ): self . position -= 1 def main_loop ( program , bracket_map ): pc = 0 tape = Tape () while pc < len ( program ): code = program [ pc ] if code == '>' : tape . advance () elif code == '<' : tape . devance () elif code == '+' : tape . inc () elif code == '-' : tape . dec () elif code == '.' : # print sys . stdout . write ( chr ( tape . get ())) elif code == ',' : # read from stdin tape . set ( ord ( sys . stdin . read ( 1 ))) elif code == '[' and tape . get () == 0 : # Skip forward to the matching ] pc = bracket_map [ pc ] elif code == ']' and tape . get () != 0 : # Skip back to the matching [ pc = bracket_map [ pc ] pc += 1 def parse ( program ): parsed = [] bracket_map = {} leftstack = [] pc = 0 for char in program : if char in ( '[' , ']' , '<' , '>' , '+' , '-' , ',' , '.' ): parsed . append ( char ) if char == '[' : leftstack . append ( pc ) elif char == ']' : left = leftstack . pop () right = pc bracket_map [ left ] = right bracket_map [ right ] = left pc += 1 return '' . join ( parsed ), bracket_map def run ( input_file ): with open ( input_file , 'r' ) as f : program , bracket_map = parse ( f . read ()) main_loop ( program , bracket_map ) if __name__ == \"__main__\" : run ( sys . argv [ 1 ]) PyPy Translation 在 PyPy repo 的 pypy/rpython/translator/goal/ 裡有一些範例， 其中 targetnopstandalone.py 是簡單的 Hello World 在這邊，我們需要一個叫做 target 的 function， 它會回傳另一個 function 作為 entry point， PyPy 翻譯時會先找叫作 target 的 function， call 它後從它回傳的 function 開始翻譯， 而最後產生的執行檔在執行時傳入的參數也是給這個回傳的 function def run ( input_file ): with open ( input_file , 'r' ) as f : program , bracket_map = parse ( f . read ()) main_loop ( program , bracket_map ) def entry_point ( argv ): if len ( argv ) > 1 : filename = argv [ 1 ] else : print ( \"You must supply a filename\" ) return 1 run ( filename ) return 0 def target ( * args ): return entry_point if __name__ == \"__main__\" : entry_point ( sys . argv ) 此外還有一個部份需要修改，就是用到 sys module 裡的 stdin/stdout 的部份， 因為目前 RPython 並沒有支援 sys.stdin 和 sys.stdout (雖然開發者說其實可以用 os.read 和 os.write 包裝) 所以需要改成用 os.read 和 os.write import os # sys.stdout.write(chr(tape.get())) os . write ( 1 , chr ( tape . get ())) # 1 for stdout # tape.set(ord(sys.stdin.read(1))) data = os . read ( 0 , 1 ) # 0 for stdin, 1 for one byte if data != '' : tape . set ( ord ( data [ 0 ])) 接下來需要抓 PyPy 的 source code : hg clone https://bitbucket.org/pypy/pypy 接下來就交給 PyPy 做轉換 pypy/rpython/bin/rpython example2.py 然後就會看到許多 PyPy 吐出來的訊息，最後產生 example2-c 這個執行檔， 這個轉換在我機器 (虛擬機) 上大約需要 4x ~ 5x 秒 結果 : File Size 290552 bytes Translation Time 56.5 s Test File Execution Time mandel.b 68.61 s 接著試跑一下 ./example2-c mandel.b Bash 裡有自己的 time command 可以看執行時間， 但是如果要更多資訊的話 (-v)，需要 GNU 版的 time command sudo pacman -S time time -v ./example2-c mandel.b 以上是成功的利用 RPython 寫了 Brainfuck Interpreter 交給 PyPy 的 RPython toolchain 轉成 machine code ~ 複習一下，要可以給 PyPy 的 RPython toolchain 轉換需要以下條件 符合 RPython 語法、功能 有 target 這個 function 回傳進入的 function 如果想看更多 translate 時可以開的優化參數的話可以看 這裡 Compile with Clang 參數 : --cc=clang More Jobs 參數 : --make-jobs=8 (針對 C backend compile 時的 -j 參數) Garbage Collection 參數 : --gc=incminimark 目前可用的選項 : boehm ref (default) semispace statistics generation hybrid minimark incminimark none Brainfuck Interpreter - JIT 前面試過了利用 PyPy 的 RPython toolchain 幫我們把 RPython code 轉成 C 去 compile， 接下來是利用 PyPy 幫我們做 JIT 出來， 感謝 PyPy 開發者的努力，我們要在 RPython 上做出 JIT 並不難， 因為 PyPy 的 JIT generator 有幾個目標 : 簡單 (基於原本的 Interpreter 上，只要做少許修改就能有 JIT) Maintainable (不會因為加了 JIT 就造成需要開另外的 project 分別 maintain) 夠快 (雖然 JIT 是生出來的，但是也要速度也要夠快) 在這目標下，就算是沒有大量人力、金錢贊助的語言，也能簡單做出不錯的 JIT， 下面就讓我們來嘗試一下 ~ (詳細訊息請看 RPython Documentation - JIT ) 要讓 PyPy 的 RPython toolchain 生出 JIT 需要提供一些資訊給它， 首先是告訴它哪些東西構成一個 execution frame， 在我們的 Brainfuck Interpreter 中並沒有真的 stack frame， 這問題就變成在執行一個 command 的時候， 哪些東西是不變的，哪些是會變的， 不變的被稱做 \" green \"，會變的稱做 \" red \"， 在我們的例子中，green 有 \"pc\"、\"program\"、\"brakcet_map\"， red 有 \"tape\"， 接著就從 rpython.rlib.jit 取得 JitDriver 這個 metaclass 來生出我們需要要的 class from rpython.rlib.jit import JitDriver jitdriver = JitDriver ( greens = [ 'pc' , 'program' , 'bracket_map' ], reds = [ 'tape' ]) 然後在 main loop 裡的 while 開頭 call jit_merge_point jitdriver . jit_merge_point ( pc = pc , tape = tape , program = program , bracket_map = bracket_map ) 接下來轉換的時候多加一個 --opt=jit 參數 pypy/rpython/bin/rpython --opt = jit example3.py 總結需要做的事 : import JitDriver 進來，把 green 和 red 變數分好 在 main loop 裡 while 一開始的地方 call jit_merge_point 把變數傳進去 translate 的時候加上 --opt=jit 參數 開 JIT 參數後，轉換的時間就變長，檔案也變大，但是跑下去就快很多 結果 : File Size 5954320 bytes Translation Time 977.4 s Test File Execution Time mandel.b 27.64 s 沒改很多 code，只做了 import 和寫幾行去 call import 進來的東西， 時間從 68.61 s 變 27.64 s (不過還是很慢) 附上轉換時的圖 XD 註 : 以前還需要寫一個 jitpolicy function， 但是現在已經是 default 了 (看 rpython/translator/driver.py )， 所以不用寫 def jitpolicy ( driver ): from rpython.jit.codewriter.policy import JitPolicy return JitPolicy () Tracing JIT 在試完生出的 JIT 的速度後， 來了解一下它是怎麼運作的。 Interpreter 執行的是我們寫的 interpreter code， 當發現 target laugange (Brainfuck) 寫的某段 code 很常跑時， 會把這部份標成 \"Hot\"，並且會做追蹤，當下一次進到這個循環的時候， interpreter 會進入 tracing mode，把每個指令紀錄下來，循環結束後， tracing mode 就停止，把追蹤紀錄丟給 optimizer， 接著丟給 assembler，產生 machine code 在之後執行時使用。 基於對原本 interpreter 的一些 assumption， 生出的 machine code 通常會對很多地方進行優化， 因此生出的 machine code 會包含一些 guard 做驗證， 驗證失敗的話就退回去使用原本 interpreter 的 code。 Debug and Trace Log 雖然前面已經生出了不錯的結果， 但是總是會想要知道還能不能更好， 所以我們需要知道 JIT 做了些什麼事， 接下來就寫一個紀錄用的 function (參數是前面提過的 green 變數) 並傳給 jitdriver def get_location ( pc , program , bracket_map ): return \" %s _ %s _ %s \" % ( program [: pc ], program [ pc ], program [ pc + 1 :] ) jitdriver = JitDriver ( greens = [ 'pc' , 'program' , 'bracket_map' ], reds = [ 'tape' ], get_printable_location = get_location ) 用跟前面一樣的方式轉換 : pypy/rpython/bin/rpython --opt = jit example4.py 接下來跑程式的時候先加環境變數來把操作寫進 log PYPYLOG = jit-log-opt:logfile ./example4-c test.b 這 log 可以看出有哪些部份被轉成了 machine code， 這在尋找有那邊可以優化的時候很有用 每個 trace 的開頭都是像這樣 [3c091099e7a4a7] {jit-log-opt-loop 結尾都是像這樣 [3c091099eae17d] jit-log-opt-loop} 中間則是每次執行的操作，有些操作如果被優化掉的話就不會出現 Optimize elidable (old : purefunction) 由於每次的 loop 都會去 dictionary 裡查對應的位址， 但是其實這個 dictionary 裡的資訊是不會變的， 所以是可以直接編成 machine code 來加速， 但是對 PyPy 而言，那個 dictionary 有可能會變動， 但它不知道其實資料不會再改了， 所以我們可以告訴它同樣的輸入一定會有相同的輸出， 這可以用 PyPy 裡的 elidable (以前是 purefunction ) decorator 做告知 from rpython.rlib.jit import elidable @elidable def get_matching_bracket ( bracket_map , pc ): return bracket_map [ pc ] # 下面把查 bracket_map 的地方換掉 接下來跟前面一樣做轉換，最後拿到的程式就比原本快很多 File Size 5852352 bytes Translation Time 960.2 s Test File Execution Time mandel.b 9.58 s 結果從 27.64 s 降到了 9.58 s Delay Output 對電腦來說 I/O 是很慢的，所以原本每個 byte 這樣讀讀寫寫也會有一點效能損失， 所以可以把直先存起來，之後再一次 output， 對於有大量 output 的 brainfuck 程式可能可以有一點點的幫助 (不多) class Tape ( object ): def __init__ ( self ): self . thetape = [ 0 ] self . position = 0 self . output = '' self . output_threshold = 50 def get ( self ): return self . thetape [ self . position ] def set ( self , val ): self . thetape [ self . position ] = val def inc ( self ): self . thetape [ self . position ] += 1 def dec ( self ): self . thetape [ self . position ] -= 1 def advance ( self ): self . position += 1 if len ( self . thetape ) <= self . position : self . thetape . append ( 0 ) def devance ( self ): self . position -= 1 def clear ( self ): if self . output : os . write ( 1 , self . output ) # 1 for stdout self . output = '' def read ( self ): self . clear () data = os . read ( 0 , 1 ) # 0 for stdin, 1 for one byte if data : self . set ( ord ( data [ 0 ])) def write ( self ): self . output += chr ( self . get ()) if len ( self . output ) > self . output_threshold : os . write ( 1 , self . output ) # 1 for stdout self . output = '' Zero Brainfuck code 裡面的 \"[-]\" 這樣的 loop 其實就是把目前指到的值歸零， 所以可以直接把它 assign 成零，不要再慢慢減了， 這樣換掉後可以有些許的提升 Compact Brainfuck 的 code 裡面常常會出現連續的 \"+\" 或 \"-\" 或 \"<\" 或 \">\"， 但是這是可以一次完成的 (連續的 \">\"、\"<\" 都可以和起來，\"+\"、\"-\" 也可以)， 不需要一個一個慢慢加、一個一個慢慢移， 所以如果把這部份處理掉， 做更有效率的計算， 可以獲得一部份的效能提升 ~ 總結 這個 Tutorial 做的只是簡單的 Brainfuck Interpreter， 離真正實用的語言的 interpreter 還有很大的差距， 但這邊可以讓我們看出在還沒化很多心力下去調整效能前， 例用 RPython 提供給我們的 toolchain 是可以簡單獲得不錯的效益的， 當然事實上是還有很多可以調整的空間， 不過已經讓我們跨出例用 RPython toolchain 的第一步了 ~ 這整個流程試下來，覺得有很多地方看到是可以做的更好的， 像是 RPython 可以做到更完善的支援， 這樣寫起來會更順利， 還有 toolchain 轉換的時間也可能再降低， 出來的 code size 可能也可以更小， 速度也可能更快， 背後 backend 也可能更多樣 (LLVM backend 好像碰到一些障礙要先幫 LLVM 上 patch 才能接起來？)， 諸如此類的問題， 總結一個問題就是 ... 缺錢， 就像是 StackOverflow 上 這篇 的答案一樣 ... What blocks Ruby, Python to get Javascript V8 speed? Nothing. Well, okay: money. (And time, people, resources, but if you have money, you can buy those.) 不過 PyPy 做到現在也算是個有特色的專案了， 不僅僅是一個 Python 的實作， 而有了一個完整的 toolchain， 而且包含幫忙處理 GC 和 JIT， 這樣的專案和成熟度， 目前應該找不到相似對手 (從 這篇 StackOverflow 的回答 也可以看出還沒有類似的成熟專案)， 無論數年後這專案走向如何， 當中累積的技術都將為未來奠定基礎。 最後複習整個流程 : 用 RPython 寫你的 Interpreter (需要有 target function) 針對 main loop 把變數分類、call JIT 的 Driver class 丟下去 toolchain 轉換 效能還不夠時，找出不會變得地方用 \" elidable \" decorator 做告知 額外紀錄 with statement in RPython 在寫 example 的時候，我開檔案那邊用的是 with statement 來幫我 handle， 結果發現丟下去轉換的時候不會過，去 PyPy irc 問了後， 發現其實 RPython 是有支援 with statement 的， 只是近期在 RPython 對檔案的部份有了 rpython/rlib/rfile.py 這個實作， 在 RPython 裡 built-in 的 open() 回傳的是這個 RFile class 的 instance， RPython 的 RFile 實作的是完整的 Python files 的 subset， 但目前沒有寫 __enter__ 和 __exit__ methods， 過沒多久開發者 Armin Rigo 就送了 一個 commit 補上了這部份， 于是乎，我可以繼續用 with statement 丟下去給 PyPy 轉了 ~ RPython's print statement RPython 裡面其實是有支援 print statement 的， 但是那大多只用於 debug， 多數情況都用 os.read / os.write， 不過其實可以用類似 \"os.fdopen(1)\" 的方法來拿到 stdout (不過要在 RPython function 裡，而不是 module global)， 所以其實可以做到當我在 RPython 用 sys.stdout 時其實後面是 call rfile.py 裡面類似 getstdout() 的 function， 它會取得並且 cache 用 os.fdopen() 取得的 rfile。 畢竟 RPython 是要拿來寫 interpreter 的， 有 os module 可以用來 I/O 其實也很夠， 只是如果有 sys.stdout / sys.stdin 的支援對很多地方會更方便些， 不過 PyPy team 應該也是缺錢缺人手， 這也不算是核心大問題， 暫時就先這樣吧，等看看哪天有人 contribute XD Comple with Clang 雖然前面有提到可以用 --cc=clang 來用 clang compile， 但其實我在試的時候有出現問題， 不過到 irc 上尋問後得到了解法， 就是加上 --gcrootfinder=shadowstack ， 以下是 Armin Rigo 的回覆 I guess clang produces subtly different assembler that throws off \"trackgcroot\" you can use --gcrootfinder=shadowstack that will be slightly slower (~10% and only before jit-compilation) (trackgcroot is a hack used with --gcrootfinder=asmgcc, which is enabled only on Linux; usually we have to fix it slightly for every new version of gcc...) if ... elif 在翻參數的時候，發現有個優化參數叫作 merge_if_blocks ， 顧名思義就是把 Python 多層的 if ... elif block 合成 C 裡 switch 的形式， 可以看 documentation 裡的說明 裡面有示意圖 XD string replace RPython 裡的 str 目前只支援 char 的 replace， 但是可以從 rpython/rlib/rstring.py 裡找到 replace function 來替代， from rpython.rlib.rstring import replace ， replace(string, old, new, max) 以下是 irc 上詢問得到得回答 wdv| any reason that RPython's string replace only works for char args ? ronan| wdv: no very good reasons ronan| wdv: it would be a bit of work to implement and interpreters are usually better off writing their own replace at a low level cfbolz| ronan, wdv: there is even a usable implementation, in rlib.rstring, I think rpython/rlib/jit.py 由於在看前面的 rpython/rlib/rstring.py 裡的 replace function 時， 發現上面有一些 decorator，其中一個是 jit.elidable ， 覺得好奇就去翻了一下，不翻還好， 億翻發現就 tutorial 上寫的 purefunction 已經 deprecated 了 XD， 現在要用剛剛看到的 \" elidable \"， 趕快來改一下 ~ Embedding PyPy 在 irc 上問問題的時候，剛好看到前面有人問了 libpypy-c.so 是幹嘛用的， 原來是近期 PyPy 提供的功能，可以把 PyPy 嵌入其他地方， 官方 Document 有寫了簡單的 C 範例，include \"PyPy.h\" 後， 把在 C 程式裡的 Python code char array 丟進去執行， 甚至可以把丟參數給 Python 端的 function， 提供了未來把 PyPy 嵌入別的地方的機會 ~ 附上 irc log : mstuchli| This is prolly a stupid question, but the libpypy-c.so is a new thing, correct? What's it for? fijal| mstuchli: for embedding arigato| mstuchli: for embedding pypy into some other program, more precisely; now the \"pypy\" executable is very small and just calls libpypy-c.so, but other programs may call it too Reference Wikipedia - Just-in-time compilation Wikipedia - Tracing just-in-time compilation Wikipedia - Interpreter (computing) Wikipedia - Unladen Swallow PyPy: Dynamic Language Compilation Framework Ryan Kelly: PyPy.js: What? How? Why? The Architecture of Open Source Applications - PyPy (2013) (video) [jserv] PyPy 簡介 brainfuck optimization strategies 打造 Brainfuck 的 JIT compiler 透過 LLVM 打造 Brainfuck JIT compiler Optimizing brainfuck compiler Brainfuck Interpreter Tracing the Meta-Level: PyPy's Tracing JIT Compiler Carl Friedrich Bolz's site RPython: a Step Towards Reconciling Dynamically and Statically Typed OO Languages PyPy's Approach to Virtual Machine Construction","loc":"/posts/2015/01/pypy-tutorial-for-brainfuck-interpreter/","tags":"Python"},{"title":"Celery - Distributed Task Queue","text":"試到一半的 Celery ~\"~ (未來會繼續) Introduction simple, flexible and reliable distributed system to process vast amounts of messages task queue with focus on real-time processing, while also supporting task scheduling BSD license Tutorial Choosing a Broker Broker 的功能是收發 messages，這邊通常會用專門的 message broker 來處理， 例如 : RabbitMQ feature-complete stable durable excellent choice for a production environment Redis feature-complete more susceptible to data loss in the event of abrupt termination or power failures Database 不推薦拿 database 來當 message queue 但對於小需求可能就足夠 Other Brokers Amazon SQS MongoDB IronMQ Broker Overview : (2015-01-27) Name Status Monitoring Remote Control RabbitMQ Stable Yes Yes Redis Stable Yes Yes Mongo DB Experimental Yes Yes Beanstalk Experimental No No Amazon SQS Experimental No No Couch DB Experimental No No Zookeeper Experimental No No Django DB Experimental No No SQLAlchemy Experimental No No Iron MQ 3rd party No No command on Arch Linux : yaourt -S rabbitmq sudo systemctl start rabbitmq 安裝 Celery 要裝 Celery 沒有什麼特別的，用 pip 就可以裝， 通常再搭配上 virtualenv 做隔離 command : pip install celery Application Celery 裝完後要做的就是先建立一個 Celery instance (Celery application)， 這個 instance 會是所有要交給 Celery 完成的事的 entry-point， 所以要讓各 modules 都可以 import # proj/celery.py from celery import Celery app = Celery ( 'proj' , broker = 'amqp://localhost:5672' , # 沒寫 port 的話會自動找 5672 port backend = 'amqp://' , include = [ 'proj.tasks' ]) # include 裡面是要跑的 tasks # Optional configuration, see the application user guide. app . conf . update ( CELERY_TASK_RESULT_EXPIRES = 3600 , ) if __name__ == '__main__' : app . start () 寫完 instance 後，可以開始給 task 了 # proj/tasks.py from proj.celery import app @app.task def add ( x , y ): return x + y @app.task def mul ( x , y ): return x * y @app.task def xsum ( numbers ): return sum ( numbers ) 啟動 Celery 接下來可以用 command 啟動 celery # celery -A ${app instance} worker -l info # 如果 -A 後面接的 folder 的話，會去找裡面的 celery.py # 等同於 \"celery -A proj.celery worker -l info\" # 如果在 proj 底下的 app instance 檔案叫 mycelery.py 的話 # command 就變成 \"celery -A proj.mycelery worker -l info\" celery -A proj worker -l info # More Help celery worker --help celery help 啟動畫面 : -------------- celery@linux-dv v3.1.17 (Cipater) ---- **** ----- --- * *** * -- Linux-3.17.3-1-ARCH-x86_64-with-arch -- * - **** --- 1. ** ---------- [config] 2. ** ---------- .> app: __main__:0x7fc92f14e0f0 3. ** ---------- .> transport: amqp://guest:**@localhost:5672// 4. ** ---------- .> results: amqp:// 5. *** --- * --- .> concurrency: 8 (prefork) -- ******* ---- --- ***** ----- [queues] -------------- .> celery exchange=celery(direct) key=celery [tasks] . proj.task.add . proj.task.mul . proj.task.xsum 開始丟 Task from proj.tasks import add add ( 4 , 5 ) # 直接 call 不換產生 task 給 Celery，而是會直接做 add . delay ( 4 , 5 ) # 用 delay 會產生 task 交給 Celery，所以是 asynchronous 的 # delay 其實 \"apply_async\" 的 shortcut # add.delay(4, 5) 等同於 add.apply_async((4, 5)) data = add . delay ( 8 , 9 ) # type(data) : celery.result.AsyncResult data . get ( timeout = 1 ) # 取值，等超過 1 秒還沒完成就 timeout，會 raise TimeoutError data . revoke ( terminate = True ) # 強制停止 task 強制停止 task (from outside) : from celery.task.control import revoke # 參數一是 task id，可以從 celery 的 log 中的得知 revoke ( \"69511b35-dcbc-4f93-9252-e428ed8114f5\" , terminate = True ) 保存結果 如果要持續監控 tasks 的狀態的話，需要把 Celery 接上 backend 來儲存， 內建的 backend 支援有很多種， 例如: SQLAlchemy、Django ORM、Memcached、Redis、AMQP (RabbitMQ)、MongoDB 等， 或者是可以自己接新的 backend。 backend 的設定在 \"Celery\" 的 backend argument 或是 configuration module 裡的 CELERY_RESULT_BACKEND AMQP 當 backend : app = Celery ( 'tasks' , backend = 'amqp' , broker = 'amqp://' ) Redis 當 backend : app = Celery ( 'tasks' , backend = 'redis://localhost' , broker = 'amqp://' ) 在用 delay 來丟 task 的時候，回傳的會是一個 AsyncResult instance， 接著可以用 ready() 這個 method 來確認完成了沒。 result = add . delay ( 4 , 4 ) # AsyncResult result . ready () # True / False 另外可以用 get() method 來一段等待時間，超過時間還沒完成就 timeout， 最後就會拿到 TimeoutError 這個 exception。 result . get ( timeout = 1 ) # result value / TimeoutError exception / exception in task 如果 task 裡 raise 了 exception， get() 會再 re-raise exception， 如果不想要再 re-raise 的話，就在 get 裡加上 propagate=False 這參數， 加上這參數後，如果 task 裡 raise 了 exception 的話， \"get()\" 拿到的會是 exception instance， 而不是直接 re-raise exception， 另外有 exception 的時候可以在 traceback 這個 attribute 裡看到原本的 traceback。 假設現在寫了一種新的 task : # proj/tasks.py from proj.celery import app @app.task def exception (): raise ValueError ( \"just kidding\" ) 接著在別的地方來丟出 task : from proj import tasks result = tasks . exception . delay () result . get () # exception and traceback # ValueError: just kidding tmp = result . get ( propagate = False ) # instance of ValueError print ( tmp ) # just kidding print ( repr ( tmp )) # ValueError('just kidding',) isinstance ( tmp , ValueError ) # True print ( result . traceback ) Configuration 用預設的東西，不太別去調設定，其實就可以良好運作了。 但是 Celery 也有提供更多的設定讓使用者可以自己調整， serializer Celery with non-Python https://groups.google.com/forum/#!topic/celery-users/K5i4r1rh4vU Frequently Asked Questions Celery 的 FAQ 的節錄 (2015-01-27) Celery - Frequently Asked Questions General 我該拿 Celery 做什麼 ? Queue everything and delight everyone 把東西放在 background 跑 例如 web request 盡可能地早點回傳給使用者，接著再把耗時的東西陸續傳給使用者，這會讓使用者感覺回應時間減少、performance 變好 在 web request 結束後跑其他額外的工作 確保工作有完成 (asynchronously 執行，定期檢查、重試) 定期執行的工作 分散式計算 平行化執行 Misconceptions Celery 一定需要 pickle ? No. Celery 支援各種 serialization scheme， 目前內建支援的有 JSON、YAML、Pickle、msgpack， 每個 task 要用什麼 serialization scheme 是可以分別指定的， 預設使用 pickle 是因為可以傳送複雜的 Python objects， 如果需要跟不同語言溝通的話可以選擇其他適合的 format。 Troubleshooting 清除所有 waiting tasks ? celery -A proj purge Results 取得某 task id 的東西 result = my_task . AsyncResult ( task_id ) result . get () Security 用 pickle 會有 security 問題吧 ? 是，用 pickle 會有安全疑慮， 基本上你要確保不該有 access 權限的地方不能 access 到你的 broker、databases、other services。 可以設定 CELERY_TASK_SERIALIZER 來改變 task messages 格式成 json 或 yaml 之類的。 我想要加密 對於支援 SSL 的 AMQP brokers 可以設定 BROKER_USE_SSL 來加密 Tasks 用名稱來 call task ? app . send_task ( 'tasks.add' , args = [ 2 , 2 ], kwargs = {}) 取得 task id ? @app.task ( bind = True ) def mytask ( self ): cache . set ( self . request . id , \"Running\" ) 我要跑連續的 task from celery.utils.log import get_task_logger logger = get_task_logger ( __name__ ) @app.task def add ( x , y ): return x + y @app.task ( ignore_result = True ) def log_result ( result ): logger . info ( \"log_result got: %r \" , result ) # run task # 這邊注意到用的是 \".s\" 而不是直接 call \".delay\" # 詳細看 celery.canvas.Signature ( add . s ( 2 , 2 ) | log_result . s ()) . delay () Reference Celery Celery Documentation GitHub - celery/celery Celery - Community Links Celery - Frequently Asked Questions Full Stack Python - Task Queues Queues - Job queues, message queues and other queues. Almost all of them in one place Wikipedia - Message broker Wikipedia - Celery Task Queue Wikipedia - Advanced Message Queuing Protocol Wikipedia - Distributed computing Wikipedia - Parallel computing","loc":"/posts/2015/01/celery/","tags":"Python"},{"title":"Xorg with libinput as driver","text":"libinput 這是 Xorg 上的 Input Stack : 這是 Wayland 上的 Input Stack : Xorg 上的 Input Stack 有以下問題 Features distributed across modules No communication between modules Impossible to test Lots of user-exposed options driver feature 比對 Feature evdev synaptics wacom Tapping no yes yes MB emulation yes yes no Gestures no no yes Finger Scrolling no yes some Calibration yes* no* yes* (* means server provides some calibration on top) 為了讓 Wayland 的 compositor 能有共通的 input stack 實作， 所以獨立出了 libinput 來解決問題， libinput 把很多內部的東西都處理掉 (藏起來)， 有著以下特色 : multiple backends, but not exposed to the users struct udev* in, devices out only the configuration options that make sense everything else is handled based on the hardware Touchpad features (normal): proper multitouch support top and bottom software button on clickpads two-finger scrolling 1/2/3-finger tapping clickfinger on Apple touchpads palm detection Touchpad features (exotic): re-routing of T440 software buttons through trackstick trackstick wheel emulation on T440 smart disabling of the touchpad auto-scaling of the top software buttons disable touchpad while using the trackstick normalized pointer acceleration A useful test suite tests multiple devices automatically uinput based tests without a compositor Future plans (non-obvious): \"buttonbox\" interface/gamepads raw/unaccelerated mouse input device identification system touchpad handwriting touchpad gestures 近況 libinput 最近發展的漸漸成熟，在 2015-01-15 釋出了 0.8 版， Fedora 22 也要把 Xorg 底下的 input driver 換成使用 libinput (xf86-input-libinput)， 目前 xf86-input-libinput 在 AUR 裡，不過相信未來應該會進 official repositories。 Users 在 Arch Linux 上，要把 Xorg 底下的 input driver 換成 libinput 的話， 先去 AUR 裝 xf86-input-libinput ， 接著就可以在 Xorg 的設定檔裡選擇 libinput 當 driver， 不過要注意的是，一些 Options 會不一樣，所以設定要調整過， 例如 : 原本 # xorg.conf.d/50-synaptics.conf # Original Section \"InputClass\" Identifier \"enable tapping\" MatchProduct \"my touchpad\" Driver \"synaptics\" Option \"TapButton1\" \"1\" EndSection 後來 # xorg.conf.d/50-synaptics.conf # libinput version Section \"InputClass\" Identifier \"enable tapping\" MatchProduct \"my touchpad\" Driver \"synaptics\" Option \"TapButton1\" \"1\" EndSection 這邊注意到，之前是把 driver assign 給 device，接著設定 options， 後來 libinput 的版本是 match 到一個 driver。 Reference Consolidating the input stacks with libinput XDC2014: Peter Hutterer - Consolidating the input stacks with libinput Replacing Xorg input-drivers with libinput libinput - a common input stack for Wayland compositors and X.Org drivers xf86-input-libinput compatibility with evdev and synaptics Fedora - Changes/LibinputForXorg libinput documentation Freedesktop.org - xf86-input-libinput","loc":"/posts/2015/01/xorg-with-libinput-as-driver/","tags":"Linux"},{"title":"[閱讀 & 翻譯] Linux Input Ecosystem","text":"以下內容翻譯自 linux input ecosystem (2010), by joe shaw (還有我的幾張截圖 zzz) 目前 Linux kernel 的 input system 分成兩大塊，一個是 device driver ，另一個是 event driver 。 device driver 顯然地就是跟硬體溝通， device driver 裡，大部分的 USB devices 都是由 usbhid driver 負責。 event driver 負責的則是把 device driver 產生的 events 丟到 userspace， 目前這邊主要是由 evdev 來完成， evdev 會建立 character devices (通常叫 /dev/input/eventN ) 並且用 struct input_event 來溝通。 要取得 evdev 的 devices 和 events 的資訊可以使用 evtest 當一個 device 接上的時候，kernel 會為 device 在 sysfs 建立一個 entry， 並且產生 hotplug event，該 event 會由 udev 處理 (套一些 policy 和額外的 properties)， 然後在 /dev 建立 device node，input devices 會套用 /lib/udev/rules.d/60-persistent-input.rules 裡的 rules， 其中還會 run /lib/udev/input_id tool 來從 sysfs node 取得 device 的 capabilities， 並且在 udev database 中設好環境變數 (例如: ID_INPUT_KEYBOARD, ID_INPUT_TOUCHPAD)。 除了前面提的東西外， X 也有 udev config backend 會在 startup 以及 hotplug devices 進來時運作 (為不同 input devices 去 queries udev)。 X 會看不同的 ID_INPUT_* properties 來判斷目前是哪個 device (keyboad, mouse, touchpad, joystick, ...)， 這些資訊可以用於 xorg.conf.d 裡面的 InputClass sections (例如: MatchIsPointer, MatchIsTouchpad, MatchIsJoystick, ...) # xorg.conf.d/50-synaptics.conf Section \"InputClass\" Identifier \"touchpad catchall\" Driver \"synaptics\" MatchIsTouchpad \"on\" Option \"TapButton1\" \"1\" Option \"TapButton2\" \"2\" Option \"TapButton3\" \"3\" Option \"VertEdgeScroll\" \"1\" Option \"VertTwoFingerScroll\" \"1\" Option \"VertScrollDelta\" \"-58\" Option \"HorizEdgeScroll\" \"1\" Option \"HorizTwoFingerScroll\" \"1\" Option \"HorizScrollDelta\" \"58\" Option \"CircularScrolling\" \"1\" Option \"CircScrollTrigger\" \"0\" Option \"CircScrollDelta\" \"58\" Option \"EmulateTwoFingerMinZ\" \"40\" Option \"EmulateTwoFingerMinW\" \"8\" Option \"CoastingSpeed\" \"0\" Option \"FingerLow\" \"35\" Option \"FingerHigh\" \"40\" EndSection Xorg 在 input devices 的 driver (handler) 的地方可以是 evdev 、 synaptics 、 joystick 。 Linux 在 evdev 裡有一個良好的 generic event interface， 所以只需要少量 drivers 就能跟硬體互動 (因為他們不走 device-specific protocols)。 而 Linux 上的 drivers 當中，幾乎全部都是走 evdev 的介面，包含前面列的三個。 在 Linux 上， Xorg 的 evdev driver (generic input driver) 提供基本的 keyboard、 mouse、lid switches、power switches 等功能， 經由 evdev 的 interface 到 /dev/input/eventN devices。 至於 synaptics driver 呢，其實也是走 evdev 的 interface 來跟 kernel 溝通的。 在 Linux 上它不能跟硬體直接溝通，也不能弄 Synaptics™ hardware-specific。 synaptics driver 只是個從 evdev 分出去的 driver，加上了一些 touchpad 硬體要有的 features (例如: two-finger scrolling)， 在 Linux 上它比較像是個 \"touchpad\" module，在其他 non-Linux 平台上則可以使用 Synaptics protocol。 而 joystick driver 的情況跟 synaptics driver 類似，走的也是 evdev 的 interface， 而不是 device-specific protocol。 X 的概念只包含了 keyboards 和 pointers，而 pointers 則包含了 mice、touchpads、joysticks、wacom tablets ... etc。 X 另外還有 core keyboard 和 pointer 的概念，預設所有的 device 都是送 core events 到 applications 的， 但是可以把特定 devices 設為 non-core。 如果要收 non-core devices 的 events 的話，需要使用 XInput 或 XInput2 extensions。 XInput 提供 core-like 的 events (例如: DeviceMotionNotify、DeviceButtonPress)， 所以跟 core events 用起來類似，但是 setup 方式和大部分的 X extensions 不一樣。","loc":"/posts/2015/01/linux-input-ecosystem/","tags":"Linux"},{"title":"libinput 0.8.0","text":"[ANNOUNCE] libinput 0.8.0 剛剛在讀 RSS 的時候看到 libinput 有新 release 了， 新的 release 改進的部份主要在於滾動和觸空版支援","loc":"/posts/2015/01/libinput-0.8.0/","tags":"Misc"},{"title":"C++11 - override & final","text":"C++11 在繼承的地方多了 override 和 final 兩個 keyword 可以用 在解釋之前先回顧 C++ 的繼承 C++ 繼承 class 定義 public : 大家都可看 protected : 只有子孫能看 private : 只有自己能看 class 繼承 public : 大家都知道父母和小孩的關係 protected : 只有子孫知道自己與祖先的關係 private : 只有自己知道跟父母的關係 基本上的 priority 就是 private > protected > public 所以在繼承的時候 priority 大的會掩蓋 priorty 小的 class A { public : int x ; protected : int y ; private : int z ; }; class B : public A { // x is public // y is protected // z is not accessible from B }; class C : protected A { // x is protected // y is protected // z is not accessible from C }; class D : private A { // x is private // y is private // z is not accessible from D }; Virutal Function C++ 裡提供了一個 keyword 叫 virtual ， 使用 virtual 關鍵字的 method 會是 Late binding (dynamic binding)， 在 runtime 的時候才會決定要 call 的 function 位址 例如 : #include <iostream> class A { public : void func1 () { std :: cout << \"func1 in A\" << std :: endl ; } virtual void func2 () { std :: cout << \"func2 in A\" << std :: endl ; } }; class B : public A { public : void func1 () { std :: cout << \"func1 in B\" << std :: endl ; } void func2 () { std :: cout << \"func2 in B\" << std :: endl ; } }; int main ( int argc , char * argv []) { A a = A (); B b = B (); a . func1 (); // func1 in A a . func2 (); // func2 in A b . func1 (); // func1 in B b . func2 (); // func2 in B A & c = b ; c . func1 (); // func1 in A c . func2 (); // func2 in B A * ptr = nullptr ; ptr = & a ; ptr -> func1 (); // func1 in A ptr -> func2 (); // func2 in A ptr = & b ; ptr -> func1 (); // func1 in A ptr -> func2 (); // func2 in B return 0 ; } 這邊可以看到，把 class B 的變數用 class A 去解讀的時候，func1 是呼叫到 class A 所定義的， 而 func2 是呼叫到 class B 所定義的，會有這樣的差別是因為 func1 沒有用 virtual ， 但是 func2 有用 virtual ， base class 有寫 virtual 的 function 在被 call 到時會去 virtual table 裡面找真正要 call 的 function 的位址， 也才能有 late binding 的效果，沒有寫 virtual 的 function 依然會是 early binding (static binding)。 在 static binding 的情況下，ptr 要 call 的 function 的位址在 compile time 就決定了， 所以 func1 一直都會 call 到 class A 的版本。而在 late binding 的情況下， 要 call 的 function 的位址在 runtime 決定，會從 virtual table 中找到對應的 function 的位址， 所以可以 call 到各自的版本。 C++11 - override & final override override 是提供給繼承的 class 用的，目的是確保 function 有 override 到 base class 的 virtual funcion， 標上 override 後，compiler 可以在 compile time 的時候檢查是否真的有 override， 可以避免不小心沒寫好造成該 override 的 function 沒有 override 到。 class A { public : virtual void foo (); void bar (); }; class B : A { public : void foo () const override ; // Error: B::foo does not override A::foo // (signature mismatch) void foo () override ; // OK: B::foo overrides A::foo void bar () override ; // Error: A::bar is not virtual }; final final 是提供給 class 或 base class 的 virtual function 使用的， 標上 final 的 class 不能再被繼承，標上 final 的 virutal function 不能再被 override。 class A { public : virtual void foo () final ; // A::foo is final void bar () final ; // Error: non-virtual function cannot be final }; class B final : A // struct B is final { public : void foo (); // Error: foo cannot be overridden as it's final in A }; class C : B // Error: B is final { }; Ref override specifier (since C++11) final specifier (since C++11) 比較安全的 C++ 虛擬函式寫法：C++11 override 與 final Wikipedia - Late binding C++ - Difference between private, public, and protected inheritance","loc":"/posts/2015/01/cpp11-override-and-final/","tags":"C++"},{"title":"Vim - 快快貼","text":"我之前在貼上大量文字進 Vim 的時候覺得有點慢，所以搜尋過如何更快速的貼上， 不過也只找到 paste mode 可以用 (應該是當時沒有打到重要的關鍵字) paste mode 預設就有 toggle key 可以設定 \" use '<leader>p' to toggle paste mode set pastetoggle =< leader > p 或是手動用 :set paste 來進入 paste mode， :set nopaste 來離開 paste mode 今天終於找到了我想要的解法，直接從 system clipboard 拿資料， 而不是由 terminal 去慢慢模擬輸入 ... 這邊要用到 Vim 裡的 register， 在 Vim 裡面對應到外面 Linux 的 clipboard 的 register 是 + ， 所以可以從這裡面快速的拿到資料 方法 1 : 在 insert mode 快速貼上 在 insert mode 裡面可以用 Ctrl+R 來 access Vim 的 register， 內容會直接輸入，所以可以使用 Ctrl+R + + 來快速的輸入 clipboard 裡的東西 方法 2 : 在 normal mode 快速貼上 在 normal mode 裡面可以用 \" 來 access Vim 的 register， 所以可以使用 \" + + + p 來快速的貼上 clipboard 裡的東西 方便起見，當然還是 map 到某個 key 上面，這樣就可以快速的使用了， 目前我是把自己之前用在 paste mode toggle 的 <leader>p map 成了 \"+p ， 想說我如果想切到 paste mode 通常也就是我要從外面貼東西進來， 乾脆就直接換成這個快速貼上 ~ 先使用一陣子看看，如果真的不習慣再換囉 ~ 其他應用 - 從 Vim 裡複製到 system clipboard 在 visual mode 或是 visual block mode 裡面可以也可以用 \" 來 access Vim 的 register， 所以可以先選取想要複製的區塊， 接著用 \" + + + y 來複製資料到 clipboard 裡 ~~~ 然後就可以在其他程式裡快樂的貼上了 ~ ya ~ 其他 Vim registers 想知道其他更多 Vim 裡的 registers 的資料可以下 :reg ， 更多資訊可以 Vim 的 manual 參考資料 StackOverflow - How to paste text into Vim command line 回應很豐富 Vim Tips wiki - In line copy and paste to system clipboard Vim Tips wiki - Accessing the system clipboard","loc":"/posts/2015/01/vim-fast-paste/","tags":"Vim"},{"title":"virtualenv 版本號異動","text":"剛剛要做系統更新的時候， 發現我這邊 Arch Linux 機器上的 virtualenv 要從 1.11.6-2 升到 12.0.5-1， 一看到覺得這版本會不會跳太大了 XD， 去翻了 virtualenv - changes 才知道在 12 月底的時候有做過版本號規則的改動 XD， 從 1.11 變 12.0 www","loc":"/posts/2015/01/virtualenv-version-change/","tags":"Misc"},{"title":"Vim Plugin - rogue","text":"剛好看到一個 Vim 的 Plugin 叫作 rogue (GitHub repo 在這裡 katono/rogue.vim ) 如果看到 rogue 這個詞會有反應的， 極有可能知道 roguelike 這個遊戲種類， 沒錯這個 Plugin 指的就是這種類的起源 Rogue 這款遊戲， 這遊戲以及其衍生出的 roguelike 的遊戲一直以來都包含著好玩的遊戲的重要要素 ~， 如果對於 roguelike 不熟悉也沒關係， 可以先看看這篇豐富的介紹文 Roguelike 到底是啥 (其中的發展還涉及了當時的 Unix 以及 BSD 還有 curses 這個 library)， roguelike 遊戲的元素到現在都還是處處可見， 早期知名的像是 NetHack (介紹文 : Jedi - 如果你一生只打算做一件事的話，玩 NetHack )， 最近很紅的像是 The Binding Of Issac ， 而這 Vim Plugin 的作者則是把 rogue 這款遊戲 (Clone 版本) porting 到 Vim 上了 ... 用 Vundle 把 Plugin 裝完後只要在 Vim 裡下 :Rogue 就可以開始遊戲 ... 雖然這對我使用 Vim 來編輯一點幫助也沒有 XD， 但是看到有人對這遊戲如此熱愛就讓我想紀錄一下 ~","loc":"/posts/2015/01/vim-plugin-rogue/","tags":"Misc"},{"title":"[文章閱讀] 9 個 GIF 動畫，看懂 Web 演化史","text":"9 個 GIF 動畫，看懂 Web 演化史 原文 : The History Of Web Design Explained In 9 GIFs GIFs 來源 : A brief history of web design for designers","loc":"/posts/2015/01/web-history-9-gifs/","tags":"Misc"},{"title":"D-Bus","text":"Basic Linux IPC Wikipedia - Inter-process communication [Linux.conf.au 2013] - An Introduction to Linux IPC Facilities [Linux.conf.au 2013] - An Introduction to Linux IPC Facilities - slide sockets FIFOs shared memory D-Bus D-Bus is a message bus system for inter-process communication ( IPC ) D-Bus Wikipedia - D-Bus Freedesktop - Introduction to D-Bus Linux From Scratch - D-Bus D-Bus Specification D-Bus is enabled automatically when using systemd because dbus is a dependency of systemd. What's D-Bus a powerful IPC system the closest thing to a standard in this area as can be found on Linux provides a nice method-call transaction mechanism has fundamental inefficiencies of the user-space implementation well suited to control tasks works well to tell a sound server to change the volume less so for anything that has to carry significant amounts of data one would not want to try to send the actual audio data over the bus In D-Bus a call-return message requires 10 message copies , 4 message validations , 4 context switches D-Bus has no timestamps on messages not available at early boot We need a better implementation -> kdbus D-Bus - Architecture libdbus dbus-daemon wrapper libraries based on particular application frameworks Interesting : In 2013 the systemd project rewrote libdbus in an effort to simplify the code, but it turned out to significantly increase the performance of D-Bus as well. In preliminary benchmarks, BMW found that the systemd D-Bus library increased performance by 360%. kdbus D-Bus in the kernel [linux.conf.au 2014] D-Bus in the Kernel - slide ALS: Linux interprocess communication and kdbus (May 30, 2013) The unveiling of kdbus (Jan 13, 2014) Linux Kernel only have primitives IPC : sockets, FIFOs, and shared memory kdbus is a in-kernel implementation of D-Bus can carry large amounts of data even used for gigabyte-sized message streams have zero-copy message passing worst case : 2 copy operations , 2 validations , 2 context switches all messages carry timestamps full credential information (user ID, process ID, SELinux label, control group information, capabilities, and much more) is passed with each message always available to the system (no need to wait for the D-Bus daemon to be started) Linux security modules can hook into it directly various race conditions have been fixed API has simplified Kdbus is implemented as a character device in the kernel signal broadcasting mechanism has been rewritten to use Bloom filters to select recipients There is a user-space proxy server that can be used by older code that has not been rewritten to use the new API, so everything should just work on a kdbus-enabled system with no code changes required. the new memfd syscall was merged into Linux kernel 3.17 memfd is a mechanism similar to Android's ashmem that allows zero-copy message passing in KDBUS. Android \"ashmem\" subsystem Android Binder Kdbus meets linux-kernel (Nov 4, 2014) D-Bus, FreeDesktop, and lots of madness Hacker News - D-Bus, FreeDesktop, and lots of madness Kdbus Details - Greg Kroah-Hartman Binder vs. kdbus Binder is bound to the CPU, D-Bus (and hence kdbus), is bound to RAM kdbus.txt","loc":"/posts/2014/12/d-bus/","tags":"Misc"},{"title":"Notification things","text":"Linux Arch Wiki - Desktop Notifications Libnotify Arch Package - libnotify desktop independent need a notification server Dependencies gdk-pixbuf2 Wikipedia - GDK GIMP Drawing Kit GDK was originally developed on the X Window System for the GIMP GdkPixbuf is a toolkit for image loading and pixel buffer manipulation. In GTK+ version 2.22 from 2010-09-23 GdkPixbuf was split off from GDK into a separate package in preparation for the transition to GTK+ 3. Notification servers Bult-in The following desktop environments use their own implementations to display notifications, and you cannot replace them. Their notification servers are started automatically on login to receive notifications from applications via DBus . Cinnamon Enlightenment GNOME KDE Standalone Mac OS X Growl Wikipedia - Growl Growl - Website Browser Firefox MDN - Notification - Web API Interfaces Chromium Chromium - Linux Technical FAQ Why don't Chromium notifications use the D-BUS-based notifications system (aka libnotify / notification-daemon)? HTML5 notifications can contain arbitrary HTML, which is not supported by the notification protocol. (This is the same reason we don't use Growl on OS X.) Chromium's notifications include a button that brings up an options menu, which is also not supported by the notification protocol. The glitzy Ubuntu notifications daemon, by design, does not allow the user to interact with notifications at all, which doesn't work when the notification HTML includes clickable links. It would be nice to extend the protocol to allow Chromium to integrate.","loc":"/posts/2014/12/notification-things/","tags":"Misc"},{"title":"Coverity","text":"from Coverity : In 2006, the Coverity Scan service was initiated with the U.S. Department of Homeland Security as the largest public-private sector research project in the world, focused on open source software quality and security. Coverity now manages the project, providing its development testing technology as a free service to the open source community to help them build quality and security into their software development process. Register your open source project for the Coverity Scan service, and follow us on Twitter to get the latest updates. Coverity Scan Static Analysis Find and fix defects in your Java, C/C++ or C# open source project for free Wikipedia - Coverity Projects that use this service Linux Kernel CPython Jenkins PHP PostgreSQL Hadoop ... example :","loc":"/posts/2014/12/coverity/","tags":"Misc"},{"title":"Linux Standard Base, Filesystem Hierarchy Standard","text":"Linux Standard Base (LSB) Wikipedia - Linux Standard Base The DRAFT LSB 5.0 Specification Filesystem Hierarchy Standard (FHS) Wikipedia - Filesystem Hierarchy Standard Filesystem Hierarchy Specification - Beta","loc":"/posts/2014/12/linux-standard-base/","tags":"Misc"},{"title":"[TED] Michael Rubinstein: See invisible motion, hear silent sounds. Cool? Creepy? We can't decide","text":"這個 talk 講的是利用影像處理來放大細微的動作，甚至藉此來初步還原出當時的聲音","loc":"/posts/2014/12/ted-motion-microscope/","tags":"TED"},{"title":"Linux Kernel Booting Process","text":"Linux/Documentation/x86/boot.txt Wikipedia - vmlinux vm is for virtual memory the Linux kernel in an statically linked executable file format vmlinuz compressed vmlinux What is the difference between the following kernel Makefile terms: vmlinux, vmlinuz, vmlinux.bin, zimage & bzimage? Arch Wiki - Arch boot process Linux Kernel Booting Process (1) - For NLKB from shimosawa Linux Kernel Booting Process (2) - For NLKB from shimosawa bzImage bzImage = big zImage Linux <= 2.6.22 bbootsect (bootsect.o): bsetup (setup.o) bvmlinux (head.o, misc.o, piggy.o) piggy.o contains the gzipped vmlinux file in its data section ( ELF ) (see compressed/Makefile piggy.o). All source files mentioned are in arch/i386/boot/ Linux >= 2.6.23 merged bbootsect and bsetup into one ( header.o ) initramfs 深入理解 Linux 2.6 的 initramfs 機制 (上) - Jserv Wikipedia - initramfs Linux/Documentation/filesystems/ramfs-rootfs-initramfs.txt Arch Wiki - mkinitcpio zlib an abstraction of the DEFLATE compression algorithm used in the gzip file compression program Wikipedia - zlib Applications Linux Kernel libpng Apache OpenSSH OpenSSL FFmpeg rsync dpkg Subversion Git PostgreSQL ... feature : code is portable, liberally licensed, and has a relatively small memory footprint","loc":"/posts/2014/12/linux-kernel-booting-process/","tags":"Misc"},{"title":"QEMU - First Step","text":"Wikipedia - QEMU Arch Wiki - QEMU Install QEMU pacman -S qemu # Arch Linux Name New Version Net Change Download Size extra/bluez-libs 5.26-1 0.28 MiB 0.06 MiB extra/celt0.5.1 0.5.1.3-3 0.16 MiB 0.04 MiB extra/libcacard 2.1.2-1 0.09 MiB 0.03 MiB extra/libiscsi 1.12.0-1 0.44 MiB 0.10 MiB extra/seabios 1.7.5-2 1.69 MiB 0.12 MiB extra/spice 0.12.5-1 2.41 MiB 0.56 MiB community/usbredir 0.6-4 0.15 MiB 0.03 MiB extra/vde2 2.3.2-6 0.78 MiB 0.19 MiB extra/qemu 2.1.2-1 178.21 MiB 19.38 MiB Total Download Size: 20.53 MiB Total Installed Size: 184.21 MiB Create Image qemu-img create -f qcow2 test.qcow2 100G output : Formatting 'test.qcow2', fmt=qcow2 size=107374182400 encryption=off cluster_size=65536 lazy_refcounts=off Install OS from bootable ISO -m to assign memory size -cdrom to assign bootable ISO -boot order=d to change the booting priority for cdrom qemu-system-x86_64 -m 2G -cdrom ArchLinux.iso -boot order = d test.qcow2 QEMU with KVM check your kernel has KVM support : lsmod | grep kvm output : kvm_intel 143245 0 kvm 421519 1 kvm_intel start QEMU in KVM mode (add --enable-kvm ) qemu-system-x86_64 --enable-kvm test.qcow2 with previous booting optinos : qemu-system-x86_64 --enable-kvm -m 2G -cdrom ArchLinux.iso -boot order = d test.qcow2","loc":"/posts/2014/12/qemu-first-step/","tags":"QEMU"},{"title":"Vim startup time log","text":"原本是在找 vim 啟動時間相關的資料，找到了 這個網站 ， 發現有 --startuptime 這個參數可以用，於是就立馬來試一下， vim --startuptime vim.log test.py 接著就可以去 vim.log 看整個啟動狀況 times in msec clock self+sourced self: sourced script clock elapsed: other lines 000.013 000.013: --- VIM STARTING --- 000.142 000.129: Allocated generic buffers 000.277 000.135: locale set 000.305 000.028: GUI prepared 000.313 000.008: clipboard setup 000.321 000.008: window checked 000.881 000.560: inits 1 000.888 000.007: parsing arguments 000.889 000.001: expanding arguments 000.903 000.014: shell init 001.163 000.260: Termcap init 001.214 000.051: inits 2 001.356 000.142: init highlight 042.935 041.473 041.473: sourcing /usr/share/vim/vimfiles/archlinux.vim 043.008 041.604 000.131: sourcing /etc/vimrc 044.222 000.267 000.267: sourcing /usr/share/vim/vim74/syntax/syncolor.vim 044.368 000.480 000.213: sourcing /usr/share/vim/vim74/syntax/synload.vim 067.980 023.555 023.555: sourcing /usr/share/vim/vim74/filetype.vim 068.028 024.211 000.176: sourcing /usr/share/vim/vim74/syntax/syntax.vim ... 161.306 000.881: loading plugins 161.907 000.601: inits 3 162.125 000.218: reading viminfo 163.820 001.695: setup clipboard 163.846 000.026: setting raw mode 163.855 000.009: start termcap 163.876 000.021: clearing screen ... 185.539 000.358: BufEnter autocommands 185.541 000.002: editing files in windows 190.308 004.767: VimEnter autocommands 190.311 000.003: before starting main loop 190.445 000.134: first screen update 190.447 000.002: --- VIM STARTED --- manual in Vim : :help slow-start 這個 log 參數剛好拿來解掉一個朋友碰到的問題 ~ 他在用 mosh 連到某台機器上開 vim 時會 hang 住， 藉由這個 log，發現是卡在 clipboard 那裡， 原因是因為程式嘗試和 X server connect，但一直連不到， 接著就找到了解法 vim -X 詳細問題解法可以看 這篇 stackoverflow 回答","loc":"/posts/2014/12/vim-startup-time-log/","tags":"Vim"},{"title":"neovim first try","text":"Vim is a wonderful editor which appears long long ago. Now, a project called Neovim wants to refactor Vim and simplify maintenance and improve plugin architecture and many thing else. It's making progress now, you can see Neovim - Progress - GitHub wiki for more information. Today, I install neovim on my computer, and it seems to work fine as original Vim (with a lots of change that user hard to detect) Now, Neovim is working on port all IO to libuv and a VimL to Lua transpiler. I hope another language will replace the Vimscript soon ... The Neovim Website Neovim - GitHub Install I install it on my Arch Linux yaourt -S neovim-git python2-neovim-git After installation, you can use nvim to start neovim, and the config is .nvimrc","loc":"/posts/2014/12/neovim-first-try/","tags":"Vim"},{"title":"[Video]  The Real Story Behind Wayland and X - Daniel Stone (linux.conf.au 2013)","text":"This talk is funny and easy to understand ~ slide","loc":"/posts/2014/12/the-real-story-behind-wayland-and-x/","tags":"Misc"},{"title":"[Slide] 淺談編譯器最佳化技術","text":"今天剛好看到在隔壁校的活動在談 \"淺談編譯器最佳化技術\"，內容蠻好懂的 ~ 淺談編譯器最佳化技術 from Kito Cheng","loc":"/posts/2014/12/compiler-optimization-intro/","tags":"Compiler"},{"title":"[JCConf] OpenJDK vs. Dalvik/ART virtual machine","text":"JCConf 官網連結 (有 Video) Preface 這裡不提 JVM tuning JNI, GC, invokedynamic Production tweaking Android Programming Content +----------------+ | CLDC-HI (Java) | +----------------+ &#94; | +----------------+ +---------------------------+ +-------------------+ | Self VM (Self) |->| Strongtalk VM (Smalltalk) |->| HotSpot VM (Java) | +----------------+ +---------------------------+ +-------------------+ | | | | | | | | | | | | | | +-----------------+ | ---------------> | V8 (Javascript) | ------------------------------------------> +-----------------+ JIT Compiled when needed Mixed-Mode Interpreted Bytecode-walking Artificial stack machine Compiled Direct native operations Native register machine Profiling Gather data about code while interpreting Invariants (types, constants, nulls) Statistics (branches, calls) Optimizations Method inlining Loop unrolling Lock coarsening/eliding Dead code elimination Duplicate code elimination Escape analysis Hotspot client mode (C1) inlines, less aggressive Fewer opportunities to optimize server mode (C2) inlines aggressively Based on richer runtime profiling Profile until 10k calls Tiered Level 0 = Interpreter Level 1~3 = C1 Level 4 = C2 from Interpreter to Compiler Bytecode interpreter switch-threading indirect-threading token-threading ... Summary : OpenJDK Introduction to Dalvik VM 因為硬體限制，不能像 HotSpot 一樣做那麼多優化 Dalvik 是 Register-based 的 VM Dalvik Executable (DEX) convert tool : dx Optimizing Dispatch selective inlining + 打開 Java 程式執行的時候，CPU 就是不知道在忙什麼 + 只是個印出 Hello World 的程式，發現 CPU 有點忙 dexopt : Instruction Rewritten libART (Android RunTime Library) Use Ahead-Of-Time (AOT) scheme instead of JIT Precompile Dalvik Bytecode into machine language during installation Summary Hotspot 和 Dalvik 完全不同 codebase，但設計原理很像，Hotspot 實作比較完整，Dalvik 有很多先天限制 Android L 啟動時間變更久 (重新 scan bytecode 來生成 machine code) 要兼顧效能和啟動時間","loc":"/posts/2014/12/openjdk-vs-dalvik-and-art-vm/","tags":"Misc"},{"title":"Django, Apache, PostgreSQL","text":"Although I usually use Arch Linux, this time I need to install every thing on Ubuntu Server (I get a task to install something on Ubuntu VM) ... First, I give my public key to current VM administrator, so I can get permission to ssh to server by key. Install Apache, mod-wsgi ... Making a virtualenv, cloning current project, installing the requirement.txt Modify Apache's configuration (Apache's configuration in Ubuntu is at /etc/apache2/apache2.conf , and default user that Apache use in Ubuntu is \"www-data\"), setting WSGIPythonPath to the virtualenv one Install PostgreSQL (this is my first time to install PostgreSQL) Setting PostgreSQL (create user, database, ...)","loc":"/posts/2014/11/django-apache-postgresql/","tags":"Django"},{"title":"Arch Linux upgrade (11/11)","text":"It has been a while since last time I upgrade my notebook, now I upgrade many software in my notebook including the Linux Kernel, everything works well after upgrade :) I love rolling release :P","loc":"/posts/2014/11/archlinux-upgrade-2014-11-11/","tags":"Misc"},{"title":"[WIP][Software Testing] Intro.","text":"Note: 本篇仍在未完成狀態 課程講義 期中考: 第 5,6,7,8,9 章 (boundary value, equivalence class, decision table, path testing, data flow testing) Intro. white & black 測試大概可以分成 白箱測試 (white-box testing) 與 黑箱測試 (black-box testing) white-box testing 又可以稱為 透明箱測試 (glass box testing) ， 因為可以看到內部結構，因此又稱為 結構測試 (structural testing) 或 邏輯驅動測試 (logic-driven testing) test case adequacy criteria test case adequacy criteria 討論的是 \"需要多少的測試才足夠\"， 這可以由涵蓋的 control-flow & data-flow 比例來衡量 control-flow coverage (測量可以經過多少 execution path) statement coverage branch coverage data-flow coverage (definition & use & kill) all-du-paths (definition & use) all-uses all-defs + 如果每條 variable 的 dc-paths 都包含的話 all-c-uses (computation) all-p-uses (predicate) all-c-uses/some-p-uses all-p-uses/some-c-uses dc-paths (definition & clear) test case 難寫通常也代表著程式太複雜，因此要降低結構複雜度，再來是避免 non-determinism Rapps-Weyuker hierarchy of data flow coverage metrics : +-----------+ | All-Paths | +-----------+ | +--------------+ | All-DU-Paths | +--------------+ | +----------+ | All-Uses | +----------+ | | |¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯| | | +------------------------+ +------------------------+ | All C-Uses some P-Uses | | All P-Uses some C-Uses | +------------------------+ +------------------------+ | | |¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯| | | +----------+ +------------+ | All-Defs | | All P-Uses | +----------+ +------------+ | +-----------+ | All Edges | +-----------+ | +-----------+ | All Nodes | +-----------+ P-use use in predicate C-use use in computation O-use use for output L-use use for location (pointers, subscripts) I-use iteration (internal counters, loop indices) I-def defined by input A-def defined by assignment Wikipedia - Program Slicing https://github.com/romanofski/programslice http://www.researchgate.net/publication/261261093_Static_Slicing_for_Python_First-Class_Objects Spyder ANSI C Dynamic http://spaf.cerias.purdue.edu/Students/spyder.html Unravel CodeSonar Indus/Kaveri JSlice SeeSlice Programslice decision-to-decision path (DD-path) coverage.py coverage report -m $ coverageg report -m Name Stmts Miss Cover Missing ------------------------------------- hw1 58 2 97% 49-50 test 21 0 100% ------------------------------------- TOTAL 79 2 97% Ch5 - Boundary Value Testing Ch5 課程講義 Ch6 - Equivalence Class Testing weak normal strong normal weak robust strong robust Ch7 - Decision Table-based Testing CH7 課程講義 Ch8 - Path Testing Program Graphs 用 imperative 寫出來的程式的 program graphs 會是 directed graph nodes are statement fragements edges are flow of control DD-Paths Test Coverage Metrics node coverage edge coverage chain coverage path coverage https://bitbucket.org/ned/coveragepy Miller's Coverage Metrics Todo DO-178B Ch9 - Data Flow Testing Define/Use Testing Slice-Based Testing Program Slicing Tools 重點: 變數在哪裡拿到 values、在哪裡被使用 unifying structure of test coverage metrics program slice (1979 - Mark Weiser) define/reference anomalies 檢查以下 issue 只有定義但沒有被使用的變數 變數未定義就使用 變數定義了多次 變數在使用之前就被 deallocate defining node usage node P-use & C-use Ref 白箱測試與黑箱測試（上）","loc":"/posts/2014/11/software-testing-intro/","tags":"Misc"},{"title":"[Psycho] Psychology Intro.","text":"修心理學通識的隨便紀錄 (? Ch1 - Psychology and Life Psychology 研究的是 個人行為和心智歷程 (behavior of individuals and their mental processes) Scientific method : 蒐集和解釋客觀的資訊 (儘量減少誤差並結論出可信的概括) Behavior : 生物依照環境而產生的可觀察的行為 描述 => 解釋 => 預測 => 控制 behavioral data reports of observations explanations Internal factors External factors predictions Causal Prediction (因果預測) Scientific Prediction 由分析結果來判斷關係 control Interventions (介入) 控制行為發生與否 Psychology's Historical Foundations Hermann Ebbinghaus 早期的實驗心理學家之一 遺忘曲線 先天論者 vs. 經驗論者 (nativist vs. empiricist) Plato (柏拉圖) and Aristotle (亞里斯多德) opposing views of how mind works John Locke 洛克 empiricist view (經驗主義) 1632-1704 Immanuel Kant 康德 nativist view 心理會影響對世界的感受 1724-1804 René Descartes (笛卡兒) 人類可以用科學來理解 1596-1650 Wilhelm Wundt First formal experimental psychology lab 1879 Edward Titchener 建立美國早期的 psychology labs 之一 1892 William James Principles of Psychology 1890 comfort food 吃下去後可以撫慰心情和精神的食物 Evolution of Modern Psychology 結構論學派 School of Structuralism 創始人為德國心理學家馮德（W. Wundt） 心理學是從個體本身的觀點研究其自覺的經驗。因此心理學的主要方法就是 內省法 或自省法 人類的意識經驗中包括三大元素，即感覺、意像、與感情 功能論學派 School of Functionalism 美國心理學家 J. James 與 J. Dewey 二人首創 受達爾文 (C. Darwin) 進化論中「適者生存」的理念 完形心理學 Gestalt Psychology (中文音義變成 \"格式塔\" ...) Gestalt 源自德文，意思是 \"形狀\"，意解為 \"看清事物\" Gestalt Psychology 的重要概念是 整體 (並非各個部份的總和)，興起於 20 世紀初的德國， 由 Kurt Koffka, Max Wertheimer, and Wolfgang Köhler 創立， 主要是在研究人類 知覺與意識 上的問題， 反對結構學派 (Structuralism) 以自我觀察、自我描述等內省的方法分析意識經驗的成份， 也反對行為主義心理學派 (Behaviorism) 過份強調動物實驗，完全排斥心智歷程的作法 心理學七種取向 Perspective Focus of Study Primary Research Topics Psychodynamic Unconscious drives Conflicts Behaviorist Specific overt responses Humanistic Human expreience and potentials Cognitive Mental processes Language Biological Brain and nervouse system processes Evolutionary Evolved psychological adaptations Sociocultural Cross-cultural patterns of attitudes and behaviors Ch2 - Research Methods in Psychology Process of Research 理論 (Theory) : An organized set of concepts that explains a phenomenon or set of phenomena. 決定論 (Determinism) : Doctrine that all events - physical, behavioral, andmental - are \"determined\" by specific causal factors that are potentially knowable step 1 Initial phase of research: Theory step 2 Develop ahypothesis 假說 step 3 Design the study 研究設計 Scientific Method 蒐集和解釋客觀的資訊 (儘量減少誤差並結論出可信的概括) 目標是要得出最多的客觀 conclusions Observer Bias 因為動機和預期造成的測試偏差 Standardization 標準化 Operational definition 操作型定義是將依些事物以某種操作表示出來 所有研究裡的變數都必須是操作型定義給定的 ex: 「花生果醬三明治」的操作性定義是「使用抹刀先將花生醬塗抹到一片麵包上，再將果醬塗抹在花生醬上，最後蓋上另一片厚度相同的麵包後所得到的成果。」 Research Variable Independent Variable (獨變項/自變項) (研究者操弄的變數) Dependent Variable (依變項) Experimental Methods 研究者操弄 independent variable 來看對 dependent variable 的影響， 用來解決因果模糊性 Control Procedures Double-blind control 雙盲控制 目的是避免研究結果受安慰劑效應或觀察者期望效應所影響 受試驗的對象及研究人員並不知道哪些對象屬於對照組，哪些屬於實驗組 在藥物測試中經常使用雙盲測試。病人被隨機編入對照組及實驗組。 對照組被給予安慰劑，而實驗組給予真正藥物。 無論是病人或觀察病人的實驗人員都不知道誰得到真正的藥物，直至研究結束為止。 不過部份的試驗會較難做成雙盲， 例如：如果治療效果非常顯著，或治療的副作用非常明顯，實驗人員便可能猜想到哪組是對照。 Placebo control 安慰劑控制 Between-subjects designs 受試者間設計 每個參與者隨機分配到不同測試環境 Within-subjects designs 受試者內設計 每個參與者可以自己控制 Sample 樣本 Population 中被選為受試者的 subset Representative Sample 代表性樣本 Population 中被選為受試者的 subset 中和特徵非常符合的部份 Population 母群 Alternative explanations 替代解釋 可以由以下幾種而得 Confounding variables (混淆變項) Expectancy effects (預期效應) Placebo effect (安慰劑效應) Correlational Methods 相關法 Correlational Coefficient Correlational Methods 正相關 負相關 Psychological Measurement Reliability Validity Self-report Measures Behavior Measure Direct observations Naturalistic observations Archival Data Case Study Ethical Issues in Research 研究的倫理議題 +----------+ | 告知同意 | +----------+ | +-----------------+ | 風險 / 獲得評估 | +-----------------+ | +----------+ | 刻意瞞騙 | +----------+ | +----------+ | 事後釋疑 | +----------+ Ch3 - The Biological and Evolutionary Basis of Behavior Nature vs. Nurture (先天 vs. 後天) Heredity vs. Environment (遺傳 vs. 環境) Nervous system Neuron Dendrites 樹突 Receive stimulation from sensory receptors Soma 細胞體 Cell body, contains nucleus Axon 軸突 Long extended fiber along which neural impulse travels 圖 ?? http://en.wikipedia.org/wiki/Synapse Synapse 突觸 不同神經元間或神經元與細胞間溝通的接頭 Synapse Transmission Neurotransmitters (神經傳導物質) Catecholamines (兒茶酚胺) Norepinephrine (NE) (正腎上腺素) Dopamine (DA) (多巴胺) 在精神分裂症患者身上可以看到高於正常值的多巴胺 Glutamate (Glu) (麩胺酸) 腦中最常見的興奮性神經傳導物質 和情緒反應、學習和記憶有關 與藥物、酒精、尼古丁成癮有關 腦內 Glu 量的失衡與精神疾病有關連,例如精神分裂症 GABA (gamma-aminobutyric acid) (迦馬胺基丁酸) 腦中最常見的抑制性神經傳導物質 GAMA 太低會產生焦慮感 Acetylcholine (Ach) (乙醯膽鹼) 和記憶有關 (ex: 阿茲海默症) 在運動神經元和肌肉纖維交接處,使骨骼肌興奮而收縮 (ex: 美洲箭毒、肉毒桿菌) Serotonin (5-HT) (血清素) 分泌血清素的神經元位於腦幹 與激發 / 喚起和自動化歷程有關 迷幻藥 LSD 抑制血清素神經元的作用 , 產生各種幻覺 抗憂鬱藥物「百憂解」可以增強血清素的作用 Endorphins (腦內啡) 神經調節物質 控制情緒行為 (焦慮、害怕、緊張、愉悅) 與鴉片類藥物、嗎啡受體部位相同 Sympathetic nervous system (交感神經系統) 應對緊急狀況 Parasympathetic nervous system (副交感神經系統) 處理 routine 的行為 Biology and Behavior Brain Structure Limbic system (邊緣系統) regulates emotions and motivated behavior Hippocampus (海馬回) 記憶 Amygdala (杏仁核) 情緒、攻擊 Hypothalamus (下視丘) manage body's interanl state 體溫調節、性興奮 Thalamus (視丘) relay sensory information Cerebellum (小腦) regulates coordinated movement Brain stem (腦幹) set brain's general alterness level and warning system Medulla (延腦) breath, blood pressure, heartbeat Pons (橋腦) Reticular Formation (網狀組織) Spinal cord (脊髓) pathway for neural fibers traveling to and from brain Cerebral cortex (大腦皮質) involve in complex mental processes Sleep Cycle Stage 1 Stage 2 Stage 3 Stage 4 Rapid EyeMovements (REM) Ch5 - Mind, Consciousness, and AlternateStates Others Pygmalion Effect 指人在被付予更高期望以後，他們會表現的更好的一種現象 Ref http://blog.xuite.net/kc6191/study/15706646-%E6%A0%BC%E5%BC%8F%E5%A1%94%28%E5%AE%8C%E5%BD%A2%E5%BF%83%E7%90%86%E5%AD%B8,+Gestalt+psychology%29 http://phiphicake.blogspot.tw/2009/04/blog-post_13.html http://psychology101.pixnet.net/blog/post/17608991-%E7%A7%91%E5%AD%B8%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88the-scientific-method%3A-design-to-be-valid http://leeoxygen.wordpress.com/2011/06/26/great-books-of-the-western-world%E3%80%8A%E8%A5%BF%E6%96%B9%E4%B8%96%E7%95%8C%E9%89%85%E8%91%97%E3%80%8B/","loc":"/posts/2014/11/psycho-intro/","tags":"Misc"},{"title":"[Psycho] Psychology Intro. 2","text":"修心理學通識的隨便紀錄 (? 教材 (非修課) : 學習與記憶 青少年發展 人格心理學 學習 學習 : 由經驗所造成的行為模式上的相對的永久性變化 preformance distinction : 學到的不見得會表現出來 習慣化 : 降低 response time 敏感化 : 提升反應程度 行為主義與行為分析 John Watson 1878 ~ 1958 Father of American behaviorism B.F. Skinner 1904 ~ 1990 Operant conditioning model 行為分析 : 專注於發現環境對行為的影響 古典制約 Classical Conditioning: Learning Predictable Signals based on 已經有的反應去做制約 Ivan Pavlov's dog from wikipedia : 狗能夠對食物自然而然的分泌唾液，此時 Ivan Pavlov 將食物看作非制約刺激（US）、唾液分泌看作非制約反應（UR），並將兩者的關係稱為非制約反射。而如果在提供食物之前的幾秒鐘發出一些作為中性刺激（NS）的聲響，將會使得這個聲響轉變為制約刺激（CS），能夠單獨在沒有食物的狀況下引起作為制約反應（CR）的唾液分泌，兩者的關係則被稱做制約反射。 食物 (US) => 唾液分泌（UR） 食物 (US) + 聲音 (NS) => 唾液分泌（UR） 聲音 (CS) => 唾液分泌（CR） 名詞解釋 非制約刺激（unconditioned stimulus，US) ： 不需經過學習就能引起反應的 刺激 ， 如上述狗食 非制約反應（uncond itioned response，UR) ： 不需經過學習就能對非制約刺 激起的反應 ， 如上述狗對食物所流的口水 制約刺激（conditioned stimulus，CS）： 本為中性刺激 ， 與非制約刺激連結 ， 能引起反應的刺激 ， 如上述聲音 制約反應（conditioned response，CR）： 由制約刺激所引起的反應 ， 如上述 狗對聲音所流的口水 操作制約 Operant Conditioning: Learning About Consequences 正增強 行為後的獎賞 負增強 厭惡而欲避免 ex: 陽光很大，出門會帶太陽眼鏡 處罰 正處罰 負處罰 制約的歷程 刺激類化 刺激區辨 Taste-aversion Learning 味道嫌惡學習 Garcia effect ex: 接受化療的癌症患者會對食物產生噁心，因為其化療往往在進食後進行，由此使癌症患者感到是食物導致其化療痛苦 觀察學習 見賢思齊，見不賢內自省 Bandura's Research 觀察學習 BoBo Doll Study 在該實驗中，Bandura 選用兒童作為實驗對象，因為通常兒童很少有社會條件反射。班杜拉試圖使兒童分別受到成人榜樣的攻擊性行為與非攻擊性行為的影響。然後將這些兒童置於沒有成人榜樣的新環境中，以觀察他們是否模仿了成人榜樣的攻擊性行為與非攻擊性行為。 班杜拉 (Albert Bandura) - 社會學習論 (social learning theory) Video 記憶 7 +- 2 working memory chunks events => Sensory Memory => Working Memory (include Short-term Memory) => Long-term Memory explicit memory : 取得資訊需要有意識的回想 implicit memory : 取得資訊不需要有意識的的回想 Types : Declarative Memory Procedural Memory Dimensions of Long-Term Memory Long-term Memory Declarative Memory Episodic Memory (個人事件記憶/情節記憶) Semantic Memory (語意記憶) Procedural Memory Serial Position Effect Primacy Effect Recency Effect Forget Proactive interference (順向干擾(對未來記憶的干擾)) Retroactive interference (逆向干擾(對過去記憶的干擾)) Video 智力 Psychological Assessment 心理評量 Formal Assessment : 信度、效度、標準化 Galton's idea of Intelligence Theories of Intelligence Crystallized Intelligence 結晶智力 Fluid Intelligence 流體智力 Sternberg's Triarchic Theory (1999) (智力三元論) Analytical intelligence 分析智力 Creative intelligence 創造智力 Practical intelligence 實用智力 Video 人類發展 Developmental Psychology 發展心理學 Locomotion research design Longitudinal Design 縱貫設計 長時間研究同年齡的受試者 受試者流失 dropout,造成不同時間資料比較的困難 Cross-Sectional Design 橫向設計 某一時間研究不同年齡組 世代效應 cohort effect: 不同年齡組受到不同的歷史的影響 Piaget's theory 認知發展理論 認知發展的基礎：基模，同化，調節，不平衡狀態 基模：知識的組織與結構 同化：以已有的知識解釋來自環境中的各種刺激 調節：個體同化外界事物時，受外界影響，知識組織產生變化 不平衡狀態：個體知識結構與外界刺激間因不一致產生不平衡狀態，使個體有進一步學習的動機 認知發展階段 Cognitive development in adulthood 流體智力 晶體智力 選擇性最適化加上補償替代方案 Erikson's theory 社會心理發展階段 Attachment 依附關係 Attachment theory Parenting style Identity formation 認同形成 James Marcia Identity diffusion 認同散亂 Foreclosure 提早結束 Moratorium 認同找尋中(延緩) Identity achievement 認同完成/成就 Expanded on Erikson's analysis Moral (道德) Development Lawrence Kohlberg Lawrence Kohlberg's stages of moral development Level 1 Stage 1 : 避免懲罰 Stage 2 : 贏得獎勵，強調報酬/交換 Level 2 Stage 3 : 贏得讚許，避免被反對，作個 \"好人\" Stage 4 : 被 \"法律與秩序\" 規範 Level 3 Stage 5 : 被公眾福利，\"社會契約\" 規範 Stage 6 : 被自己建立的抽象道德原則規範 visual cliff 發展心理學的一個著名實驗，用來研究人類和動物的深度知覺，設計者為 Eleanor Gibson 和 Richard Walk Erikson's theory 社會心理發展階段 Erikson's stages of psychosocial development stage 1 ~ 8 Parenting Styles","loc":"/posts/2014/11/psycho-intro-2/","tags":"Misc"},{"title":"[PyPy] IO improvements","text":"剛剛看到 PyPy status blog 上的新文章 ， 以下是大概的內容 PyPy 在 Warsaw (為波蘭的首都及最大的城市) 的 sprint 順利結束了 (wrapped up)， 有些 branch (gc_no_cleanup_nursery, gc-incminimark-pinning) 已經順利 merge 回 master (improve I/O & GC) 改變一 - gc_no_cleanup_nursery PyPy GC 會把 new objects allocate 在 young object area (就是 GC 上慣稱的 nursery 啦)， 每經過一個 minor collection 都要把 nursery 清理。簡單起見，GC 通常會把整個 nursery 清成 0。 這樣作法對於 cache 會有 bad effects，因為你一次把一大塊 memory 清成 0， 而且把一些不需要清成 0 的資料也清了 (例如 large strings)。對於這個問題， 可以用 incremental nursery zeroing 來減輕， 但是 gc_no_cleanup_nursery 這個 branch 把 zeroing 整個拿掉， 因此提升了 string handling 和 recursive code 的效率 (因為 jitframes 也不再需要把 memory 清成 0) 改變二 - gc-incminimark-pinning 隨著時間的過去 PyPy GC 會把 objects 在 memory 裡做移動，也就是說 memory address 會改變， 因此要把 pointer 傳給 C function 時，必須確保指到 objects 不會被 GC 移動。 PyPy 2.4 以前，用 copying the data into or from a non-movable buffer 來解決， 顯然這沒有效率。這個 branch 使用了 \"pinning\" 的概念， 這讓程式可以知會 GC 某些 objects 在一段時間內不允許被移動。 這會讓 GC 的複雜度稍微上升，但是可以大幅提升 I/O performance。","loc":"/posts/2014/11/pypy-io-improvements/","tags":"Python"},{"title":"ZIP unsupported compression method 99","text":"前陣子朋友碰到有設密碼的 zip 檔不能用 unzip 來解開， 會出現 \"does not support compression method 99\" 的錯誤， 原因是這些檔案用 AES 加密， 對 unzip 來說是新 method 所以不支援， 這時候只好用其他支援的工具解開啦， 例如 : 7z","loc":"/posts/2014/11/zip-unsupported-99/","tags":"Misc"},{"title":"[Prolog] Cut","text":"Prolog 裡，\"+\" 等同於 not (檢查一個 goal 不能證明為真的 predicate) \"!\" 則是切除邏輯判斷的結構 在 ! 左邊的 predicates 成立，就把在 ! 之後 head 相同的情況放棄， 在 ! 左邊的 predicates 不成立，就把同一行程式 ! 右邊的 predicates 放棄掉 a ( X , Y ) :- b ( X ), !, c ( Y ). b ( 1 ). b ( 2 ). b ( 3 ). c ( 1 ). c ( 2 ). c ( 3 ). ?- a ( Q , R ). Q = 1 R = 1 ; Q = 1 R = 2 ; Q = 1 R = 3 ; No . a ( X , Y ) :- b ( X ), c ( Y ), !. b ( 1 ). b ( 2 ). b ( 3 ). c ( 1 ). c ( 2 ). c ( 3 ). ?- a ( Q , R ). Q = R , R = 1 . Links PTT - Prolog的符號: \"+\"和\"!\"是甚麼? Prolog/Cuts and Negation","loc":"/posts/2014/10/prolog-cut/","tags":"Prolog"},{"title":"[FP] predicate","text":"short : A predicate is a box that takes an argument and returns a Boolean value . For example, \"x -> x is even\". A function is a box that takes an argument and returns a value . For example, \"x -> x*x\" Predicate (謂語) in natural language Subject + Predicate : The dog + barks. The predicate identifies and describes the action of the sentence. Predicate in Functional A predicate is a function that returns the Boolean value In Python Python - Functional Programming How To ''' filter(predicate, iter) ''' def is_even ( x ): return ( x % 2 ) == 0 list ( filter ( is_even , range ( 10 ))) # there are more in iterools In Prolog Prolog's BNF <program> ::= <clause list> <query> | <query> <clause list> ::= <clause> | <clause list> <clause> <clause> ::= <predicate> . | <predicate> :- <predicate list>. <predicate list> ::= <predicate> | <predicate list> , <predicate> <predicate> ::= <atom> | <atom> ( <term list> ) <term list> ::= <term> | <term list> , <term> <term> ::= <numeral> | <atom> | <variable> | <structure> <structure> ::= <atom> ( <term list> ) <query> ::= ?- <predicate list>. <atom> ::= <small atom> | ' <string> ' <small atom> ::= <lowercase letter> | <small atom> <character> <variable> ::= <uppercase letter> | <variable> <character> <lowercase letter> ::= a | b | c | ... | x | y | z <uppercase letter> ::= A | B | C | ... | X | Y | Z | _ <numeral> ::= <digit> | <numeral> <digit> <digit> ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 <character> ::= <lowercase letter> | <uppercase letter> | <digit> | <special> <special> ::= + | - | * | / | \\ | &#94; | ~ | : | . | ? | | # | $ | & <string> ::= <character> | <string> <character> Prolog has two types of clause (子句) : (clause = facts | rules) facts cat ( tom ). rules animal ( tom ) :- cat ( tom ). Both facts and rules are composed of predicates. Links Functional predicate - wikipedia Prolog - wikipedia","loc":"/posts/2014/10/predicate/","tags":"Functional"},{"title":"[FP] Referential Transparency","text":"Short : no side effect Referential Transparency - wikipedia Referential Transparency means a expression won't change the behavior of a program For example : // C code // this is not referential transparency // it's referential opaqueness // function will modify the variable outside the function void f ( int * x ) { * x += 3 ; } // this is referential transparency // function won't modify the variable outside the function int f ( int x ) { return x + 3 ; } if a function is referential transparency, then it can be optimized by many ways, ex: memoization common subexpression elimination lazy evaluation parallelization only referentially transparent functions can be memoized (cache the results) a referentially transparent expression is deterministic (the same results with the same input)","loc":"/posts/2014/10/referential-transparency/","tags":"Functional"},{"title":"Python virtualenv upgrade","text":"If you want to upgrade main Python program in virtualenv, then just run the creation command again. ex: virtualenv env virtualenv env-pypy3 -p /usr/bin/pypy3","loc":"/posts/2014/10/python-virtualenv-upgrade/","tags":"Python"},{"title":"RPython Intro.","text":"(not complete) What's RPython RPython is a subset of Python Language RPython Type Static (not Manifest Typing, but Type Inference) http://stackoverflow.com/questions/7161856/what-is-statically-typed-in-rpython Not all code in the PyPy repository is RPython. For example, there are code generators (e.g. in rlib.parsing) that run at compile time and produce RPython code, but are not RPython (frequently with a \"NOT_RPYTHON\" docstring, by the way). Also, large parts of the standard library are written in full Python (mostly taken straight from CPython). To make a C code generator, code on interpreter level has to restrict to a subset of Python. (Code on application level cat still use full Python) PyPy is not source-to-source translations , it start translation from live python code objects . Type Inference & Static Typing Types are not stated explicitly, they are infered, so RPython is static typing. Static typing doesn't mean the type has to be written out (that's manifest typing ), it means each expression has a single type that never changes. Analysis def add ( a , b ): return a + b We cann't infer a (non-generic) type for a function like above, the return type depends on arguments, so the return type is determined by analysis the arguments (when the function is called) RPythonic Flow restrictions variable constant globals are considered constants (global instances don't have this restriction) control structures range definitions run-time definition of classes or functions is not allowed generators exceptions fully supported Object restrictions int, float, bool works strings tuple no variable-length tuples lists annotator can figure out most of the time that your list is fixed-size, even when you use list comprehension dicts unique key type only functions Integer Types build a Python VM with RPython","loc":"/posts/2014/10/RPython/","tags":"Python"},{"title":"Try the jitviewer","text":"the jitviewer target analysis log from PyPy, and display Python bytecode & jit operations via the web install jitviewer is a PyPy2 only program now (it need rpython) create the virtual environment virtualenv env-pypy -p /usr/bin/pypy active the virtual environment source env-pypy/bin/activate get the PyPy2 source code (for rpython) wget https://bitbucket.org/pypy/pypy/downloads/pypy-2.4.0-src.tar.bz2 tar -xvf pypy-2.4.0-src.tar.bz2 install jitviewer pip install jitviewer set the env setenv PYTHONPATH pypy-2.4.0-src run the sample jitviewer.py --log log create log of PyPy setenv PYPYLOG jit-log-opt,jit-backend-counts:myprogram.log pypy -c your_program.py with PyPy3 As jitviewer is a PyPy2 only program now (2014-10-15), you should run your program by PyPy3 and output the log, then use jitviewer with PyPy2 to analysis the log. expect in the future There are something that I think it should have ... PyPy3 compatibility jitviewer with PyPy3 is not working now, the smaller part is the syntax in jitviewer (something like print function), the bigger part is the rpython module ... At the moment, rpython has a lot of Python 2 only syntax (even in PyPy3 source code). CPython compatibility This means to remove the depenency of rpython. note The PyPy does not modify the output of Python bytecodes, so the Python bytecodes output from CPython's dis module or PyPy's are the same.","loc":"/posts/2014/10/jitviewer/","tags":"Python"},{"title":"PTT - Python 版 - transpose 問題","text":"這篇在解 PTT Python 版上的一個問題 (#1KEG5cfG) 基本上就是要做 transpose，但是資料長度不依， 所以就來試試囉 : https://gist.github.com/wdv4758h/1f4090ee9b0035dbcee0 以下都以 Python 3 為考量，而且以 zip 為出發點來解這個問題。 如果是一個完整 n x m 的資料， 類似的工作可以用 zip 就完成。 data = [ range ( 10 ) for i in range ( 8 )] def transpose ( data ): return zip ( * data ) for i in transpose ( data ): print ( i ) 現在的狀況不是完整 n x m 的資料，而是長短不一的， 一種解是用 itertools 裡的 zip_longest， 參數是 iterables 還有 fillvalue (預設是 None)， fillvalue 會拿來填滿資料短缺的部份。 import itertools as it def transpose ( data ): return it . zip_longest ( * data ) # 跟前面文章借測資 data = [ list ( range ( i )) for i in range ( 10 , 0 , - 1 )] del data [ 3 ] del data [ 6 ] for i in transpose ( data ): print ( i ) 這邊會把不夠的地方都補 None， 所以輸出會是: (0, 0, 0, 0, 0, 0, 0, 0) (1, 1, 1, 1, 1, 1, 1, None) (2, 2, 2, 2, 2, 2, None, None) (3, 3, 3, 3, 3, 3, None, None) (4, 4, 4, 4, 4, None, None, None) (5, 5, 5, 5, None, None, None, None) (6, 6, 6, None, None, None, None, None) (7, 7, 7, None, None, None, None, None) (8, 8, None, None, None, None, None, None) (9, None, None, None, None, None, None, None) 如果前面那種剛好符合需求，那就可以開心的拿來用了， 如果真的不想要看到多補的那些資料，就再把結果處理過。 def transpose ( data ): return ( tuple ( it . filterfalse ( lambda x : x is None , i )) for i in it . zip_longest ( * data )) for i in transpose ( data ): print ( i ) 如此一來結果就變成: (0, 0, 0, 0, 0, 0, 0, 0) (1, 1, 1, 1, 1, 1, 1) (2, 2, 2, 2, 2, 2) (3, 3, 3, 3, 3, 3) (4, 4, 4, 4, 4) (5, 5, 5, 5) (6, 6, 6) (7, 7, 7) (8, 8) (9,) 不過上面處理是以輸入 data 裡沒有 None 為前提的 XD 資料裡面可能有 None 的話就另外用別的值囉。","loc":"/posts/2014/10/ptt-python-transpose/","tags":"Python"},{"title":"Pythoner 讀 「松本行弘的程式世界」 - part 3","text":"ch 8 Regular Expression 毫無反應就是 regular expression 書上是介紹 Ruby 裡的 re，基本上長的就是 Perl 樣 (X 基本 re 觀念都差不多 # Ruby '<ul><li>a</li>b</ul>' . split ( /(<.*?>)/ ) => [ \"\" , \"<ul>\" , \"\" , \"<li>\" , \"a\" , \"</li>\" , \"b\" , \"</ul>\" ] # Python import re re . split ( '(<.*?>)' , '<ul><li>a</li>b</ul>' ) >>> [ '' , '<ul>' , '' , '<li>' , 'a' , '</li>' , 'b' , '</ul>' , '' ] 書上提到 Ruby 1.9 的 re 使用了 Oniguruma 這個 engine， Ruby 2.0 後轉到 Oniguruma 的 fork : Onigmo Python 的話可以看 re 的 document 這章節最後最後提到 DSL (Domain Specific Language) ch 9-1 Integer 在 C 裡，型態為 int 的狀態下，5 / 2 的結果會是 2 int 有大小上限 bitwise operation bitmask 2's complement ch 9-2 Float fixed point number (不好用) IEEE 754 電腦中的浮點數沒有結合律 (誤差會擴大) 誤差會累積 Inf, 0, NaN 運算的值的絕對值相差過大時，計算會造成誤差 cancellation error (相減兩個相近的數字時造成的誤差) >>> 10000001.0 + 0.12345678 + 0.11111111 + ( - 10000000.0 ) 1.234567889943719 >>> 10000001.0 + ( - 10000000.0 ) + 0.12345678 + 0.11111111 1.23456789 >>> 0.0123456 - 0.0123444 1.1999999999998123e-06","loc":"/posts/2014/10/pythoner-read-ruby-book-3/","tags":"Misc"},{"title":"Pythoner 讀 「松本行弘的程式世界」 - part 2","text":"ch 2-5 Duck Typing duck typing 實在很常聽到，尤其自己常寫的是 Python XD 在講到 type 時，常聽到的有 static 和 dynamic，static 的話不用執行就可以知道， dynamic 的話要執行下去才能確認 硬體看得懂的是二進位數字，其他寫程式用到的型別都是建立在這之上的， 如果沒有做成更好用的 type 的話會造成程式撰寫上的負擔， 於是 Fortran 提供了型別 (整數資料、浮點數陣列等等)， 於是有了 static type (宣告型別) Lisp & Dynamic type 在 Fortran 出現後幾年，出現了 Lisp， 1958 年的 Lisp 只有兩種型別 : list、atom，不是 list 的都是 atom cons cell car, cdr S-expression Lisp 的 list 裡事先無法知道 cons cell 裡面指到的是 cons cell 還是 atom， 本質上可說是 polymorphism 的 data structure， 所以 Lisp 採用的是 \"資料本身還有描述自己型別的資訊\"，又稱為動態型別 cons cell +-----+-----+ | car | cdr | +-----+-----+ | | | | +---+ +-----+-----+ | 5 | | car | cdr | +---+ +-----+-----+ atom | | | | +----+ nil | 13 | atom +----+ atom Static Type 起自 Fortran、Dynamic Type 起自 Lisp， 在最初的物件導向語言 Simula 裡，出現了和 Dynamic Type 類似的型別 Ref (Simula 中除了物件之外都是靜態型別)， 之後從 Simula 的物件導向概念延生出的 Smalltalk 和 Lisp 一樣全面採用動態型別， 1980 年代前半，受到 Simula 影響而誕生了 C++，重要概念 : \"subclass 可以視為 base class 的 instance\" Duck Typing 的概念是: \"走路像鴨子，看起來像鴨子，那就可以把他當成鴨子\" Dynamic Type 裡避免名去檢查型別，而改以檢查是否有某 method","loc":"/posts/2014/10/pythoner-read-ruby-book-2/","tags":"Misc"},{"title":"血月之 Stellarium","text":"Stellarium 月全蝕的時候從朋友那知道的 Open Source 軟體， 看起來蠻棒的 XD","loc":"/posts/2014/10/stellarium/","tags":"Misc"},{"title":"心理學概論 之 Chomsky","text":"這禮拜二在上心理學概論的時候，上到打瞌睡 zzz， 都是因為整天都有課 (晚上也有)，前面又上完體育課很累 ... 就在半睡半醒中，突然聽到了 Chomsky ! 頓時精神力上升，腦中馬上浮現 Chomsky Normal Form， 馬上抬頭看一下 slide，上面寫著 Noam Chomsky， 立馬 Google ... 果然是同個人啊 ... 在上心理學的時候可以想到正規也是個奇妙的狀況 Orz","loc":"/posts/2014/10/psychology-intro-chomsky/","tags":"Misc"},{"title":"Pythoner 讀 「松本行弘的程式世界」 - part 1","text":"這邊是讀了書上內容的節錄和獨後自己查的資料 目前心得 : 可以看到一些觀念，但是有些例子就 ... (尤其是少部份有提到 Python 的) ch 14-1 - functional programming 是的沒錯，我第一個翻的章節是 chapter 14 ... Fortran 設計者為 John Backus (John Backus 還發明了 BNF)， 其在 1997 年 Turing Award 上發表的語言 \"FP\" 被認為是 Functional Programming 的起點 Feature: Higher-order function pure function (no side effect) Referential transparency Lisp Lisp 的基礎是 Alonzo Church 提的 lambda calculus，也支援 Higher-order function Lisp 具有一些 functional 的特性，但不是純粹的 functional Lisp 最大的特色是 S-expression 另一個特色是 list (LISP = LISt Processing)，Lisp 把節點稱為 cons cell， cons 是從建立新 cell 的 function : cons (construct) 而來， 而一開始的 Lisp 環境把第一個資料放在 address register，第二個放在 data register， 所以 car = content of address register、cdr = content of data register， 構成 list 的資料成為 atom (symbol or number) cons cell: car cdr Lisp 的 list 底下結構是 singly linked-list Haskell Haskell Curry 的 Combinatory logic 和 Alonzo Church 的 lambda calculus 幾乎相同的東西 Haskell feature: no side effect Higher-order function partial function application lazy evaluation type inference list comprehension block by indent Haskell 有靜態多型的型別系統和 type inference，可以在接近 duck typing 的情況下， 在編譯時完成 type checking OCaml OCaml 歷史比 Haskell 早，誕生於法國 和 Haskell 相比有些不同: has side effect no lazy evaluation module system OCaml 想要 lazy evaluation 時可以明確標示 Erlang Erlang 是為了平行處理而設計的，設計受到 Prolog 影響 dynamic type, no lazy evaluation 以 actor 理論為基礎 Ruby Block Proc object lambda enumerator What Is the Difference Between a Block, a Proc, and a Lambda in Ruby? [ 1 , 2 , 3 ]. each { | x | puts x * 2 } [ 1 , 2 , 3 ]. each do | x | puts x * 2 # block is everything between the do and end end lam = lambda { | x | puts x * 2 } [ 1 , 2 , 3 ]. each ( & lam ) p = Proc . new { | x | puts x * 2 } [ 1 , 2 , 3 ]. each ( & p ) # The '&' tells ruby to turn the proc into a block ch 14-2 Code Generation nothing ch 14-3 Memory Management 因為一些概念之前有看過了，所以這邊算是複習和加強 XD Garbage Collection 的誕生是在 1960 年代， 起因於 Lisp 需要產生大量 cons cell object，不能明確管理各個 object GC 衡量: GC 所佔的時間比例 Pause Time 平均 pause time 最長的 pause time no GC 例如 C 或 C++，programmer 自己管理 memory，自己 malloc/free、new/delete programmer 沒把程式寫好會造成: dangling pointer (因為把還在用的 free 掉了) memory leak (該 free 的沒 free 到) double free 要檢查這些問題可以使用 valgrind GC algorithm Algorithm Description Problem reference counting 用一數字紀錄被 reference 的次數，最容易實作 cycle reference 不適合平行處理 mark & sweep 把 trace 的到的 objects 做標記，沒標到的清掉 objects 量上升時，速度容易下降 mark & compact 把 trace 的到的 objects 做標記， 接著把標過的集合起來， 如此一來 memory 操作就有了區域性， 讓快取之類的機制效率提高 比 mark & sweep 慢 不能使用保守 GC copying 把還在用的複製一份到新的 memory 區域 (會分成新和舊)， 接著把舊區域整個清掉 Algorithm Description Generational 多數 objects 會在短時間內變成 garbage，所以可以用 age 做不同處理， 會分成 minor GC 和 major GC， 有 write barrier (紀錄 old object 裡用到 young object 的狀況，這紀錄稱為 remembered set) Conservative 在 C 這種本來沒有 GC 的語言，compile 後就沒有區分 integer 和 pointer 的資訊， 因為 CPU 不需要，這時可以使用 Conservative 實作，概念是 \"碰到 address 相同時， 代表可能被引用，視為存活\" (heap 會整個被掃過) Incremental 把 GC 操作切割，以降低每次 GC 的最長時間，也用了 write barrier Concurrent 機制和 Incremental GC 類似，利用 write barrier 維持狀態資訊，實作時也可能有專用的 GC thread Bitmap Marking Linux 這類 Unix-like 在 fork 時 memory addres 是 copy-on-write 的， 可以避免不必要的 page copy，但是和 GC 的搭配不太好，GC 在改動時就會大量複製， Bitmap Marking 就是用來降低複製 page 的次數，不時直接對 object 做標記， 而是有另外的空間用於標記，所以複製的只有標記用的 Bitmap ch 14-4 Ruby with C 介紹 Ruby 如何和 C 一起用 ch 14-5 Open Source Open Source 發展簡史","loc":"/posts/2014/10/pythoner-read-ruby-book-1/","tags":"Misc"},{"title":"People who make VMs","text":"剛剛碰巧看到一個 StackOverflow 上的回應 ， 原來 V8 的 team 和 HotSpot JVM 的有很大重複，還有其他像是 Self VM、Animorphic Smalltalk VM、OOVM 都是， 而其中的 tech lead 叫 Lars Bak。 Lars Bak 是 Dart 語言的創始人 (Dart 語言是 Google 想用來取代 Javascript 的一個語言) 也是 V8 和 Java HostSpot JVM 的領導，對於 VM 的技術有非常多的經驗，住在丹麥的 Aarhus 的農舍。 剛好有找到一篇報導，請見下面連結 The genius behind Google's browser 對岸翻譯版","loc":"/posts/2014/09/vm-people/","tags":"Misc"},{"title":"Incremental Garbage Collector","text":"前情提要 - Pause Time 在 CPython 中使用的是 reference count，所以當 count 變成 0 時就必須把空間回收， 當一個巨大的 object 要被回收時，就會產生不小的 pause time，但是這個時間是 deterministic 的。 reference count 有個問題就是 reference cycle，為了找出 cycle 就必須爬過所有 objects， 但是這就會產生 nondeterministic GC pause。 reference count 是把回收的 cost 分開在各個時間點，而 tracing 的 GC 是把回收的 cost 集中在某一段時期， 回收所需時間可能不低，在這之中得把程式 pause，可能會讓使用者感覺到停頓， 而 Incremental GC 想做的就是把這段過程拆分成好幾個小步驟， 分別在不同時間執行 (打散)，讓程式執行更平順。 Ref 你丟我撿！神奇的 Firefox 內部記憶體回收機制 Incremental GC now in Firefox Aurora Incremental GC in Firefox 16! Incremental Garbage Collector in PyPy","loc":"/posts/2014/09/incremental-gc/","tags":"Misc"},{"title":"Generational Garbage Collection for SpiderMonkey","text":"原文章 : Generational Garbage Collection in Firefox 今天看到上面那篇 SpiderMonkey 的 Generational Garbage Collection 的文章， 就讀一讀理解一下並做些紀錄 Generational garbage collection Generational garbage collection 的核心觀念就是 \"大多數的物件的生命都很短\"， 所以就修改原本的 GC 設計，依照不同的存在時間有不同的處理方式， 對於 Tracing 的 GC 會需要去掃過物件來檢查是否有物件已經成為 Garbage， 當程式會製造出大量的物件時，檢查的時間就會上升，這時如果用已經存在的時間來區分， 而做不同的處理方式時，多數的短期物件就可以更快的被回收，也不必頻繁檢查會長期存在的物件。 原文章裡的 SpiderMonkey 利用了這種方式來讓 temporary objects 的 penalty 下降 Nursery & Tenured 多數的 objects 都會 allocate 到一個叫做 Nursery 的 memory region， 當 Nursery 滿的時候，只檢查 Nursery 裡的 objects，此時多數的 short-lived temporary objects 就會被清掉， 而這樣的檢查相對於原本 (檢查全部的 objects) 也來的快 此時，依然存活的 objects 就會被放到 Tenured region Tenured heap 仍然會回收 grabage，但是頻率會比 Nursery 來的低 最終然會需要原整的 GC，但是頻率也會比 Nursery GC 來的低 所以就分成下面這種情況 Garbage Collection Scan Place frequency speed minor GCs Nursery high fast major GCs full heap low slow memory region age Nursery young Tenured old Problem Tenured object 裡面可能有指向 Nursery object 的資料 (Nursery objects 因為某些 Tenured objects 而持續 alive) 解法一 掃過整個 Tenured heap 來找出指到 Nursery objects 的 pointer， 但是這麼做的話就違背了 GGC 的設計本意，所以需要更 cheap 的解決方案 解法二 先注意到，在 heap graph 中 Tenured 指向 Nursery 的 edges 不會存在很久， 因為接下來 minor GC 就會把 Nursery 中的 survivors 移到 Tenured heap 所以我們在意的是從上次 minor/major GC 後，有更動過的 Tenured objects， 而這些 objects 的數量相對來說就會比較少 因此我們做的是在更動 Tenured objects 時，檢查是否有 Nursery pointers， 如果有的話就把這些 cross-generational edges 紀錄到 store buffer ， 這樣的事情稱為 write barrier 在 minor GC 時，我們就跑過一遍 store buffer 裡的資料並且把裡面的 Nursery objects 標記為存在 (edge 的來源都需要被使用，因為當 Nursery objects 被標記為存在之後，將會移往 Tenured area， 所以原本的 Tenured (裡面有指向 Nursery 的 pointer) 也需要被 update minor GC 需要的執行時間決定於新 cross-generational edges 和 Nursery 裡的 objects 數量， 當然，追蹤 store buffer records 或是單純的檢查是否要新增 record 都會讓 normal heap access 有些許的效能損失， 所以某些 code 可能在 GGC 裡會變慢一些","loc":"/posts/2014/09/ggc-spidermonkey/","tags":"GC"},{"title":"Python coding style","text":"不能不提的 PEP8 Google Python Style Guide","loc":"/posts/2014/09/python-coding-style/","tags":"Python"},{"title":"Levenshtein distance","text":"第一次碰這類的東西，做些筆記 XD edit distance edit distance = 更動多少次數後，兩字串會一樣 計算方式有很多種 Algorithm insertion deletion substitution transposition (換位) Hamming distance X X O X Longest Common Subsequence O O X X Levenshtein distance O O O X Damerau-Levenshtein distance O O O O Levenshtein distance http://en.wikipedia.org/wiki/Levenshtein_distance http://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance Levenshtein distance 是用來評估兩 sequence 差別度的一種 string metric， 兩個字串的 Levenshtein distance 就是一個字串變成另一個字串的最小字元編輯次數 (insert, delete, substitute)， 由俄國科學家 Vladimir Levenshtein 在 1965 年提出 substitution : s a t -> s i t insertion : st -> s i t deletion : si a t -> sit 看一段簡單的 Python code 來了解運算: def lev ( a , b ): if not a : return len ( b ) if not b : return len ( a ) return min ( lev ( a [ 1 :], b [ 1 :]) + ( a [ 0 ] != b [ 0 ]), lev ( a [ 1 :], b ) + 1 , lev ( a , b [ 1 :]) + 1 ) 傳入 min function 的有 3 個， 第一個是兩邊都減一個字元，如果減去字元不一樣就把次數加 1 (substitute)， 第二個是 a 減去一個字元並且次數加一，這可以看成 a 字串的 delete 或是在 b 前面 insert 了和 a match 的字元， 第三個跟第二個雷同 當然，這個寫法很沒有效率，做了很多次不必要的遞迴，用 CPython (Python 3.4) 下去跑測試， 丟個簡單的字串當測試 lev('fasfasf', 'afvq') 這個做法大約要 1.9 ms 簡單地用 lru cache 來做 DP: from functools import lru_cache def lev ( a , b ): @lru_cache ( maxsize = None ) def _lev ( a , b ): if not a : return len ( b ) if not b : return len ( a ) return min ( _lev ( a [ 1 :], b [ 1 :]) + ( a [ 0 ] != b [ 0 ]), _lev ( a [ 1 :], b ) + 1 , _lev ( a , b [ 1 :]) + 1 ) return _lev ( a , b ) 利用 lru cache 來簡單地做 DP 後，剛剛的測試現在大約變成 370 µs 當然，還有很多改進空間，像是 自己實際寫 DP 判斷字串相同就直接回傳 0 (對於有很多相同子字串的情況可以用字串比對的 cost 換掉一些遞迴) 減去頭尾相同的子字串 如果要速度的話: python-Levenshtein ，C 寫的 Python extension，剛剛的測試丟下去大概會變成 300 ns 以內 計算的 cost 大約會是 O(len(a) * len(b))，所以在幫助 fuzzy string searching 的時候， 比較的字串同常會比較小，以便於提升速度 其他性質 lower bound : 兩字串的長度差 upper bound : 較長的字串的長度 只有當字串相等時會是 0 當字串長度相同時，Hamming distance 會是 Levenshtein distance 的 upper bound [三角不等式] 兩個字串的 Levenshtein distance 不會大於分別和第三個字串的 Levenshtein distance 的合 使用情境 spell checkers OCR assist natural language translation based on translation memory http://en.wikipedia.org/wiki/Record_linkage","loc":"/posts/2014/09/levenshtein-distance/","tags":"Fuzzy"},{"title":"About Stackless Python","text":"Stackless Python 背後的由來以及現況 ~ 聽故事去","loc":"/posts/2014/02/stackless-python/","tags":"Python"},{"title":"Chart.js 簡單的畫出 Chart","text":"Chart.js 是利用 HTML5 的 canvas 去畫的， 而 Chart.js 這個 library 本身是 open source 的 (MIT license) ( Chart.js - github ) 所以到底要怎麼用呢？ 其實要用這個 library 很簡單， 首先要先把 Chart.js (或 Chart.min.js) include 進來 (這邊先用 CDN 上的做範例，要擺到自己機器上的再去修改 src) <script src= \"//cdnjs.cloudflare.com/ajax/libs/Chart.js/0.2.0/Chart.min.js\" ></script> 再來是要有畫布啦 ~ <canvas id= \"myChart\" width= \"400\" height= \"400\" ></canvas> 接著是給資料然後畫圖 ~ var data = [ { value : 30 , color : \"#F38630\" }, { value : 50 , color : \"#E0E4CC\" }, { value : 100 , color : \"#69D2E7\" } ]; //Get the context of the canvas element we want to select var ctx = document . getElementById ( \"myChart\" ). getContext ( \"2d\" ); var myNewChart = new Chart ( ctx ). Pie ( data ); var data = [ { value: 30, color:\"#F38630\" }, { value : 50, color : \"#E0E4CC\" }, { value : 100, color : \"#69D2E7\" } ]; var ctx = document.getElementById(\"myChart\").getContext(\"2d\"); var myNewChart = new Chart(ctx).Pie(data); Chart.js 目前有六種 Charts， 可以在 官方文件 看到相關的設定、資料格式， 每個 Chart 除了本身的資料外，還有一些 option 可以調整， 例如要不要 animation 啦、要不要顯示 label 啦 ... etc 六種 Chart Line Chart var data = { labels : [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\"], datasets : [ { fillColor : \"rgba(220,220,220,0.5)\", strokeColor : \"rgba(220,220,220,1)\", pointColor : \"rgba(220,220,220,1)\", pointStrokeColor : \"#fff\", data : [65,59,90,81,56,55,40] }, { fillColor : \"rgba(151,187,205,0.5)\", strokeColor : \"rgba(151,187,205,1)\", pointColor : \"rgba(151,187,205,1)\", pointStrokeColor : \"#fff\", data : [28,48,40,19,96,27,100] } ] }; var ctx = document.getElementById(\"LineChart\").getContext(\"2d\"); new Chart(ctx).Line(data); Bar Chart var data = { labels : [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\"], datasets : [ { fillColor : \"rgba(220,220,220,0.5)\", strokeColor : \"rgba(220,220,220,1)\", data : [65,59,90,81,56,55,40] }, { fillColor : \"rgba(151,187,205,0.5)\", strokeColor : \"rgba(151,187,205,1)\", data : [28,48,40,19,96,27,100] } ] }; var ctx = document.getElementById(\"BarChart\").getContext(\"2d\"); new Chart(ctx).Bar(data); Radar chart var data = { labels : [\"Eating\",\"Drinking\",\"Sleeping\",\"Designing\",\"Coding\",\"Partying\",\"Running\"], datasets : [ { fillColor : \"rgba(220,220,220,0.5)\", strokeColor : \"rgba(220,220,220,1)\", pointColor : \"rgba(220,220,220,1)\", pointStrokeColor : \"#fff\", data : [65,59,90,81,56,55,40] }, { fillColor : \"rgba(151,187,205,0.5)\", strokeColor : \"rgba(151,187,205,1)\", pointColor : \"rgba(151,187,205,1)\", pointStrokeColor : \"#fff\", data : [28,48,40,19,96,27,100] } ] }; var ctx = document.getElementById(\"RadarChart\").getContext(\"2d\"); new Chart(ctx).Radar(data); Polar area chart var data = [ { value : 30, color: \"#D97041\" }, { value : 90, color: \"#C7604C\" }, { value : 24, color: \"#21323D\" }, { value : 58, color: \"#9D9B7F\" }, { value : 82, color: \"#7D4F6D\" }, { value : 8, color: \"#584A5E\" } ]; var ctx = document.getElementById(\"PolarChart\").getContext(\"2d\"); new Chart(ctx).PolarArea(data); Pie chart var data = [ { value: 30, color:\"#F38630\" }, { value : 50, color : \"#E0E4CC\" }, { value : 100, color : \"#69D2E7\" } ]; var ctx = document.getElementById(\"PieChart\").getContext(\"2d\"); new Chart(ctx).Pie(data); Doughnut chart var data = [ { value: 30, color:\"#F7464A\" }, { value : 50, color : \"#E2EAE9\" }, { value : 100, color : \"#D4CCC5\" }, { value : 40, color : \"#949FB1\" }, { value : 120, color : \"#4D5360\" } ]; var ctx = document.getElementById(\"DoughnutChart\").getContext(\"2d\"); new Chart(ctx).Doughnut(data); Ref Chart.js","loc":"/posts/2014/02/chart-js/","tags":"Misc"},{"title":"自製 template tags 和 filters","text":"起手式 要建立自己的 template tags 之前，要先在一個 app 資料架底下建立 \"templatetags\" 資料夾， 如果這些 tags 是跟 app A 有關的話，那很理所當然可以放在 app A 資料夾下的 \"templatetags\"， 如果是比較不能區分的話，可以建立一個 app 專門放 template tags。 注意要有 __init__.py 來讓 Python 把這個資料夾當作 package 自製的 tags 和 filter 就放在 templatetags 資料夾底下的檔案， 檔案名字就是在 template 要 load 時的名字 結構可能長這樣: App/ __init__.py models.py templatetags/ __init__.py abc.py view.py 在 template 裡要用到 abc.py 這個檔案裡寫的 tags、filter 時， 就在 template 裡 \"{% load abc %}\" 有包含 custom tags 的 app 要加到 INSTALLED_APPS 裡 {% load %} 才會 work。 (security feature: 你可以在一台機器上裝多個 template libraries 而不讓它們可以 access 機器上的每個 Django 的程式) 鍛冶 要能製造出一個 valid 的 tag library 首先要有一個叫作 register 的 template.Library instance 所以開頭會長這樣 : from django import template register = template . Library () filters tags Ref Custom template tags and filters Django default tags & filters django/template/defaultfilters.py django/template/defaulttags.py","loc":"/posts/2014/02/django-templatetags/","tags":"Django"},{"title":"[回憶] 2012 年夏 ~ 2014 年春","text":"一年半內除了學校的課程能學到些什麼？ 不多也不少，這樣而已 (想到什麼就紀錄些什麼吧) 起頭 2012 年夏，正值升大學的時期，雖然進了資工系，但其實什麼都還不會， 暑假期間開始常上 BBS，後來看到上面的色碼還有其他的控制碼覺得很有趣， 接著就開始在上面試了一下，然後又看到某人在上面搞出一堆神奇的東西 (?)， 再來是開到上面的 vim mode (當時還不會用 vim)， 這算是初步接觸到 vim 的地方之一吧 XD (另外是鳥哥寫的文章)。 之後拿到了社團 server 上的帳號，開始連進去亂試指令 w， 從此掉進無底的坑洞 (X，這時間大概有時候會翻翻鳥哥吧， 到了學校後開始接觸 FreeBSD， 就裝來玩玩看，翻翻 FreeBSD handbook，開始認識 configure、make、ports ... etc， 當時在 FreeBSD 上用的是 tcsh (因為社團 server 預設是 tcsh，所以先接觸到 XD)， 因為一些原因開始看怎麼寫 shell script (Bourne Shell 的)， 慢慢知道有 sed、awk 這些東西， 開始使用 regular expression (已經想不起來從哪個時間點開始了)。 寫到這裡開始回去翻以前寫在 BBS 的文章回想 XD 阿對一開始還去玩了 pi 的貪吃蛇 ~ 哦哦哦！BBS 上看到的有石頭文、guest 發文、... (?) 原來暑假就有翻過 regular expression，只是沒有碰到要使用的地方就不熟 XD， 後來有在用就比較 OK 了 ~ 喔對，BBS 有聊天指令 XD 看到移位碼就想起之前試一試發現， 原本應該擋掉的名片檔移位碼在我亂試的情況下發現有 bug XDDDD， 後來被 PO 到 sysop，之後又修掉了。 原來當初 9 月開始就有去過 PyHUG，但是當時完全不會 Python zzz 找到了 ~ 2012/10/17 拋棄 Windows，轉用 Linux ， 當時裝了 Ubuntu，DE 預設是 Unity，用沒多久後換成 Gnome 2，大概就這樣用了一學期。 寒假換成 LXDE 又用了一學期，中間好像有試過 Gnome 3 一陣子吧， 一下學期末把 WM 換成了 awesome wm，然後就離不開 awesome 一直到現在， 一下結束的暑假把 Ubuntu 換成了 Arch Linux ，變成 Arch Linux + awesome。 Vim 說到 Vim 啊 ... 一開始其實看到很多次，但是都沒有真的把它拿來用，所以不熟 zzz。 後來毅然決然把所有編輯純文字的東西都只用 vim ，一陣子後就習慣整個操作， 不過當時對 hjkl 的移動還不是很熟，索性在 .vimrc 裡把方向鍵 map 掉， 只用 hjkl 移動，後來也就習慣了。 一上結束的寒假稍微看了一下 .vimrc 的設定，調了一些東西和試了一些 plugin (雖然最後大多把 plugin 關了 XD)， 做的設定中幾個最常用到的是 paste mode 切換的快捷鍵、儲存時自動移除行尾多餘空白、下次開啟時回到關閉前的位置 ... etc。 plugin 部份的話用 Vundle 管理很方便，在加上一小段 script 後， 到新的地方只要打開 vim 就會自動裝好 vundle， 接著就可以利用 vundle 很快的把你的 plugin 裝起來， 利用 vundle 後 update plugin 也一樣只需要一個 command。 現在只要是純文字的東西我都用 vim，可以說是離不開了 XD，就連這篇文章也是我用 vim 打出來的 ~ Python 到底是從什麼時候開始比較常寫 Python 的我又忘了 (X 剛開始因為別人介紹，陸陸續續有看一點 Python 的東西，社課後知道了 list、tuple， 不過這時還是沒有在使用它，後來假期有人約讀書會所以看了 Python tutorial 的前部份。 一下結束後的暑假 (不知道是不是這個時期開始)，因為在跟高中同學打 game， 那遊戲在有人踩到紀錄點時會存資料在 host user， 而在某次遊戲中有人不小心在很糟糕的時間點踩到了， 結果只能回溯到那悲慘的時間點， 後來我就想說寫個程式讓他去 check 有新紀錄時就 backup 一次， 就開始用 Python 寫個小程式去 check， 東查西查，開始對 Python 變比較熟一點， 後來為了能一次 check 多個檔案又嘗試了 Python 的 multiprocessing， 而另一個同學則是去寫了簡單的 GUI， 在看了他的 code 並幫忙修改後，稍微對 Python 的 class 有點感覺了， 然後這也是我第一次使用內建的 tkinter 做簡單的 GUI。 之後開始愈來愈常寫 Python，慢慢的學會愈來愈多東西 XD 筆記 做筆記的方式嘛 ... 高中用過 Evernote 記了一點東西(不多)， 後來大一有陣子是 Google Docs + Markdown (本機)。 一下結束後的暑假聽到 Sphinx 這玩意， 看起來還不錯，也看到別人寫出來的東西， 所以就開始變成寫 reStructuredText 、用 Sphinx generate HTML， 不過 Markdown 也還是有再用 (這篇就是用 Markdown 寫的)， 所以目前是 Markdown & reStructuredText 亂用中 (X Version Control 我現在常用的 Version Control 是 git， 一開始也是不熟 (看了看還是沒常用)，後來把一些東西用 git 上去後， 變成只熟 add & commit (X，後來碰到一些狀況而對 checkout、push、partial add、cherry-pick、stash 比較熟一點， 目前是基本操作還 OK 啦 (自己說 mercurial ...，目前無緣 XD，只在別人教的時候試過一次，不過因為已經慣用 git 了，所以 ... XD cvs 只在抓 FreeBSD kernel source 的時候用過 zzz Linux 一個無底洞 (X 我掉進去後就再也出不來了 XD 因為已經太融入生活了，不知道該說什麼 ~ 現在用 Arch Linux 用的很開心 O w O 改天想到再補東西吧 ~ FreeBSD FreeBSD 的部份算是配合修課做了點基本的學習， 內容大概有 FTP、Samba、ZFS、FAMP (FreeBSD + Apache + MySQL + PHP)、 NFS、amd (Berkeley Automounter)、NIS、PF、NAT、DHCP、SSL/TLS、Proxy、DNS、Postfix ... 這些算是有基本的接觸過了 (有架出東西)，最不熟的大概是最後的 Mail Server 部份吧 zzz， 東西弄起來有點麻煩，最後交作業的時候 ClamAV 偵測病毒信件的部份沒弄好 = =。 以前課程有 VPN，修課的時候剛好沒有，想之後找時間架來玩玩。 HTML, CSS, Javascript 這邊要從一下結束的暑假開始， 社團決定大家要一起用 Django 寫社團網站， 這時候就開始摸索 Django 和認識基本的 HTML， 不過 CSS 部份是由另一位負責，所以沒接觸。 後來進 OH 去用 Django 改寫目前的網站， OH 原本的網站是套 Bootstrap 2，我在做新網站的時候改用了 Bootstrap 3， 接著就因為 Bootstrap 3 改了很多地方，所以要到處去修 Orz， 中間調樣式的時候開始認識一些 CSS 的東西， 某些地方因為用到 Javascript 所以也開始有了點接觸。 2014 2月，開始想用 GitHub Pages 來寫 blog， 於是開始使用 Pelican 這個 Python 寫的 static site generator， 因為可以用 Markdown 和 reStructuredText 所以可以很開心的用 vim 寫文章 ~~~ 在使用 Pelican 寫 blog 後，想說順便來試著自己寫個 theme 來看看， 所以就開始寫更多的 CSS，中間在調某些功能的時候用到了 Javascript， 所以也寫了一小段的 Javascript code。 Database Database 的話只會一點點簡單的 SQL 語法， 大多是寫東西需要去查的，用一用就知道了幾個， 只用過 SQLite、MySQL、MariaDB，不過都不熟就是了 XD， 因為碰到的東西重點都不是在調 Database， 很多都只是接上去而已。 C 說實話，C 其實只會些基本的東西，沒有很熟 XD 現在只想到好幾個月前在 Wikipedia 的 Multiple dispatch 頁面看到的 C code 感覺還蠻有趣的 (X C++ 一下的 OOP 課開始頻繁接觸 C++， 因為老師的課程安排，所以學了一些 C++11 的東西， 老師在 constructor 那部份講了好一陣子， 後來作業的關係寫了自己的 vector 和 list Orz， 還記得那時候在講 new，new operator、operator new、placement new ... 某次作業好像用到了 C++11 加進來的 lambda expression。 其實老師的講義寫了很多東西，只是我還沒能好好吸收起來 ...， 只好一定要好好補起來 = = Makefile 曾經在某陣子因為寫 C++ 作業的關係看了些 Makefile 的東西， 也寫了些簡單的 Makefile ...，不過現在差不多忘了 (X awk awk 好像寫過那麼一下 ... sed sed 好像在某次作業用過，還有自己寫的 shell script 裡用過， 不過基本上 ... 不熟 XD shell script (Bourne Shell) shell script 少數時候會因需求寫一點， 不過都是寫純 Bourne Shell 的 (X， Bash 的只有在 .bashrc 裡寫過 XD lua 接觸到 lua 是因為轉用 awesome wm 的關係 XD， awesome wm 的設定檔是用 lua 寫的， 所以改的時候會看到一些 lua 語法 ~， 前陣子在看 coroutine 的時候又看到用 lua 去說明的文章， 不過說那麼多其實還是沒在寫 lua XD (根本沒好好學過) Perl Perl 只有在寫作業 (irc bot、大量寄信程式、登入時間統計) 的時候用過， 寫完之後就沒用過了 (X，現在可以說是完全不會了 XD Functional Programming 有想要接觸 Functional 的東西耶 之後想找時間學 Haskell ~ (曾經在某天翻過，連基本的都差不多忘光了 XD 最近寫 Python 開始慢慢使用 lambda、filter、map、reduce (X","loc":"/posts/2014/02/recall-2012-summer-2014-spring/","tags":"Misc"},{"title":"XMLHttpRequest","text":"有了 XMLHttpRequest 就讓我們可以利用 Javascript 去做 request 以下直接用一段 Javascript 去說明 var req = new XMLHttpRequest (); req . onreadystatechange = function (){ if ( req . readyState === 4 ){ alert ( req . responseText ); } } req . open ( 'GET' , \"test.html\" , true ); req . send ( null ); 首先是建立 XMLHttpRequest 物件，再來撰寫 readyState 改變時所要做的動作 ( onreadystatechange )， open method 去指定要做的 request，再來呼叫 send method 送出 在收到回應後，XMLHttpRequest 物件會設定的一些屬性 readyState 0 (UNSENT) The object has been constructed. 1 (OPENED) The open() method has been successfully invoked. During this state request headers can be set using setRequestHeader() and the request can be made using the send() method. 2 (HEADERS_RECEIVED) All redirects (if any) have been followed and all HTTP headers of the final response have been received. Several response members of the object are now available. 3 (LOADING) The response entity body is being received. 4 (DONE) The data transfer has been completed or something went wrong during the transfer (e.g. infinite redirects). 因此才在 onreadystatechange 裡做了 readyState 判斷， on readyState change 顧名思義就是 readyState 有變動時會去 call 這個 method， 所以加上 readyState 的判斷後變成只有處理完後 \"readyState 是 4 \" 時才做動作 Status 就是 HTTP 的 Status Code responseText 收到的內容 responseXML 收到的內容 (XML 格式) Ref XMLHttpRequest - MDN XMLHttpRequest - Wikipedia Ajax (programming)","loc":"/posts/2014/02/XMLHttpRequest/","tags":"Misc"},{"title":"closure 概念","text":"Closure 擁有非區域變數且非參數的變數 // Javascript function func () { var x = 10 ; function f ( y ) { return x + y ; } return f ; } var test = func (); func ( 10 ); // 20 func ( 5 ); // 15 這個例子可以看到 x 是個 func 的區域變數，但是在 f 當中又用到 x， 對於 f 來說 x 既不是區域變數又不是參數 # Python 3 def gen ( num ): def func ( inc ): nonlocal num print ( num + inc ) return func s = gen ( 10 ) s ( 2 ) # 12 s ( 5 ) # 15 Reference Closure (computer programming) - Wikipedia [JavaScript] Closure 概念 [Closure] JavaScript使用 Closure模擬出 Private Member JavaScript Essence: Closure","loc":"/posts/2014/02/closure/","tags":"Misc"},{"title":"coroutine 概念","text":"直接往下到 Reference 看別人寫的文章比較好 (X coroutine 是由 Melvin Conway 在 1960 年代所提出來 Coroutine 基本概念 Coroutine 可以視為 可以中斷及繼續執行的 function call 在程式語言中，通常這種中斷會用 yield 來表示，中斷時程式狀態會被保留，下次就恢復到該狀態繼續執行 Generator generator 又稱為 semicoroutine 雖然 generator 一樣可以中斷、繼續，但是 coroutine 可以指定從哪裡繼續執行，而 generator 不行，generator 只能回到上次中斷處 但是 coroutine 可以用 generator 實作出來 Coroutines in Python Improve Your Python: 'yield' and Generators Explained Tasks and coroutines Reference Coroutine: 入門篇 使用 Coroutine 實作 Iterator 使用 Coroutine 改寫狀態機 使用 Coroutine 改寫狀態機－續 使用 coroutine 實做 user-level thread Coroutine - wikipedia","loc":"/posts/2014/02/coroutine/","tags":"Misc"},{"title":"Python - @wraps","text":"在這邊先假設看這篇文章的都知道 decorator 在使用 decorator 時，若沒有經過處理，可能會造成 function 的 property 改變，例如: def test ( func ): \"\"\"this is in test function\"\"\" def haha (): \"\"\"this is in haha function\"\"\" print ( \"haha\" ) return haha @test def func1 (): \"\"\"this is in func1\"\"\" print ( \"func1\" ) print ( func1 . __name__ , ',' , func1 . __doc__ ) # OUTPUT : # haha , this is in haha function 可以看到 func1 的 __name__ 和 __doc__ 都改變了，這通常不是我們想要的，還有可能在 debug 的時候造成麻煩 因此 Python 有了 wraps 這個 decorator 去處理這個問題 (在 functools 裡) from functools import wraps def test ( func ): \"\"\"this is in test function\"\"\" @wraps ( func ) def haha (): \"\"\"this is in haha function\"\"\" print ( \"haha\" ) return haha @test def func1 (): \"\"\"this is in func1\"\"\" print ( \"func1\" ) print ( func1 . __name__ , ',' , func1 . __doc__ ) # OUTPUT : # func1 , this is in func1 可以看到，加上了 @wraps 後維持了 function 本來的 property ~","loc":"/posts/2014/02/python-wraps/","tags":"Python"},{"title":"初次使用 Pelican","text":"首先，什麼是 Pelican 呢？ Pelican 是個 Python 寫的靜態網站 generator， 你可以使用 Markdown, reStructuredText, AsciiDoc 等 markup language 作為撰寫的格式， 然後經由 Pelican 去生成靜態的網頁，經由這種方式，可以方便地使用你喜歡的文字編輯器去撰寫你的文章， 還可以結合 Version Control 去管理， 而由於生成的網頁是靜態的，所以可以放到 Github Pages 或者其他可以放置靜態網頁的地方去 Host，無疑是個很方便的模式。 Pelican 初步設定 Theme Disqus Support Pelican 要支援 Disqus 非常簡單，首先只要在你的 Disqus 新增好你的網站，獲得你的 Disqul url 後， 只要在你的 pelicanconf.py 裡新增 DISQUS_SITENAME = 'your-disqus-url' 即可： DISQUS_SITENAME = 'my-blog.disqus.com'","loc":"/posts/2014/02/pelican/","tags":"Python"}]}